---
title: HiveMetaStore
date: 2025-03-12
type: book
sidebar_position: 1
---

import Link from '/src/components/Link';
import Figure from '/src/components/Figure';
import BZhan from '/src/components/BZhan';
import PluginFields from '/src/components/PluginFields';

## 数据源配置

<Figure img={require('./datasource.png')}/>

* **配置项说明:** 

<PluginFields>

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. metaData

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** HiveMeta
	* **说明:** 		无

3. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** default
	* **说明:** 		Hive 数据库使用的库名，请在执行任务前先创建完成

4. hms

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** HMS
	* **说明:** 		无


</PluginFields>

## 数据端配置

<Figure img={require('./params-cfg.png')}/>

* **配置项说明:** 

<PluginFields>

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. dbName

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** default
	* **说明:** 		Hive 数据库使用的库名，请在执行任务前先创建完成

3. metaStoreUrls
	* **类型:** 单行文本
	* **必须:** 是
4. hiveAddress
	* **类型:** 单行文本
	* **必须:** 是
5. userToken
	* **类型:** 单行文本
	* **必须:** 是

</PluginFields>

## 批量读

<Figure img={require('./dataxReader.png')}/>

* **配置项说明:** 

<PluginFields>

1. 资源

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		DFS服务端连接配置

2. 目标分区

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		如果目标表设置了分区键，请设置该选项

3. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.hive.reader.DataXHiveReader.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误


</PluginFields>

## 批量写

<Figure img={require('./dataxWriter.png')}/>

* **配置项说明:** 

<PluginFields>

1. hiveserver2

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. 分区时间戳格式

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** yyyyMMddHHmmss
	* **说明:** 

		每进行一次DataX导入在Hive表中会生成一个新的分区，现在系统分区名称为'pt'格式为开始导入数据的当前时间戳，格式为`yyyyMMddHHmmss`或者`yyyyMMdd`

3. fsName

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：Hadoop hdfs文件系统namenode节点地址。格式：hdfs://ip:端口；例如：hdfs://127.0.0.1:9000

4. 分区保留数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2
	* **说明:** 

		每进行一次DataX导入在Hive表中会生成一个新的分区，现在系统分区名称为`pt`格式为开始导入数据的时间戳

5. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		解析Reader的元数据，自动生成Writer create table DDL语句

6. fileType

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** TEXT
	* **说明:** 		描述：文件的类型，目前只支持用户配置为"text"

7. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXHiveWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

8. writeMode

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** append
	* **说明:** 

		hdfswriter写入前数据清理处理模式：
		
		- **append**: 写入前不做任何处理，DataX hdfswriter直接使用filename写入，并保证文件名不冲突，
		- **nonConflict**：如果目录下有fileName前缀的文件，直接报错

9. encoding

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** utf-8
	* **说明:** 		描述：写文件的编码配置。


</PluginFields>



