---
title: TIS扩展点列表
linktitle: TIS扩展点列表
date: 2022-09-11
type: book
sidebar_position: 1
---

import TOCInline from '@theme/TOCInline';

:::tip 统计
**扩展点**：68，**实现插件**：237
:::

<TOCInline toc={toc} />


## com.qlangtech.tis.plugin.datax.format.guesstype.GuessFieldType

### com.qlangtech.tis.plugin.datax.format.guesstype.GuessOff

* **显示名:** off 

* **全路径名:** [com.qlangtech.tis.plugin.datax.format.guesstype.GuessOff](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-common-plugin/src/main/java/com/qlangtech/tis/plugin/datax/format/guesstype/GuessOff.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-common-plugin.tpi](./tpis#tis-datax-common-plugintpi)

### com.qlangtech.tis.plugin.datax.format.guesstype.GuessOn

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.format.guesstype.GuessOn](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-common-plugin/src/main/java/com/qlangtech/tis/plugin/datax/format/guesstype/GuessOn.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-common-plugin.tpi](./tpis#tis-datax-common-plugintpi)

* **配置项说明:** 

1. 扫描行数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 20000
	* **说明:** 		会遍历该项设定设定值，指定的行数，以判断列类型

## com.qlangtech.tis.plugin.trigger.JobTrigger

### :closed_lock_with_key:com.qlangtech.tis.plugin.trigger.impl.PartialJobsTrigger

* **显示名:** PartialTables 

* **全路径名:** [com.qlangtech.tis.plugin.trigger.impl.PartialJobsTrigger](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-datax-commercial/tis-datax-common-commercial-plugin/src/main/java/com/qlangtech/tis/plugin/trigger/impl/PartialJobsTrigger.java) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-datax-common-commercial-plugin.tpi](./tpis#tis-datax-common-commercial-plugintpi)

* **配置项说明:** 

1. Tables

	* **类型:** 多选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		需要同步的表

## com.qlangtech.tis.manage.IAppSource

### com.qlangtech.tis.plugin.datax.DataFlowDataXProcessor

* **显示名:** WorkflowProcessor 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataFlowDataXProcessor](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-common-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataFlowDataXProcessor.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-common-plugin.tpi](./tpis#tis-datax-common-plugintpi)

* **配置项说明:** 

1. 实例名称

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. 全局配置

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** datax-global-config
	* **说明:** 		无

### com.qlangtech.tis.plugin.datax.DefaultDataxProcessor

* **显示名:** DataxProcessor 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DefaultDataxProcessor](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-common-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DefaultDataxProcessor.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-common-plugin.tpi](./tpis#tis-datax-common-plugintpi)

* **配置项说明:** 

1. 实例名称

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. 全局配置

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** datax-global-config
	* **说明:** 		无

3. 所属部门

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

4. 接口人

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

## com.qlangtech.tis.plugin.datax.doris.CreateTable

### com.qlangtech.tis.plugin.datax.doris.datamodel.DuplicateCreateTable

* **显示名:** Duplicate 

* **全路径名:** [com.qlangtech.tis.plugin.datax.doris.datamodel.DuplicateCreateTable](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-doris-plugin/src/main/java/com/qlangtech/tis/plugin/datax/doris/datamodel/DuplicateCreateTable.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-doris-plugin.tpi](./tpis#tis-datax-doris-plugintpi)

### com.qlangtech.tis.plugin.datax.doris.datamodel.UniqueCreateTable

* **显示名:** Unique 

* **全路径名:** [com.qlangtech.tis.plugin.datax.doris.datamodel.UniqueCreateTable](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-doris-plugin/src/main/java/com/qlangtech/tis/plugin/datax/doris/datamodel/UniqueCreateTable.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-doris-plugin.tpi](./tpis#tis-datax-doris-plugintpi)

## com.qlangtech.tis.plugins.datax.kafka.writer.protocol.KafkaProtocol

### com.qlangtech.tis.plugins.datax.kafka.writer.protocol.KafkaPlaintext

* **显示名:** PLAINTEXT 

* **全路径名:** [com.qlangtech.tis.plugins.datax.kafka.writer.protocol.KafkaPlaintext](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-kafka-plugin/src/main/java/com/qlangtech/tis/plugins/datax/kafka/writer/protocol/KafkaPlaintext.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-kafka-plugin.tpi](./tpis#tis-datax-kafka-plugintpi)

### com.qlangtech.tis.plugins.datax.kafka.writer.protocol.KafkaSaslPlaintext

* **显示名:** SASL_PLAINTEXT 

* **全路径名:** [com.qlangtech.tis.plugins.datax.kafka.writer.protocol.KafkaSaslPlaintext](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-kafka-plugin/src/main/java/com/qlangtech/tis/plugins/datax/kafka/writer/protocol/KafkaSaslPlaintext.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-kafka-plugin.tpi](./tpis#tis-datax-kafka-plugintpi)

* **配置项说明:** 

1. SASL Mechanism

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** PLAIN
	* **说明:** 		SASL mechanism used for client connections. This may be any mechanism for which a security provider is available.

2. SASL JAAS Config

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 
	* **说明:** 		JAAS login context parameters for SASL connections in the format used by JAAS configuration files.

### com.qlangtech.tis.plugins.datax.kafka.writer.protocol.KafkaSaslSsl

* **显示名:** SASL_SSL 

* **全路径名:** [com.qlangtech.tis.plugins.datax.kafka.writer.protocol.KafkaSaslSsl](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-kafka-plugin/src/main/java/com/qlangtech/tis/plugins/datax/kafka/writer/protocol/KafkaSaslSsl.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-kafka-plugin.tpi](./tpis#tis-datax-kafka-plugintpi)

* **配置项说明:** 

1. SASL Mechanism

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** GSSAPI
	* **说明:** 		SASL mechanism used for client connections. This may be any mechanism for which a security provider is available.

2. SASL JAAS Config

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 
	* **说明:** 		JAAS login context parameters for SASL connections in the format used by JAAS configuration files.

## com.qlangtech.tis.plugins.incr.flink.chunjun.poll.Polling

### com.qlangtech.tis.plugins.incr.flink.chunjun.poll.RunInterval

* **显示名:** RunInterval 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.poll.RunInterval](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-chunjun-base-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/poll/RunInterval.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-chunjun-base-plugin.tpi](./tpis#tis-chunjun-base-plugintpi)

* **配置项说明:** 

1. incrColumn

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		增量字段，可以是对应的增量字段名

2. 轮询间隔

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5000
	* **说明:** 		轮询间隔时间，从数据库中拉取数据的间隔时间，默认为5000毫秒

3. useMaxFunc

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 

		描述：用于标记是否保存endLocation位置的一条或多条数据，true：不保存，false(默认)：保存， 某些情况下可能出现最后几条数据被重复记录的情况，可以将此参数配置为true
		
		useMaxFunc的使用场景
		​ 考虑可能存在这样的场景：某一次增量同步后的endLocation为x，在下一次增量同步作业启动的间隙中，表内又写入了增量键的值=x的数据。按照默认的情况，假设增量键为id，下一次作业会拼接例如SELECT id,name,age FROM table WHERE id > x。此时在间隙中插入的id=x的数据将会丢失。
		
		​ 为了对应上述场景，chunjun增量同步提供了配置项useMaxFunc（默认值为false）。在设置useMaxFunc=true时，chunjun会在增量作业启动时获取当前数据库中增量键的最大值作为本次作业的endLocation，并且将用于startLocation的运算符号从'>'改为'>='。例如：
		
		某一次增量启动时上次作业的endLocation为10，id最大值为100，那么将会拼接SQL语句 SELECT id,name,age FROM table WHERE id >= 10 AND id < 100
		下一次增量作业启动时id的最大值为200，那么将会拼接SQL语句 SELECT id,name,age FROM table WHERE id >=100 AND id < 200

4. 起始位点

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** Latest
	* **说明:** 

		Chunjun 增量消费启动起始位点支持三种模式：
		
		* `Latest`:
		* `Initial`:
		* `Designated`:

## com.qlangtech.tis.plugin.tdfs.TDFSLinker

### com.qlangtech.tis.plugin.datax.tdfs.impl.FtpTDFSLinker

* **显示名:** FTP 

* **全路径名:** [com.qlangtech.tis.plugin.datax.tdfs.impl.FtpTDFSLinker](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dfs-plugin/src/main/java/com/qlangtech/tis/plugin/datax/tdfs/impl/FtpTDFSLinker.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dfs-plugin.tpi](./tpis#tis-datax-dfs-plugintpi)

* **配置项说明:** 

1. 远端连接

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		FTP服务端连接配置

2. path

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：FTP文件系统的路径信息，FtpWriter会写入Path目录下属多个文件。 

### com.qlangtech.tis.plugin.datax.tdfs.impl.LocalFileDFSLinker

* **显示名:** Local Files 

* **全路径名:** [com.qlangtech.tis.plugin.datax.tdfs.impl.LocalFileDFSLinker](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dfs-plugin/src/main/java/com/qlangtech/tis/plugin/datax/tdfs/impl/LocalFileDFSLinker.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dfs-plugin.tpi](./tpis#tis-datax-dfs-plugintpi)

* **配置项说明:** 

1. path

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		描述：本地文件系统的路径（绝对路径），必须为目录路径，该目录下存放有目标资源文件

### com.qlangtech.tis.plugin.datax.hdfs.HdfsTDFDLinker

* **显示名:** Hdfs 

* **全路径名:** [com.qlangtech.tis.plugin.datax.hdfs.HdfsTDFDLinker](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-hdfs-reader-writer-plugin/src/main/java/com/qlangtech/tis/plugin/datax/hdfs/HdfsTDFDLinker.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-hdfs-reader-writer-plugin/tis-datax-hdfs-reader-writer-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-datax-hdfs-reader-writer-plugin/tis-datax-hdfs-reader-writer-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. 远端连接

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：Hadoop hdfs文件系统namenode节点地址。格式：hdfs://ip:端口；例如：hdfs://127.0.0.1:9000

2. path

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据文件保存的路径位置

### :closed_lock_with_key:com.qlangtech.tis.plugin.datax.aliyunoss.AliyunOSSTDFSLinker

* **显示名:** AlyiunOSS 

* **全路径名:** [com.qlangtech.tis.plugin.datax.aliyunoss.AliyunOSSTDFSLinker](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-datax-commercial/tis-datax-oss-plugin/src/main/java/com/qlangtech/tis/plugin/datax/aliyunoss/AliyunOSSTDFSLinker.java) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-datax-oss-plugin.tpi](./tpis#tis-datax-oss-plugintpi)

* **配置项说明:** 

1. 远端连接

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. bucket

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：OSS的bucket  

3. rootPath

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：TIS 查找可用资源文件会从该路径下遍历查找 

### com.qlangtech.tis.hive.reader.HiveDFSLinker

* **显示名:** Hive 

* **全路径名:** [com.qlangtech.tis.hive.reader.HiveDFSLinker](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/hive/reader/HiveDFSLinker.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. 远端连接

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. fsName

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：Hadoop hdfs文件系统namenode节点地址。格式：hdfs://ip:端口；例如：hdfs://127.0.0.1:9000

3. 文件格式

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.trigger.util.UnCacheString@7a3c99f1
	* **说明:** 		目前支持三种存储格式：Text：普通文本，一行一条用分隔符分隔，HFile：HBase使用的存储格式，Parquet：最常用的列存格式文件，ORC文件格式

## com.qlangtech.tis.plugin.datax.transformer.UDFDefinition

### com.qlangtech.tis.plugin.datax.transformer.impl.ConcatUDF

* **显示名:** Concat Fields 

* **全路径名:** [com.qlangtech.tis.plugin.datax.transformer.impl.ConcatUDF](https://github.com/qlangtech/plugins/tree/master/tis-transformer/src/main/java/com/qlangtech/tis/plugin/datax/transformer/impl/ConcatUDF.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-transformer.tpi](./tpis#tis-transformertpi)

* **配置项说明:** 

1. from

	* **类型:** 多选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		从下拉列表中选择记录中的某一列，作为需要转换的值来源。
		
		TIS中某些数据端是支持上下文绑定参数，参数以`$`开头，例如，兼容JDBC接口的数据端类型，TIS提供了`$dbName`,`$tableName`,`$timestamp`等上下文绑定参数，以下是绑定参数说明：
		1. `$dbName` ：源端数据库名称
		2. `$tableName`：源端数据库表名称
		3. `$timestamp`：当前系统运行时间戳，类型为：TIMESTAMP（精确到毫秒，该值依赖于运行所在节点的系统时间，请校对正确）
		
		以上`$dbName`，`$tableName`参数 分别对应当前执行数据同步的`数据库`及`数据表`名称，供用户选择，参与当前Transformer算子中作为入参执行计算。

2. 分隔符

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** Empty
	* **说明:** 		选择字段分隔符

3. to

	* **类型:** 多选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		设置合并到的列，有两种执行模式：
		 1. 可以新添加一列: 可以选择 `Virtual Column`，设置新列的名称，并且为新列设置`类型`
		 2. 替换原有记录的值: 可以选择 `Target Column`，从下拉列表中选择原有记录中的某一列作为替换目标

### com.qlangtech.tis.plugin.datax.transformer.impl.CopyValUDF

* **显示名:** Copy Field 

* **全路径名:** [com.qlangtech.tis.plugin.datax.transformer.impl.CopyValUDF](https://github.com/qlangtech/plugins/tree/master/tis-transformer/src/main/java/com/qlangtech/tis/plugin/datax/transformer/impl/CopyValUDF.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-transformer.tpi](./tpis#tis-transformertpi)

* **配置项说明:** 

1. from

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		从下拉列表中选择记录中的某一列，作为需要转换的值来源

2. to

	* **类型:** 多选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		设置拷贝到的列，有两种执行模式：
		1. 可以新添加一列: 可以选择 `Virtual Column`，设置新列的名称，并且为新列设置`类型`
		2. 替换原有记录的值: 可以选择 `Target Column`，从下拉列表中选择原有记录中的某一列作为替换目标

### com.qlangtech.tis.plugin.datax.transformer.impl.DataMaskingUDF

* **显示名:** Data Masking 

* **全路径名:** [com.qlangtech.tis.plugin.datax.transformer.impl.DataMaskingUDF](https://github.com/qlangtech/plugins/tree/master/tis-transformer/src/main/java/com/qlangtech/tis/plugin/datax/transformer/impl/DataMaskingUDF.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-transformer.tpi](./tpis#tis-transformertpi)

* **配置项说明:** 

1. from

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		从下拉列表中选择记录中的某一列，作为需要转换的值来源

2. 开始位置

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 0
	* **说明:** 		设置需要截取字段的开始位置

3. 截取长度

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 9999
	* **说明:** 		设置需要截取字段的长度

4. 替换字符

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** *
	* **说明:** 		用于脱敏替换使用的字符，注意：替换字符只能由长度为1的字符构成

5. to

	* **类型:** 多选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		设置拷贝到的列，有两种执行模式：
		1. 可以新添加一列: 可以选择 `Virtual Column`，设置新列的名称，并且为新列设置`类型`
		2. 替换原有记录的值: 可以选择 `Target Column`，从下拉列表中选择原有记录中的某一列作为替换目标

### com.qlangtech.tis.plugin.datax.transformer.impl.JSONSplitterUDF

* **显示名:** JSON Splitter 

* **全路径名:** [com.qlangtech.tis.plugin.datax.transformer.impl.JSONSplitterUDF](https://github.com/qlangtech/plugins/tree/master/tis-transformer/src/main/java/com/qlangtech/tis/plugin/datax/transformer/impl/JSONSplitterUDF.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-transformer.tpi](./tpis#tis-transformertpi)

* **配置项说明:** 

1. from

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		从下拉列表中选择记录中的某一列，作为需要转换的值来源

2. prefix

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		设置新拆分目标列的前缀，达到方便用户识别和避免与原有记录的列重复的目的

3. to

	* **类型:** 多选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		设置json数据结构中的列名及数据类型

4. skipError

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 		解析json过程中如发生解析错误的情况，是否直接跳过，或抛出异常最终会导致导入程序执行终止

### com.qlangtech.tis.plugin.datax.transformer.impl.SubStrUDF

* **显示名:** SubStr 

* **全路径名:** [com.qlangtech.tis.plugin.datax.transformer.impl.SubStrUDF](https://github.com/qlangtech/plugins/tree/master/tis-transformer/src/main/java/com/qlangtech/tis/plugin/datax/transformer/impl/SubStrUDF.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-transformer.tpi](./tpis#tis-transformertpi)

* **配置项说明:** 

1. from

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		从下拉列表中选择记录中的某一列，作为需要转换的值来源

2. 开始位置

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 0
	* **说明:** 		设置需要截取字段的开始位置

3. 截取长度

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 9999
	* **说明:** 		设置需要截取字段的长度

4. to

	* **类型:** 多选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		设置拷贝到的列，有两种执行模式：
		1. 可以新添加一列: 可以选择 `Virtual Column`，设置新列的名称，并且为新列设置`类型`
		2. 替换原有记录的值: 可以选择 `Target Column`，从下拉列表中选择原有记录中的某一列作为替换目标

## com.qlangtech.tis.plugin.datax.seq.SeqKey

### com.qlangtech.tis.plugin.datax.seq.OffSeqKey

* **显示名:** off 

* **全路径名:** [com.qlangtech.tis.plugin.datax.seq.OffSeqKey](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-doris-plugin/src/main/java/com/qlangtech/tis/plugin/datax/seq/OffSeqKey.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-doris-plugin.tpi](./tpis#tis-datax-doris-plugintpi)

### com.qlangtech.tis.plugin.datax.seq.OnSeqKey

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.seq.OnSeqKey](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-doris-plugin/src/main/java/com/qlangtech/tis/plugin/datax/seq/OnSeqKey.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-doris-plugin.tpi](./tpis#tis-datax-doris-plugintpi)

* **配置项说明:** 

1. seqKey

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

## com.qlangtech.tis.plugins.incr.flink.chunjun.script.ChunjunStreamScriptType

### com.qlangtech.tis.plugins.incr.flink.chunjun.script.ChunjunSqlType

* **显示名:** SQL 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.script.ChunjunSqlType](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-chunjun-base-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/script/ChunjunSqlType.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-chunjun-base-plugin.tpi](./tpis#tis-chunjun-base-plugintpi)

### com.qlangtech.tis.plugins.incr.flink.chunjun.script.StreamApiScript

* **显示名:** StreamAPI 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.script.StreamApiScript](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-chunjun-base-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/script/StreamApiScript.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-chunjun-base-plugin.tpi](./tpis#tis-chunjun-base-plugintpi)

## com.qlangtech.plugins.incr.flink.cdc.mongdb.UpdateRecordComplete

### com.qlangtech.plugins.incr.flink.cdc.mongdb.impl.updatecomplete.FullChangelog

* **显示名:** FULL_CHANGE_LOG 

* **全路径名:** [com.qlangtech.plugins.incr.flink.cdc.mongdb.impl.updatecomplete.FullChangelog](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-mongdb-plugin/src/main/java/com/qlangtech/plugins/incr/flink/cdc/mongdb/impl/updatecomplete/FullChangelog.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-mongdb-plugin.tpi](./tpis#tis-flink-cdc-mongdb-plugintpi)

### com.qlangtech.plugins.incr.flink.cdc.mongdb.impl.updatecomplete.UpdateLookup

* **显示名:** UPDATE_LOOKUP 

* **全路径名:** [com.qlangtech.plugins.incr.flink.cdc.mongdb.impl.updatecomplete.UpdateLookup](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-mongdb-plugin/src/main/java/com/qlangtech/plugins/incr/flink/cdc/mongdb/impl/updatecomplete/UpdateLookup.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-mongdb-plugin.tpi](./tpis#tis-flink-cdc-mongdb-plugintpi)

## com.qlangtech.tis.datax.job.DataXJobWorker

### com.qlangtech.tis.plugin.datax.powerjob.K8SDataXPowerJobJobTemplate

* **显示名:** powerjob-job-tpl 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.K8SDataXPowerJobJobTemplate](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-local-powerjob-executor/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/K8SDataXPowerJobJobTemplate.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-local-powerjob-executor.tpi](./tpis#tis-datax-local-powerjob-executortpi)

* **配置项说明:** 

1. Instance重试数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 0
	* **说明:** 		实例级别，失败了整个任务实例重试，会更换 TaskTracker（本次任务实例的Master节点），代价较大，大型Map/MapReduce慎用

2. 最大实例数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		最大同时执行实例数：该任务允许同时执行的数量，0代表不限（默认为 0），建议使用默认值1，可以保证不会重复触发执行

3. Task重试数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 0
	* **说明:** 		Task 级别，每个子 Task 失败后单独重试，会更换 ProcessorTracker（本次任务实际执行的 Worker 节点），代价较小，推荐使用。

4. 单机线程并发数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2
	* **说明:** 		单机线程并发数：该实例执行过程中每个 Worker 使用的线程数量（MapReduce 任务生效，其余无论填什么，都只会使用必要的线程数...）

5. 任务超时时间

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 0
	* **说明:** 		运行时间限制：限定任务的最大运行时间，超时则视为失败，单位毫秒，0 代表不限制超时时间（不建议不限制超时时间）

6. 最大使用机器数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 3
	* **说明:** 		最大执行机器数量：限定调动执行的机器数量

7. 忽略失败

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		workflow 节点执行过程中，如果失败是否跳过继续执行下游节点？

### com.qlangtech.tis.plugin.datax.powerjob.K8SDataXPowerJobOverwriteTemplate

* **显示名:** powerjob-job-tpl-app-overwrite 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.K8SDataXPowerJobOverwriteTemplate](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-local-powerjob-executor/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/K8SDataXPowerJobOverwriteTemplate.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-local-powerjob-executor.tpi](./tpis#tis-datax-local-powerjob-executortpi)

* **配置项说明:** 

1. 定时执行

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 		数据同步任务可定时执行

2. Instance重试数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 0
	* **说明:** 		实例级别，失败了整个任务实例重试，会更换 TaskTracker（本次任务实例的Master节点），代价较大，大型Map/MapReduce慎用

3. 最大实例数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		最大同时执行实例数：该任务允许同时执行的数量，0代表不限（默认为 0），建议使用默认值1，可以保证不会重复触发执行

4. Task重试数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 0
	* **说明:** 		Task 级别，每个子 Task 失败后单独重试，会更换 ProcessorTracker（本次任务实际执行的 Worker 节点），代价较小，推荐使用。

5. 单机线程并发数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2
	* **说明:** 		单机线程并发数：该实例执行过程中每个 Worker 使用的线程数量（MapReduce 任务生效，其余无论填什么，都只会使用必要的线程数...）

6. 任务超时时间

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 0
	* **说明:** 		运行时间限制：限定任务的最大运行时间，超时则视为失败，单位毫秒，0 代表不限制超时时间（不建议不限制超时时间）

7. 最大使用机器数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 3
	* **说明:** 		最大执行机器数量：限定调动执行的机器数量

8. 忽略失败

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		workflow 节点执行过程中，如果失败是否跳过继续执行下游节点？

### com.qlangtech.tis.plugin.datax.powerjob.K8SDataXPowerJobUsingExistCluster

* **显示名:** powerjob-use-exist-cluster 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.K8SDataXPowerJobUsingExistCluster](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-local-powerjob-executor/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/K8SDataXPowerJobUsingExistCluster.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-local-powerjob-executor.tpi](./tpis#tis-datax-local-powerjob-executortpi)

* **配置项说明:** 

1. 调度中心地址

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		调度中心（powerjob-server）地址列表

2. 宿主应用名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		宿主应用名称，需要提前在控制台完成注册

3. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		宿主应用对应的密码

### com.qlangtech.tis.plugin.datax.powerjob.K8SDataXPowerJobServer

* **显示名:** powerjob-server 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.K8SDataXPowerJobServer](https://github.com/qlangtech/plugins/tree/master/tis-k8s-plugin/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/K8SDataXPowerJobServer.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-k8s-plugin.tpi](./tpis#tis-k8s-plugintpi)

* **配置项说明:** 

1. k8sImage

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** datax-worker
	* **说明:** 		选择一个与该执行器匹配的Docker Image实例

2. 服务暴露

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		Powerjob 启动之后将默认7700端口对外部暴露，可选择K8S相应暴露服务端口方式，如：NodePort，Ingress，LoadBalance

3. 宿主应用名称

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		宿主应用名称，需要提前在控制台完成注册, 必填项，否则启动报错

4. 宿主应用密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		宿主应用密码，需要提前在控制台完成注册, 必填项，否则启动报错

5. coreDS

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** Embedded
	* **说明:** 

		保存Powerjob server元数据的关系型数据库连接配置，目前支持两种方式：
		1. `Embedded`: 由K8S集群启动MySQL类型的Powerjob Server元数据服务，由于容器MySQL持久化存储卷存在丢失风险，请谨慎使用该种方式。
		2. `Customized`: 由用户事先部署的MySQL的数据库服务，提供Powerjob Server元数据服务，因该种数据库服务可提供高可用容灾解决方案（推荐使用）

6. omsProfile

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** OMSProfile
	* **说明:** 		OMS相关配置

### com.qlangtech.tis.plugin.datax.powerjob.K8SDataXPowerJobWorker

* **显示名:** powerjob-worker 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.K8SDataXPowerJobWorker](https://github.com/qlangtech/plugins/tree/master/tis-k8s-plugin/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/K8SDataXPowerJobWorker.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-k8s-plugin.tpi](./tpis#tis-k8s-plugintpi)

* **配置项说明:** 

1. WorkerPort

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 27777
	* **说明:** 		Worker 工作端口

2. 本地存储策略

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** MEMORY
	* **说明:** 

		本地存储策略，枚举值磁盘/内存，大型MapReduce 等会产生大量 Task 的任务推荐使用磁盘降低内存压力，否则建议使用内存加速计算

3. maxResultLength

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 8096
	* **说明:** 		每个Task返回结果的默认长度，超长将被截断，过长可能导致网络拥塞

4. 轻量任务上限

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 50
	* **说明:** 		同时运行的轻量级任务数量上限

5. 重量任务上限

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 12
	* **说明:** 		同时运行的重量级任务数量上限

6. 状态上报间隔

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10
	* **说明:** 		worker 健康状态上报的间隔（秒）

### com.qlangtech.plugins.incr.flink.cluster.FlinkK8SClusterManager

* **显示名:** flink-cluster 

* **全路径名:** [com.qlangtech.plugins.incr.flink.cluster.FlinkK8SClusterManager](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-realtime-flink/src/main/java/com/qlangtech/plugins/incr/flink/cluster/FlinkK8SClusterManager.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-realtime-flink.tpi](./tpis#tis-realtime-flinktpi)

* **配置项说明:** 

1. clusterId

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** tis-flink-cluster-2
	* **说明:** 

		The cluster-id, which should be no more than 45 characters, is used for identifying a unique Flink cluster. The id must only contain lowercase alphanumeric characters and "-". The required format is <code class="highlighter-rouge">[a-z](.)</code>. If not set, the client will automatically generate it with a random ID.

2. k8sImage

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** flink-cluster
	* **说明:** 		选择一个与该执行器匹配的Docker Image实例

3. 服务暴露

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		Flink集群 启动之后将默认8081端口对外部暴露，可选择K8S相应暴露服务端口方式，如：NodePort，Ingress，LoadBalance

4. jmMemory

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1638400
	* **说明:** 

		Total Process Memory size for the JobManager. This includes all the memory that a JobManager JVM process consumes, consisting of Total Flink Memory, JVM Metaspace, and JVM Overhead. In containerized setups, this should be set to the container memory. See also 'jobmanager.memory.flink.size' for Total Flink Memory size configuration.
		
		 单位：`kb`

5. tmMemory

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1769472
	* **说明:** 

		Total Process Memory size for the TaskExecutors. This includes all the memory that a TaskExecutor consumes, consisting of Total Flink Memory, JVM Metaspace, and JVM Overhead. On containerized setups, this should be set to the container memory. See also 'taskmanager.memory.flink.size' for total Flink memory size configuration.
		
		 单位：`kb`

6. tmCPUCores

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 1000
	* **说明:** 

		CPU cores for the TaskExecutors. In case of Yarn setups, this value will be rounded to the closest positive integer. If not explicitly configured, legacy config options 'yarn.containers.vcores' and 'kubernetes.taskmanager.cpu' will be used for Yarn / Kubernetes setups, and 'taskmanager.numberOfTaskSlots' will be used for standalone setups (approximate number of slots).
		
		*1000个单位代表一个1 CPU Core

7. taskSlot

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 

		The number of parallel operator or user function instances that a single TaskManager can run. If this value is larger than 1, a single TaskManager takes multiple instances of a function or operator. That way, the TaskManager can utilize multiple CPU cores, but at the same time, the available memory is divided between the different operator or function instances. This value is typically proportional to the number of physical CPU cores that the TaskManager's machine has (e.g., equal to the number of cores, or half the number of cores).

8. svcAccount

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** default
	* **说明:** 

		Service account that is used by jobmanager and taskmanager within kubernetes cluster. Notice that this can be overwritten by config options 'kubernetes.jobmanager.service-account' and 'kubernetes.taskmanager.service-account' for jobmanager and taskmanager respectively.

9. 授权

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 

		保证Flink 在Kubernetes（Session / Application）模式下拥有执行所有操作都有相应的权限，如不拥有相应权限则会报以下错误：
		```shell script
		io.fabric8.kubernetes.client.KubernetesClientException: pods is forbidden: 
		User "system:serviceaccount:default:default" cannot watch resource "pods" in API group "" in the namespace "default"
		```
		
		如选择：是，执行过程会查看系统是否有 rolebing：tis-flink-manager，如没有，则会在Kubernetes Cluster中执行以下等效语句：
		```shell script
		kubectl  create clusterrolebinding tis-flink-manager --clusterrole=cluster-admin --serviceaccount=default:default
		```

### com.qlangtech.plugins.incr.flink.cluster.KubernetesApplicationClusterConfig

* **显示名:** flink-kubernetes-application-cfg 

* **全路径名:** [com.qlangtech.plugins.incr.flink.cluster.KubernetesApplicationClusterConfig](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-realtime-flink/src/main/java/com/qlangtech/plugins/incr/flink/cluster/KubernetesApplicationClusterConfig.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-realtime-flink.tpi](./tpis#tis-realtime-flinktpi)

* **配置项说明:** 

1. 配置编号

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		可将此配置作为'kubernetes-application'部署配置模版，作为配置标识后续可供其他kubernetes-application部署类型的Flink Job引用

2. k8sImage

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** flink-cluster
	* **说明:** 		选择一个与该执行器匹配的Docker Image实例

3. 服务暴露

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		Flink集群 启动之后将默认8081端口对外部暴露，可选择K8S相应暴露服务端口方式，如：NodePort，Ingress，LoadBalance

4. jmMemory

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1638400
	* **说明:** 

		Total Process Memory size for the JobManager. This includes all the memory that a JobManager JVM process consumes, consisting of Total Flink Memory, JVM Metaspace, and JVM Overhead. In containerized setups, this should be set to the container memory. See also 'jobmanager.memory.flink.size' for Total Flink Memory size configuration.
		
		 单位：`kb`

5. tmMemory

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1769472
	* **说明:** 

		Total Process Memory size for the TaskExecutors. This includes all the memory that a TaskExecutor consumes, consisting of Total Flink Memory, JVM Metaspace, and JVM Overhead. On containerized setups, this should be set to the container memory. See also 'taskmanager.memory.flink.size' for total Flink memory size configuration.
		
		 单位：`kb`

6. tmCPUCores

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 1000
	* **说明:** 

		CPU cores for the TaskExecutors. In case of Yarn setups, this value will be rounded to the closest positive integer. If not explicitly configured, legacy config options 'yarn.containers.vcores' and 'kubernetes.taskmanager.cpu' will be used for Yarn / Kubernetes setups, and 'taskmanager.numberOfTaskSlots' will be used for standalone setups (approximate number of slots).
		
		*1000个单位代表一个1 CPU Core

7. taskSlot

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 

		The number of parallel operator or user function instances that a single TaskManager can run. If this value is larger than 1, a single TaskManager takes multiple instances of a function or operator. That way, the TaskManager can utilize multiple CPU cores, but at the same time, the available memory is divided between the different operator or function instances. This value is typically proportional to the number of physical CPU cores that the TaskManager's machine has (e.g., equal to the number of cores, or half the number of cores).

8. svcAccount

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** default
	* **说明:** 

		Service account that is used by jobmanager and taskmanager within kubernetes cluster. Notice that this can be overwritten by config options 'kubernetes.jobmanager.service-account' and 'kubernetes.taskmanager.service-account' for jobmanager and taskmanager respectively.

9. 授权

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 

		保证Flink 在Kubernetes（Session / Application）模式下拥有执行所有操作都有相应的权限，如不拥有相应权限则会报以下错误：
		```shell script
		io.fabric8.kubernetes.client.KubernetesClientException: pods is forbidden: 
		User "system:serviceaccount:default:default" cannot watch resource "pods" in API group "" in the namespace "default"
		```
		
		如选择：是，执行过程会查看系统是否有 rolebing：tis-flink-manager，如没有，则会在Kubernetes Cluster中执行以下等效语句：
		```shell script
		kubectl  create clusterrolebinding tis-flink-manager --clusterrole=cluster-admin --serviceaccount=default:default
		```

## com.qlangtech.tis.plugin.ds.oracle.Authorized

### com.qlangtech.tis.plugin.ds.oracle.auth.AcceptAuthorized

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.ds.oracle.auth.AcceptAuthorized](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-oracle-plugin/src/main/java/com/qlangtech/tis/plugin/ds/oracle/auth/AcceptAuthorized.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-oracle-plugin.tpi](./tpis#tis-datax-oracle-plugintpi)

* **配置项说明:** 

1. Schema

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		可以只包含某一个模式（Schema）下的表，[Oracle模式对象schema的介绍](https://www.modb.pro/db/508147)
		
		可以不填，但当选中的表在多个授权Schema中出现时，TIS会报异常

2. 去除保留Schema

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 		过滤掉系统保留Schema，如："ANONYMOUS", "APEX_030200", "APEX_PUBLIC_USER", "APPQOSSYS", "BI", "CTXSYS", "DBSNMP", "DIP", "EXFSYS", "FLOWS_FILES", "HR", "IX"等

## com.qlangtech.tis.config.hive.meta.PartitionFilter

### com.qlangtech.tis.hive.reader.impl.DefaultPartitionFilter

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.hive.reader.impl.DefaultPartitionFilter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/hive/reader/impl/DefaultPartitionFilter.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. ptFilter

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.hive.reader.impl.DefaultPartitionFilter.getPtDftVal()
	* **说明:** 

		每次触发全量读取会使用输入项目的表达式对所有分区进行匹配，默认值为 `pt=latest`，假设系统中存在两个分区路径：1. pt=20231111121159 , 2. pt=20231211121159
		
		很明显 `pt=20231211121159` 为最新分区，会作为目标分区进行读取。
		
		用户也可以在输入框中输入 `pt=’20231211121159‘` 强制指定特定分区作为目标分区进行读取。也可以在输入项目中使用过滤条件进行匹配，例如：`pt=’20231211121159‘ and pmod='0'`

2. 路径格式

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** WithoutPtKeys
	* **说明:** 

		支持两种分区路径格式：
		1. `WithoutPtKeys`: 分区路径上`不包含`分区字段名，如：**/user/hive/warehouse/sales_data/2023/1**
		2. `WithPtKeys`:（默认值） 分区路径上`包含`分区字段名，如：**/user/hive/warehouse/sales_data/year=2023/month=1**

### com.qlangtech.tis.hive.reader.impl.NonePartition

* **显示名:** off 

* **全路径名:** [com.qlangtech.tis.hive.reader.impl.NonePartition](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/hive/reader/impl/NonePartition.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

## com.qlangtech.tis.hive.PartitionPathPattern

### com.qlangtech.tis.hive.reader.impl.PartitionPathPatternWithPtKeys

* **显示名:** WithPtKeys 

* **全路径名:** [com.qlangtech.tis.hive.reader.impl.PartitionPathPatternWithPtKeys](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/hive/reader/impl/PartitionPathPatternWithPtKeys.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

### com.qlangtech.tis.hive.reader.impl.PartitionPathPatternWithoutPtKeys

* **显示名:** WithoutPtKeys 

* **全路径名:** [com.qlangtech.tis.hive.reader.impl.PartitionPathPatternWithoutPtKeys](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/hive/reader/impl/PartitionPathPatternWithoutPtKeys.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

## com.qlangtech.tis.plugin.ds.oracle.ConnEntity

### com.qlangtech.tis.plugin.ds.oracle.impl.SIDConnEntity

* **显示名:** SID 

* **全路径名:** [com.qlangtech.tis.plugin.ds.oracle.impl.SIDConnEntity](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-oracle-plugin/src/main/java/com/qlangtech/tis/plugin/ds/oracle/impl/SIDConnEntity.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-oracle-plugin.tpi](./tpis#tis-datax-oracle-plugintpi)

* **配置项说明:** 

1. SID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** xe
	* **说明:** 		无

### com.qlangtech.tis.plugin.ds.oracle.impl.ServiceNameConnEntity

* **显示名:** ServiceName 

* **全路径名:** [com.qlangtech.tis.plugin.ds.oracle.impl.ServiceNameConnEntity](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-oracle-plugin/src/main/java/com/qlangtech/tis/plugin/ds/oracle/impl/ServiceNameConnEntity.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-oracle-plugin.tpi](./tpis#tis-datax-oracle-plugintpi)

* **配置项说明:** 

1. serviceName

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		从 Oracle 8i 开始，Oracle 已经引入了 Service Name 的概念以支持数据库的集群 (RAC) 部署，一个 Service Name 可作为一个数据库的逻辑概念，统一对该数据库不同的 SID 实例的连接。
		
		以服务名方式连接方式 (即 port 和 dbname 中间使用 “ / ” 分隔开)，即：
		
		"jdbc:oracle:thin:@" + hostname + ":" + port + **"/"** + dbname

## com.qlangtech.tis.plugin.ds.DataSourceFactory

### com.qlangtech.tis.plugin.ds.clickhouse.ClickHouseDataSourceFactory

* **显示名:** ClickHouse 

* **全路径名:** [com.qlangtech.tis.plugin.ds.clickhouse.ClickHouseDataSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-clickhouse-plugin/src/main/java/com/qlangtech/tis/plugin/ds/clickhouse/ClickHouseDataSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-clickhouse-plugin.tpi](./tpis#tis-datax-clickhouse-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. host

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		服务器节点连接地址，可以为IP或者域名

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 8123
	* **说明:** 		无

4. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据库名,创建JDBC实例时用

5. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** default
	* **说明:** 		无

6. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

### com.qlangtech.tis.plugin.datax.dameng.ds.DaMengDataSourceFactory

* **显示名:** DaMeng 

* **全路径名:** [com.qlangtech.tis.plugin.datax.dameng.ds.DaMengDataSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dameng-plugin/src/main/java/com/qlangtech/tis/plugin/datax/dameng/ds/DaMengDataSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dameng-plugin.tpi](./tpis#tis-datax-dameng-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. 分库分表

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 		无

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5236
	* **说明:** 		无

4. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据库名,创建JDBC实例时用

5. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** root
	* **说明:** 		无

6. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

7. 附加参数

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		无

### com.qlangtech.tis.plugin.ds.doris.DorisSourceFactory

* **显示名:** Doris 

* **全路径名:** [com.qlangtech.tis.plugin.ds.doris.DorisSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-doris-plugin/src/main/java/com/qlangtech/tis/plugin/ds/doris/DorisSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-doris-plugin.tpi](./tpis#tis-datax-doris-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. host

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		目标数据库的 JDBC 连接信息，用于执行preSql及postSql

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 9030
	* **说明:** 		无

4. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		Doris表的数据库名称

5. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** root
	* **说明:** 		Doris数据库的用户名

6. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		Doris数据库的密码

7. loadUrl

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** []
	* **说明:** 

		Doris FE的地址用于Streamload，可以为多个fe地址，fe_ip:fe_http_port
		样例：
		
		```json
		["172.28.17.100:8030", "172.28.17.100:8030"]
		```

### com.qlangtech.tis.plugin.ds.kingbase.KingBaseDataSourceFactory

* **显示名:** KingBase 

* **全路径名:** [com.qlangtech.tis.plugin.ds.kingbase.KingBaseDataSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-kingbase-plugin/src/main/java/com/qlangtech/tis/plugin/ds/kingbase/KingBaseDataSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-kingbase-plugin.tpi](./tpis#tis-datax-kingbase-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. host

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		服务器节点连接地址，可以为IP或者域名

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

4. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据库名,创建JDBC实例时用

5. schema

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** public
	* **说明:** 		Specify the schema (or several schema separated by commas) to be set in the search-path. This schema will be used to resolve unqualified object names used in statements over this connection.

6. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** root
	* **说明:** 		无

7. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

8. 兼容数据库

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** Postgres
	* **说明:** 		无

9. 读写分离

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 

		支持批量数据同步过程中从从节点读取数据,[KingBase详细说明文档](https://bbs.kingbase.com.cn/docHtml?recId=218c307e5f3d72bf20bb84a51859344a&url=aHR0cHM6Ly9iYnMua2luZ2Jhc2UuY29tLmNuL2tpbmdiYXNlLWRvYy92OS4xLjEuMjQvZmFxL2ZhcS1uZXcvaW50ZXJmYWNlL2pkYmMuaHRtbCNpZDQ)

10. 编码

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据数据

11. 附加参数

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		无

### com.qlangtech.tis.plugin.datax.MariaDBDataSourceFactory

* **显示名:** MariaDB 

* **全路径名:** [com.qlangtech.tis.plugin.datax.MariaDBDataSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax-mariadb-plugin/src/main/java/com/qlangtech/tis/plugin/datax/MariaDBDataSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-mariadb-plugin.tpi](./tpis#tis-datax-mariadb-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. 分库分表

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 

		如数据库中采用分表存放，可以开启此选项，默认为： `off`(不启用)
		
		`on`: 分表策略支持海量数据存放，每张表的数据结构需要保证相同，且有规则的后缀作为物理表的分区规则，逻辑层面视为同一张表。
		如逻辑表`order` 对应的物理分表为：  `order_01`,`order_02`,`order_03`,`order_04`
		
		[详细说明](https://tis.pub/docs/guide/datasource/multi-table-rule/)

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 3306
	* **说明:** 		无

4. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据库名,创建JDBC实例时用

5. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** root
	* **说明:** 		无

6. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

7. 传输压缩

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 

		与服务端通信时采用zlib进行压缩，效果请参考[https://blog.csdn.net/Shadow_Light/article/details/100749537](https://blog.csdn.net/Shadow_Light/article/details/100749537)

8. 附加参数

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		无

### com.qlangtech.tis.plugin.ds.mangodb.MangoDBDataSourceFactory

* **显示名:** MongoDB 

* **全路径名:** [com.qlangtech.tis.plugin.ds.mangodb.MangoDBDataSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-mongodb-plugin/src/main/java/com/qlangtech/tis/plugin/ds/mangodb/MangoDBDataSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-mongodb-plugin.tpi](./tpis#tis-datax-mongodb-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. address

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** host:27017[;host:27017]
	* **说明:** 		MongoDB的数据地址信息，因为MonogDB可能是个集群，则ip端口信息需要以Json数组的形式给出,可填写多个每个address中间可用';'分隔【必填】

3. dbName

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		MongoDB 数据库名称

4. 授权机制

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.ds.mangodb.MangoDBDataSourceFactory.dftAuthMechanism()
	* **说明:** 		the authentication mechanism

5. username

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		MongoDB的用户名。【选填】

6. password

	* **类型:** 密码
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		MongoDB的密码。【选填】

7. userSource

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** admin
	* **说明:** 		保存用户的库

8. 预读记录数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 500
	* **说明:** 		预先读取MongoDB中一定数量的记录，通过反射的方式分析出各字段类型，可以简化MongoDB Schema定义

### com.qlangtech.tis.plugin.datax.odps.OdpsDataSourceFactory

* **显示名:** AliyunODPS 

* **全路径名:** [com.qlangtech.tis.plugin.datax.odps.OdpsDataSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-odps-plugin/src/main/java/com/qlangtech/tis/plugin/datax/odps/OdpsDataSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-odps-plugin.tpi](./tpis#tis-datax-odps-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. odpsServer

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		描述：ODPS的server地址，例如，线上地址为 http://service.odps.aliyun.com/api 
		
		 [具体各地域Endpoint对照表](https://help.aliyun.com/document_detail/34951.html#section-f2d-51y-5db)

3. tunnelServer

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		ODPS的tunnelserver地址，例如，线上地址为 http://dt.odps.aliyun.com
		
		 [具体各地域Endpoint对照表](https://help.aliyun.com/document_detail/34951.html#section-f2d-51y-5db)

4. project

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：ODPS表所属的project，注意:Project只能是字母+数字组合，请填写英文名称。在云端等用户看到的ODPS项目中文名只是显示名，请务必填写底层真实地Project英文标识名。

5. useProjectTimeZone

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 		是否使用MaxCompute项目空间的时区

6. authToken

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		无

### com.qlangtech.tis.plugin.ds.oracle.OracleDataSourceFactory

* **显示名:** Oracle 

* **全路径名:** [com.qlangtech.tis.plugin.ds.oracle.OracleDataSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-oracle-plugin/src/main/java/com/qlangtech/tis/plugin/ds/oracle/OracleDataSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-oracle-plugin.tpi](./tpis#tis-datax-oracle-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. 服务节点

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		服务器节点连接地址，可以为IP或者域名

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1521
	* **说明:** 		无

4. 连接方式

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** SID
	* **说明:** 

		连接方式选择，[Oracle SIDs vs. Oracle SERVICE NAMES](https://www.stechies.com/difference-between-oracle-sids-and-oracle-service-names/)

5. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** system
	* **说明:** 		无

6. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

7. 包含授权

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		Oracle系统会向用户授权其他用户名下的表
		
		* 如选择`on`可以包含系统授权的其他用户名下的表
		
		* 如选择`off`则只包含用户名下的表

8. 所在时区

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.async.message.client.consumer.impl.MQListenerFactory.dftZoneId()
	* **说明:** 		设置Oracle服务端所在时区

### com.qlangtech.tis.plugin.ds.postgresql.PGDataSourceFactory

* **显示名:** PostgreSQL 

* **全路径名:** [com.qlangtech.tis.plugin.ds.postgresql.PGDataSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-postgresql-plugin/src/main/java/com/qlangtech/tis/plugin/ds/postgresql/PGDataSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-postgresql-plugin.tpi](./tpis#tis-datax-postgresql-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. host

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		服务器节点连接地址，可以为IP或者域名

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5432
	* **说明:** 		无

4. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据库名,创建JDBC实例时用

5. schema

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** public
	* **说明:** 		Specify the schema (or several schema separated by commas) to be set in the search-path. This schema will be used to resolve unqualified object names used in statements over this connection.

6. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** root
	* **说明:** 		无

7. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

8. 编码

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据数据

9. 附加参数

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		无

### com.qlangtech.tis.plugin.ds.sqlserver.SqlServer2008DatasourceFactory

* **显示名:** SqlServer-2008 

* **全路径名:** [com.qlangtech.tis.plugin.ds.sqlserver.SqlServer2008DatasourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-sqlserver-v2008-plugin/src/main/java/com/qlangtech/tis/plugin/ds/sqlserver/SqlServer2008DatasourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-sqlserver-v2008-plugin.tpi](./tpis#tis-datax-sqlserver-v2008-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. 分库分表

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 		无

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1433
	* **说明:** 		无

4. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据库名,创建JDBC实例时用

5. schema

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** dbo
	* **说明:** 		Specify the schema (or several schema separated by commas) to be set in the search-path. This schema will be used to resolve unqualified object names used in statements over this connection.

6. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** root
	* **说明:** 		无

7. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

8. 附加参数

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		无

### :closed_lock_with_key:com.qlangtech.tis.plugin.ds.sqlserver.SqlServer2019DatasourceFactory

* **显示名:** SqlServer-2019 

* **全路径名:** [com.qlangtech.tis.plugin.ds.sqlserver.SqlServer2019DatasourceFactory](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-datax-commercial/tis-datax-sqlserver-v2019-plugin/src/main/java/com/qlangtech/tis/plugin/ds/sqlserver/SqlServer2019DatasourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-datax-sqlserver-v2019-plugin.tpi](./tpis#tis-datax-sqlserver-v2019-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. 分库分表

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 		无

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1433
	* **说明:** 		无

4. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据库名,创建JDBC实例时用

5. schema

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** dbo
	* **说明:** 		Specify the schema (or several schema separated by commas) to be set in the search-path. This schema will be used to resolve unqualified object names used in statements over this connection.

6. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** root
	* **说明:** 		无

7. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

8. useSSL

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		支持加密传输

9. 附加参数

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		无

### com.qlangtech.tis.plugin.ds.starrocks.StarRocksSourceFactory

* **显示名:** StarRocks 

* **全路径名:** [com.qlangtech.tis.plugin.ds.starrocks.StarRocksSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-starrocks-plugin/src/main/java/com/qlangtech/tis/plugin/ds/starrocks/StarRocksSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-starrocks-plugin.tpi](./tpis#tis-datax-starrocks-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. host

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		目标数据库的 JDBC 连接信息，用于执行preSql及postSql

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 9030
	* **说明:** 		无

4. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		Doris表的数据库名称

5. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** root
	* **说明:** 		Doris数据库的用户名

6. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		StarRocks数据库的密码

7. loadUrl

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** []
	* **说明:** 

		Doris FE的地址用于Streamload，可以为多个fe地址，fe_ip:fe_http_port
		样例：
		
		```json
		["172.28.17.100:8030", "172.28.17.100:8030"]
		```

### com.qlangtech.tis.plugin.ds.mysql.MySQLV5DataSourceFactory

* **显示名:** MySQL-V5 

* **全路径名:** [com.qlangtech.tis.plugin.ds.mysql.MySQLV5DataSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-ds-mysql-v5-plugin/src/main/java/com/qlangtech/tis/plugin/ds/mysql/MySQLV5DataSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-ds-mysql-v5-plugin.tpi](./tpis#tis-ds-mysql-v5-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. 分库分表

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 

		如数据库中采用分表存放，可以开启此选项，默认为： `off`(不启用)
		
		`on`: 分表策略支持海量数据存放，每张表的数据结构需要保证相同，且有规则的后缀作为物理表的分区规则，逻辑层面视为同一张表。
		如逻辑表`order` 对应的物理分表为：  `order_01`,`order_02`,`order_03`,`order_04`
		
		[详细说明](https://tis.pub/docs/guide/datasource/multi-table-rule/)

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 3306
	* **说明:** 		无

4. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据库名,创建JDBC实例时用

5. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** root
	* **说明:** 		无

6. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

7. 编码

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据数据

8. 传输压缩

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 

		与服务端通信时采用zlib进行压缩，效果请参考[https://blog.csdn.net/Shadow_Light/article/details/100749537](https://blog.csdn.net/Shadow_Light/article/details/100749537)

9. 附加参数

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		无

### :closed_lock_with_key:com.qlangtech.tis.plugin.ds.mysql.MySQLV8DataSourceFactory

* **显示名:** MySQL-V8 

* **全路径名:** [com.qlangtech.tis.plugin.ds.mysql.MySQLV8DataSourceFactory](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-datax-commercial/tis-ds-mysql-v8-plugin/src/main/java/com/qlangtech/tis/plugin/ds/mysql/MySQLV8DataSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-ds-mysql-v8-plugin.tpi](./tpis#tis-ds-mysql-v8-plugintpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. 分库分表

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 

		如数据库中采用分表存放，可以开启此选项，默认为： `off`(不启用)
		
		`on`: 分表策略支持海量数据存放，每张表的数据结构需要保证相同，且有规则的后缀作为物理表的分区规则，逻辑层面视为同一张表。
		如逻辑表`order` 对应的物理分表为：  `order_01`,`order_02`,`order_03`,`order_04`
		
		[详细说明](https://tis.pub/docs/guide/datasource/multi-table-rule/)

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 3306
	* **说明:** 		无

4. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据库名,创建JDBC实例时用

5. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** root
	* **说明:** 		无

6. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

7. 编码

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据数据

8. 传输压缩

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 

		与服务端通信时采用zlib进行压缩，效果请参考[https://blog.csdn.net/Shadow_Light/article/details/100749537](https://blog.csdn.net/Shadow_Light/article/details/100749537)

9. 附加参数

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		无

### com.qlangtech.tis.hive.Hiveserver2DataSourceFactory

* **显示名:** Hiveserver2 

* **全路径名:** [com.qlangtech.tis.hive.Hiveserver2DataSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/hive/Hiveserver2DataSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. metaData

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** HiveMeta
	* **说明:** 		无

3. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** default
	* **说明:** 		Hive 数据库使用的库名，请在执行任务前先创建完成

4. hms

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** HMS
	* **说明:** 		无

## com.qlangtech.tis.plugin.incr.TISSinkFactory

### com.qlangtech.plugins.incr.flink.chunjun.clickhouse.sink.ChunjunClickhouseSinkFactory

* **显示名:** Chunjun-Sink-Clickhouse 

* **全路径名:** [com.qlangtech.plugins.incr.flink.chunjun.clickhouse.sink.ChunjunClickhouseSinkFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-chunjun-clickhouse-plugin/src/main/java/com/qlangtech/plugins/incr/flink/chunjun/clickhouse/sink/ChunjunClickhouseSinkFactory.java) 

* **提供者:** [Chunjun](https://dtstack.github.io/chunjun) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-clickhouse-plugin.tpi](./tpis#tis-flink-chunjun-clickhouse-plugintpi)

* **配置项说明:** 

1. semantic

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** at-least-once
	* **说明:** 

		**描述：** sink 端是否支持二阶段提交
		
		**注意：**
		    如果此参数为空，默认不开启二阶段提交，即 sink 端不支持 exactly_once 语义；
		    当前只支持 exactly-once 和 at-least-once

2. 脚本类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** StreamAPI
	* **说明:** 

		TIS 为您自动生成 Flink Stream 脚本，现支持两种类型脚本：
		
		* `SQL`: **优点**逻辑清晰，便于用户自行修改执行逻辑
		* `Stream API`：**优点**基于系统更底层执行逻辑执行、轻量、高性能

3. batchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5000
	* **说明:** 

		描述：一次性批量提交的记录数大小，该值可以极大减少 ChunJun 与数据库的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成 ChunJun 运行进程 OOM 情况

4. flushIntervalMills

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 		"the flush interval mills, over this time, asynchronous threads will flush data. The default value is 10s.

5. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		sink 并行度

### com.qlangtech.plugins.incr.flink.chunjun.dameng.sink.ChunjunDamengSinkFactory

* **显示名:** Chunjun-Sink-DaMeng 

* **全路径名:** [com.qlangtech.plugins.incr.flink.chunjun.dameng.sink.ChunjunDamengSinkFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-chunjun-dameng-plugin/src/main/java/com/qlangtech/plugins/incr/flink/chunjun/dameng/sink/ChunjunDamengSinkFactory.java) 

* **提供者:** [Chunjun](https://dtstack.github.io/chunjun) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-dameng-plugin.tpi](./tpis#tis-flink-chunjun-dameng-plugintpi)

* **配置项说明:** 

1. semantic

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** at-least-once
	* **说明:** 

		**描述：** sink 端是否支持二阶段提交
		
		**注意：**
		    如果此参数为空，默认不开启二阶段提交，即 sink 端不支持 exactly_once 语义；
		    当前只支持 exactly-once 和 at-least-once

2. 脚本类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** StreamAPI
	* **说明:** 

		TIS 为您自动生成 Flink Stream 脚本，现支持两种类型脚本：
		
		* `SQL`: **优点**逻辑清晰，便于用户自行修改执行逻辑
		* `Stream API`：**优点**基于系统更底层执行逻辑执行、轻量、高性能

3. batchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5000
	* **说明:** 

		描述：一次性批量提交的记录数大小，该值可以极大减少 ChunJun 与数据库的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成 ChunJun 运行进程 OOM 情况

4. flushIntervalMills

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 		"the flush interval mills, over this time, asynchronous threads will flush data. The default value is 10s.

5. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		sink 并行度

### com.qlangtech.plugins.incr.flink.chunjun.doris.sink.ChunjunDorisSinkFactory

* **显示名:** Chunjun-Sink-Doris 

* **全路径名:** [com.qlangtech.plugins.incr.flink.chunjun.doris.sink.ChunjunDorisSinkFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-chunjun-doris-plugin/src/main/java/com/qlangtech/plugins/incr/flink/chunjun/doris/sink/ChunjunDorisSinkFactory.java) 

* **提供者:** [Chunjun](https://dtstack.github.io/chunjun) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-doris-plugin.tpi](./tpis#tis-flink-chunjun-doris-plugintpi)

* **配置项说明:** 

1. semantic

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** at-least-once
	* **说明:** 

		**描述：** sink 端是否支持二阶段提交
		
		**注意：**
		    如果此参数为空，默认不开启二阶段提交，即 sink 端不支持 exactly_once 语义；
		    当前只支持 exactly-once 和 at-least-once

2. 脚本类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** StreamAPI
	* **说明:** 

		TIS 为您自动生成 Flink Stream 脚本，现支持两种类型脚本：
		
		* `SQL`: **优点**逻辑清晰，便于用户自行修改执行逻辑
		* `Stream API`：**优点**基于系统更底层执行逻辑执行、轻量、高性能

3. batchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5000
	* **说明:** 

		描述：一次性批量提交的记录数大小，该值可以极大减少 ChunJun 与数据库的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成 ChunJun 运行进程 OOM 情况

4. flushIntervalMills

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 		"the flush interval mills, over this time, asynchronous threads will flush data. The default value is 10s.

5. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		sink 并行度

6. connectTimeout

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugins.incr.flink.chunjun.doris.sink.ChunjunDorisCommon.dftConnectTimeout()
	* **说明:** 		和服务端建立连接的超时时间，单位：ms

7. socketTimeout

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugins.incr.flink.chunjun.doris.sink.ChunjunDorisCommon.dftSocketTimeout()
	* **说明:** 		从服务端读取数据的超时时间，单位：ms

8. retries

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugins.incr.flink.chunjun.doris.sink.ChunjunDorisCommon.dftRetries()
	* **说明:** 		从服务端读取数据失败最大重试次数

### com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.sink.ChujunKafkaSinkFactory

* **显示名:** Chunjun-Sink-Kafka 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.sink.ChujunKafkaSinkFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-chunjun-kafka-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/kafka/sink/ChujunKafkaSinkFactory.java) 

* **提供者:** [Chunjun](https://dtstack.github.io/chunjun) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-kafka-plugin.tpi](./tpis#tis-flink-chunjun-kafka-plugintpi)

* **配置项说明:** 

1. 传输格式

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** json
	* **说明:** 

		Kafka 传输文本格式 ，参数设置，详细请查看: https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/connectors/table/formats/overview/

2. semantic

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** none
	* **说明:** 

		**描述：** sink 端是否支持二阶段提交
		
		**注意：**
		    如果此参数为空，默认不开启二阶段提交，即 sink 端不支持 exactly_once 语义；
		    当前只支持 exactly-once 和 at-least-once

3. 脚本类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** StreamAPI
	* **说明:** 

		TIS 为您自动生成 Flink Stream 脚本，现支持两种类型脚本：
		
		* `SQL`: **优点**逻辑清晰，便于用户自行修改执行逻辑
		* `Stream API`：**优点**基于系统更底层执行逻辑执行、轻量、高性能

4. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		sink 并行度

### com.qlangtech.tis.plugins.incr.flink.connector.kingbase.sink.KingBaseSinkFactory

* **显示名:** Chunjun-Sink-KingBase 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.connector.kingbase.sink.KingBaseSinkFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-chunjun-kingbase-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/connector/kingbase/sink/KingBaseSinkFactory.java) 

* **提供者:** [Chunjun](https://dtstack.github.io/chunjun) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-kingbase-plugin.tpi](./tpis#tis-flink-chunjun-kingbase-plugintpi)

* **配置项说明:** 

1. semantic

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** at-least-once
	* **说明:** 

		**描述：** sink 端是否支持二阶段提交
		
		**注意：**
		    如果此参数为空，默认不开启二阶段提交，即 sink 端不支持 exactly_once 语义；
		    当前只支持 exactly-once 和 at-least-once

2. 脚本类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** StreamAPI
	* **说明:** 

		TIS 为您自动生成 Flink Stream 脚本，现支持两种类型脚本：
		
		* `SQL`: **优点**逻辑清晰，便于用户自行修改执行逻辑
		* `Stream API`：**优点**基于系统更底层执行逻辑执行、轻量、高性能

3. batchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5000
	* **说明:** 

		描述：一次性批量提交的记录数大小，该值可以极大减少 ChunJun 与数据库的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成 ChunJun 运行进程 OOM 情况

4. flushIntervalMills

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 		"the flush interval mills, over this time, asynchronous threads will flush data. The default value is 10s.

5. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		sink 并行度

### com.qlangtech.tis.plugins.incr.flink.connector.sink.MySQLSinkFactory

* **显示名:** Chunjun-Sink-MySQL 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.connector.sink.MySQLSinkFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-chunjun-mysql-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/connector/sink/MySQLSinkFactory.java) 

* **提供者:** [Chunjun](https://dtstack.github.io/chunjun) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-mysql-plugin.tpi](./tpis#tis-flink-chunjun-mysql-plugintpi)

* **配置项说明:** 

1. semantic

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** at-least-once
	* **说明:** 

		**描述：** sink 端是否支持二阶段提交
		
		**注意：**
		    如果此参数为空，默认不开启二阶段提交，即 sink 端不支持 exactly_once 语义；
		    当前只支持 exactly-once 和 at-least-once

2. 脚本类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** StreamAPI
	* **说明:** 

		TIS 为您自动生成 Flink Stream 脚本，现支持两种类型脚本：
		
		* `SQL`: **优点**逻辑清晰，便于用户自行修改执行逻辑
		* `Stream API`：**优点**基于系统更底层执行逻辑执行、轻量、高性能

3. batchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5000
	* **说明:** 

		描述：一次性批量提交的记录数大小，该值可以极大减少 ChunJun 与数据库的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成 ChunJun 运行进程 OOM 情况

4. flushIntervalMills

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 		"the flush interval mills, over this time, asynchronous threads will flush data. The default value is 10s.

5. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		sink 并行度

### com.qlangtech.tis.plugins.incr.flink.maria.sink.MariaDBSinkFactory

* **显示名:** Chunjun-Sink-MariaDB 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.maria.sink.MariaDBSinkFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-chunjun-mysql-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/maria/sink/MariaDBSinkFactory.java) 

* **提供者:** [Chunjun](https://dtstack.github.io/chunjun) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-mysql-plugin.tpi](./tpis#tis-flink-chunjun-mysql-plugintpi)

* **配置项说明:** 

1. semantic

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** at-least-once
	* **说明:** 

		**描述：** sink 端是否支持二阶段提交
		
		**注意：**
		    如果此参数为空，默认不开启二阶段提交，即 sink 端不支持 exactly_once 语义；
		    当前只支持 exactly-once 和 at-least-once

2. 脚本类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** StreamAPI
	* **说明:** 

		TIS 为您自动生成 Flink Stream 脚本，现支持两种类型脚本：
		
		* `SQL`: **优点**逻辑清晰，便于用户自行修改执行逻辑
		* `Stream API`：**优点**基于系统更底层执行逻辑执行、轻量、高性能

3. batchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5000
	* **说明:** 

		描述：一次性批量提交的记录数大小，该值可以极大减少 ChunJun 与数据库的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成 ChunJun 运行进程 OOM 情况

4. flushIntervalMills

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 		"the flush interval mills, over this time, asynchronous threads will flush data. The default value is 10s.

5. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		sink 并行度

### com.qlangtech.plugins.incr.flink.chunjun.oracle.sink.ChunjunOracleSinkFactory

* **显示名:** Chunjun-Sink-Oracle 

* **全路径名:** [com.qlangtech.plugins.incr.flink.chunjun.oracle.sink.ChunjunOracleSinkFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-chunjun-oracle-plugin/src/main/java/com/qlangtech/plugins/incr/flink/chunjun/oracle/sink/ChunjunOracleSinkFactory.java) 

* **提供者:** [Chunjun](https://dtstack.github.io/chunjun) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-oracle-plugin.tpi](./tpis#tis-flink-chunjun-oracle-plugintpi)

* **配置项说明:** 

1. semantic

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** at-least-once
	* **说明:** 

		**描述：** sink 端是否支持二阶段提交
		
		**注意：**
		    如果此参数为空，默认不开启二阶段提交，即 sink 端不支持 exactly_once 语义；
		    当前只支持 exactly-once 和 at-least-once

2. 脚本类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** StreamAPI
	* **说明:** 

		TIS 为您自动生成 Flink Stream 脚本，现支持两种类型脚本：
		
		* `SQL`: **优点**逻辑清晰，便于用户自行修改执行逻辑
		* `Stream API`：**优点**基于系统更底层执行逻辑执行、轻量、高性能

3. batchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5000
	* **说明:** 

		描述：一次性批量提交的记录数大小，该值可以极大减少 ChunJun 与数据库的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成 ChunJun 运行进程 OOM 情况

4. flushIntervalMills

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 		"the flush interval mills, over this time, asynchronous threads will flush data. The default value is 10s.

5. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		sink 并行度

### com.qlangtech.plugins.incr.flink.chunjun.postgresql.sink.ChunjunPostgreSQLSinkFactory

* **显示名:** Chunjun-Sink-Postgres 

* **全路径名:** [com.qlangtech.plugins.incr.flink.chunjun.postgresql.sink.ChunjunPostgreSQLSinkFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-chunjun-postgresql-plugin/src/main/java/com/qlangtech/plugins/incr/flink/chunjun/postgresql/sink/ChunjunPostgreSQLSinkFactory.java) 

* **提供者:** [Chunjun](https://dtstack.github.io/chunjun) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-postgresql-plugin.tpi](./tpis#tis-flink-chunjun-postgresql-plugintpi)

* **配置项说明:** 

1. semantic

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** at-least-once
	* **说明:** 

		**描述：** sink 端是否支持二阶段提交
		
		**注意：**
		    如果此参数为空，默认不开启二阶段提交，即 sink 端不支持 exactly_once 语义；
		    当前只支持 exactly-once 和 at-least-once

2. 脚本类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** StreamAPI
	* **说明:** 

		TIS 为您自动生成 Flink Stream 脚本，现支持两种类型脚本：
		
		* `SQL`: **优点**逻辑清晰，便于用户自行修改执行逻辑
		* `Stream API`：**优点**基于系统更底层执行逻辑执行、轻量、高性能

3. batchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5000
	* **说明:** 

		描述：一次性批量提交的记录数大小，该值可以极大减少 ChunJun 与数据库的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成 ChunJun 运行进程 OOM 情况

4. flushIntervalMills

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 		"the flush interval mills, over this time, asynchronous threads will flush data. The default value is 10s.

5. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		sink 并行度

### com.qlangtech.tis.plugins.incr.flink.connector.sink.SqlServerSinkFactory

* **显示名:** Chunjun-Sink-SqlServer 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.connector.sink.SqlServerSinkFactory](https://github.com/qlangtech/tis-sqlserver-plugin/tis-flink-chunjun-sqlserver-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/connector/sink/SqlServerSinkFactory.java) 

* **提供者:** [Chunjun](https://dtstack.github.io/chunjun) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-sqlserver-plugin.tpi](./tpis#tis-flink-chunjun-sqlserver-plugintpi)

* **配置项说明:** 

1. semantic

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** at-least-once
	* **说明:** 

		**描述：** sink 端是否支持二阶段提交
		
		**注意：**
		    如果此参数为空，默认不开启二阶段提交，即 sink 端不支持 exactly_once 语义；
		    当前只支持 exactly-once 和 at-least-once

2. 脚本类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** StreamAPI
	* **说明:** 

		TIS 为您自动生成 Flink Stream 脚本，现支持两种类型脚本：
		
		* `SQL`: **优点**逻辑清晰，便于用户自行修改执行逻辑
		* `Stream API`：**优点**基于系统更底层执行逻辑执行、轻量、高性能

3. batchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5000
	* **说明:** 

		描述：一次性批量提交的记录数大小，该值可以极大减少 ChunJun 与数据库的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成 ChunJun 运行进程 OOM 情况

4. flushIntervalMills

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 		"the flush interval mills, over this time, asynchronous threads will flush data. The default value is 10s.

5. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		sink 并行度

### com.qlangtech.tis.plugins.incr.flink.chunjun.starrocks.sink.ChunjunStarRocksSinkFactory

* **显示名:** Chunjun-Sink-StarRocks 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.starrocks.sink.ChunjunStarRocksSinkFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-chunjun-starrocks-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/starrocks/sink/ChunjunStarRocksSinkFactory.java) 

* **提供者:** [Chunjun](https://dtstack.github.io/chunjun) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-starrocks-plugin.tpi](./tpis#tis-flink-chunjun-starrocks-plugintpi)

* **配置项说明:** 

1. semantic

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** at-least-once
	* **说明:** 

		**描述：** sink 端是否支持二阶段提交
		
		**注意：**
		    如果此参数为空，默认不开启二阶段提交，即 sink 端不支持 exactly_once 语义；
		    当前只支持 exactly-once 和 at-least-once

2. 脚本类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** StreamAPI
	* **说明:** 

		TIS 为您自动生成 Flink Stream 脚本，现支持两种类型脚本：
		
		* `SQL`: **优点**逻辑清晰，便于用户自行修改执行逻辑
		* `Stream API`：**优点**基于系统更底层执行逻辑执行、轻量、高性能

3. batchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5000
	* **说明:** 

		描述：一次性批量提交的记录数大小，该值可以极大减少 ChunJun 与数据库的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成 ChunJun 运行进程 OOM 情况

4. flushIntervalMills

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 		"the flush interval mills, over this time, asynchronous threads will flush data. The default value is 10s.

5. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		sink 并行度

### com.qlangtech.tis.plugins.incr.flink.connector.elasticsearch7.ElasticSearchSinkFactory

* **显示名:** Flink-ElasticSearch-Sink 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.connector.elasticsearch7.ElasticSearchSinkFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-sink-elasticsearch7-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/connector/elasticsearch7/ElasticSearchSinkFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-sink-elasticsearch7-plugin.tpi](./tpis#tis-sink-elasticsearch7-plugintpi)

* **配置项说明:** 

1. bulkFlushIntervalMs

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 

		刷新的时间间隔（不论缓存操作的数量或大小如何），默认10秒自动提交一次

2. bulkFlushMaxActions

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		设置使 sink 在接收每个元素之后立即提交，否则这些元素将被缓存起来，官方文档：
		[https://nightlies.apache.org/flink/flink-docs-master/zh/docs/connectors/datastream/elasticsearch/#%e9%85%8d%e7%bd%ae%e5%86%85%e9%83%a8%e6%89%b9%e9%87%8f%e5%a4%84%e7%90%86%e5%99%a8](https://nightlies.apache.org/flink/flink-docs-master/zh/docs/connectors/datastream/elasticsearch/#%e9%85%8d%e7%bd%ae%e5%86%85%e9%83%a8%e6%89%b9%e9%87%8f%e5%a4%84%e7%90%86%e5%99%a8)

3. bulkFlushMaxSizeMb

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		刷新前最大缓存的数据量（以兆字节为单位）

## com.qlangtech.tis.plugin.incr.IncrStreamFactory

### com.qlangtech.plugins.incr.flink.launch.TISFlinkCDCStreamFactory

* **显示名:** Flink 

* **全路径名:** [com.qlangtech.plugins.incr.flink.launch.TISFlinkCDCStreamFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-realtime-flink/src/main/java/com/qlangtech/plugins/incr/flink/launch/TISFlinkCDCStreamFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-realtime-flink.tpi](./tpis#tis-realtime-flinktpi)

* **配置项说明:** 

1. cluster

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** Standalone
	* **说明:** 

		对应Flink的执行任务集群，TIS组装好Flink Job之后，提交任务时会向 Flink Cluster中提交任务。
		
		TIS平台中，提交任务前，请先创建Flink Cluster，其支持三种部署模式：
		
		1. Kubernetes Session: [详细请查看](https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/deployment/resource-providers/native_kubernetes/#session-mode)
		
		   特点是多个Flink Job任务会由同一个Job Manager分配资源调度
		
		2. Kubernetes Application: [详细请查看](https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/deployment/resource-providers/native_kubernetes/#application-mode)
		   [Application Mode Detail](https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/deployment/overview/#application-mode)
		
		   每个Flink Job任务独占一个JobManager ，对于运行在集群中的Job不会有资源抢占问题，
		   >因此对于比较重要且优先级的任务，建议采用这种部署方式
		
		
		3. Standalone: [详细请查看](https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/deployment/resource-providers/standalone/overview/)
		
		   这种部署方式最简单，用户下载TIS 定制过的Flink安装包，解压，修改配置后即可启动运行，因为是单机版的，由于单机slot资源限制只可以部署有限Flink Job任务 [安装说明](https://tis.pub/docs/install/flink-cluster/standalone)

2. 并行度

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 

		任务执行并行度
		
		在 Flink 里面代表每个任务的并行度，适当的提高并行度可以大大提高 job 的执行效率，比如你的 job 消费 kafka 数据过慢，适当调大可能就消费正常了。

3. 重启策略

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 

		The cluster can be started with a default restart strategy which is always used when no job specific restart strategy has been defined. In case that the job is submitted with a restart strategy, this strategy overrides the cluster’s default setting.
		
		Detailed description:[restart-strategies](https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/task_failure_recovery/#restart-strategies)
		
		There are 4 types of restart-strategy:
		
		1. `off`: No restart strategy.
		2. `fixed-delay`: Fixed delay restart strategy. More details can be found [here](https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/task_failure_recovery/#fixed-delay-restart-strategy).
		3. `failure-rate`: Failure rate restart strategy. More details can be found [here](https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/task_failure_recovery#failure-rate-restart-strategy).
		4. `exponential-delay`: Exponential delay restart strategy. More details can be found [here](https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/task_failure_recovery#exponential-delay-restart-strategy).

4. 支持意外恢复

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 

		支持任务恢复，当Flink节点因为服务器意外宕机导致当前运行的flink job意外终止，需要支持Flink Job恢复执行，
		
		需要Flink配置支持：
		
		1. 持久化stateBackend
		2. 开启checkpoint

5. checkpoint

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 

		Checkpoints make state in Flink fault tolerant by allowing state and the corresponding stream positions to be recovered, thereby giving the application the same semantics as a failure-free execution.
		
		Detailed description:
		1. [https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/checkpoints/](https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/checkpoints/)
		2. [https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/fault-tolerance/checkpointing/](https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/fault-tolerance/checkpointing/)

6. stateBackend

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** FSState
	* **说明:** 

		Flink provides different state backends that specify how and where state is stored.
		
		State can be located on Java’s heap or off-heap. Depending on your state backend, Flink can also manage the state for the application, meaning Flink deals with the memory management (possibly spilling to disk if necessary) to allow applications to hold very large state. By default, the configuration file flink-conf.yaml determines the state backend for all Flink jobs.
		
		However, the default state backend can be overridden on a per-job basis, as shown below.
		
		For more information about the available state backends, their advantages, limitations, and configuration parameters see the corresponding section in [Deployment & Operations](https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/state_backends/).

## com.qlangtech.tis.datax.impl.DataxWriter

### com.qlangtech.tis.plugin.datax.DataXClickhouseWriter

* **显示名:** ClickHouse 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXClickhouseWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-clickhouse-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXClickhouseWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-clickhouse-plugin.tpi](./tpis#tis-datax-clickhouse-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. preSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 `@table` 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, ... datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：`"preSql":["delete from 表名"]`，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称

3. postSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ）

4. batchByteSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 13421772
	* **说明:** 		无

5. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		在开始执行DataX任务前，自动在目标数据库中创建表，目标表Engine类型为'CollapsingMergeTree' 构建原理请参考[MySQL到ClickHouse实时同步](https://www.askcug.com/topic/76/mysql%E5%88%B0clickhouse%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5-cloudcanal%E5%AE%9E%E6%88%98)

6. batchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 2048
	* **说明:** 

		* 描述：一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。

7. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXClickhouseWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.dameng.writer.DataXDaMengWriter

* **显示名:** DaMeng 

* **全路径名:** [com.qlangtech.tis.plugin.datax.dameng.writer.DataXDaMengWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dameng-plugin/src/main/java/com/qlangtech/tis/plugin/datax/dameng/writer/DataXDaMengWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dameng-plugin.tpi](./tpis#tis-datax-dameng-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. preSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 `@table` 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, ... datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：`"preSql":["delete from 表名"]`，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称

3. postSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ）

4. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		解析Reader的元数据，自动生成Writer create table DDL语句，有三种选择：
		* `off`：关闭自动生成及同步目标端建表DDL语句，当目标端表实例已经存在可选择此选项。
		* `default`：打开动生成及自动执行目标端建表DDL语句，执行任务状态由程序自动控制毋需人为干涉。
		* `customized`：用户可自定义设置`自动执行目标端建表DDL语句逻辑`，如：是否需要生成列注释等。

5. batchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 1000
	* **说明:** 

		* 描述：一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。

6. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.dameng.writer.DataXDaMengWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXDFSWriter

* **显示名:** TDFS 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXDFSWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dfs-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXDFSWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dfs-plugin.tpi](./tpis#tis-datax-dfs-plugintpi)

* **配置项说明:** 

1. 资源

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		DFS服务端连接配置

2. 添加元数据

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		写数据过程中会在`DFS`目录中写一份source的元数据。
		
		 当其他环境中需要使用TIS来导入DFS中的数据时，可以利用这份元数据快速生成目标端的数据表结构，省去手动配置元数据的流程。

3. 替换规则

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** truncate
	* **说明:** 

		FtpWriter写入前数据清理处理模式： 
		
		 1. **truncate**:  写入前清理目录下一fileName前缀的所有文件。
		
		 2. **append**: 写入前不做任何处理，DFS Writer直接使用filename写入，并保证文件名不冲突。
		
		 3. **nonConflict**: 如果目录下有fileName前缀的文件，直接报错。

4. fileFormat

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** TEXT
	* **说明:** 

		文件写出的格式，包括[csv](http://zh.wikipedia.org/wiki/%E9%80%97%E5%8F%B7%E5%88%86%E9%9A%94%E5%80%BC) 和**text**两种，**csv**是严格的**csv**格式，如果待写数据包括列分隔符，则会按照**csv**的转义语法转义，转义符号为双引号。**text**格式是用列分隔符简单分割待写数据，对于待写数据包括列分隔符情况下不做转义。

5. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXDFSWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.doris.DataXDorisWriter

* **显示名:** Doris 

* **全路径名:** [com.qlangtech.tis.plugin.datax.doris.DataXDorisWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-doris-plugin/src/main/java/com/qlangtech/tis/plugin/datax/doris/DataXDorisWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-doris-plugin.tpi](./tpis#tis-datax-doris-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. preSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 `@table` 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, ... datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：`"preSql":["delete from 表名"]`，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称

3. postSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ）

4. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		解析Reader的元数据，自动生成Writer create table DDL语句，有三种选择：
		* `off`：关闭自动生成及同步目标端建表DDL语句，当目标端表实例已经存在可选择此选项。
		* `default`：打开动生成及自动执行目标端建表DDL语句，执行任务状态由程序自动控制毋需人为干涉。
		* `customized`：用户可自定义设置`自动执行目标端建表DDL语句逻辑`，如：是否需要生成列注释等。

5. loadProps

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.doris.DataXDorisWriter.getDftLoadProps()
	* **说明:** 

		StreamLoad 的请求参数,默认传入的数据均会被转为字符串，并以 **\t** 作为列分隔符，**\n** 作为行分隔符，组成csv文件进行 [StreamLoad导入参数说明](http://doris.apache.org/master/zh-CN/administrator-guide/load-data/stream-load-manual.html#%E5%AF%BC%E5%85%A5%E4%BB%BB%E5%8A%A1%E5%8F%82%E6%95%B0)。 如需更改列分隔符， 则正确配置 loadProps 即可：
		
		```json
		 {
		  "column_separator": "\\x01",
		  "line_delimiter": "\\x02"
		}
		```

6. maxBatchRows

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 10000
	* **说明:** 

		- 描述：单次StreamLoad导入的最大行数
		- 必选：否
		- 默认值：10000 (1W)

7. maxBatchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 104857600
	* **说明:** 

		- 描述：单次StreamLoad导入的最大字节数。
		- 必选：否
		- 默认值：104857600 (100M)

8. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.doris.DataXDorisWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXElasticsearchWriter

* **显示名:** Elasticsearch 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXElasticsearchWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-elasticsearch-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXElasticsearchWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-elasticsearch-plugin.tpi](./tpis#tis-datax-elasticsearch-plugintpi)

* **配置项说明:** 

1. endpoint

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		ElasticSearch的连接地址

2. index

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.trigger.util.UnCacheString@7c206b14
	* **说明:** 		Elasticsearch中的index名

3. cleanup

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 		是否删除原表

4. batchSize

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 1000
	* **说明:** 		每次批量数据的条数

5. trySize

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 1
	* **说明:** 		失败后重试的次数

6. timeout

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 600000
	* **说明:** 		客户端超时时间

7. discovery

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 		启用节点发现将(轮询)并定期更新客户机中的服务器列表

8. compression

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** true
	* **说明:** 		http请求，开启压缩

9. multiThread

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** true
	* **说明:** 		http请求，是否有多线程

10. 忽略错误

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 		忽略写入错误，不重试，继续写入

11. ignoreParseError

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** true
	* **说明:** 		忽略解析数据格式错误，继续写入

12. alias

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		数据导入完成后写入别名

13. aliasMode

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** append
	* **说明:** 		数据导入完成后增加别名的模式，append(增加模式), exclusive(只留这一个)

14. settings

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** {"index" :{"number_of_shards": 1, "number_of_replicas": 0}}
	* **说明:** 

		创建index时候的settings, 与elasticsearch官方相同，详细配置请参考：[index-modules-settings](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html#index-modules-settings)

15. splitter

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** ,
	* **说明:** 		如果插入数据是array，就使用指定分隔符

16. dynamic

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 		不使用datax的mappings，使用es自己的自动mappings

17. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXElasticsearchWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugins.datax.kafka.writer.DataXKafkaWriter

* **显示名:** Kafka 

* **全路径名:** [com.qlangtech.tis.plugins.datax.kafka.writer.DataXKafkaWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-kafka-plugin/src/main/java/com/qlangtech/tis/plugins/datax/kafka/writer/DataXKafkaWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-kafka-plugin.tpi](./tpis#tis-datax-kafka-plugintpi)

* **配置项说明:** 

1. Bootstrap Servers

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		A list of host/port pairs to use for establishing the initial connection to the Kafka cluster. The client will make use of all servers irrespective of which servers are specified here for bootstrapping&mdash;this list only impacts the initial hosts used to discover the full set of servers. This list should be in the form <code>host1:port1,host2:port2,...</code>. Since these servers are just used for the initial connection to discover the full cluster membership (which may change dynamically), this list need not contain the full set of servers (you may want more than one, though, in case a server is down).

2. Topic

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		Topic pattern in which the records will be sent.  '{stream}' to send the message to a specific topic based on these values. Notice that the topic name will be transformed to a standard naming convention.

3. Test Topic

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		Topic to test if can produce messages.

4. Delivery Timeout

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 120000
	* **说明:** 		An upper bound on the time to report success or failure after a call to 'send()' returns.

5. Protocol

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** PLAINTEXT
	* **说明:** 		Protocol used to communicate with brokers.

6. ACKs

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 

		The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the  durability of records that are sent.
		
		**all**: 这意味着leader需要等待所有备份都成功写入日志，这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的保证

7. Compression Type

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** none
	* **说明:** 		The compression type for all data generated by the producer.

8. Send Buffer bytes

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 131072
	* **说明:** 		The size of the TCP send buffer (SO_SNDBUF) to use when sending data. If the value is -1, the OS default will be used.

9. Client DNS Lookup

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** use_all_dns_ips
	* **说明:** 		Controls how the client uses DNS lookups. If set to use_all_dns_ips, connect to each returned IP address in sequence until a successful connection is established. After a disconnection, the next IP is used. Once all IPs have been used once, the client resolves the IP(s) from the hostname again. If set to resolve_canonical_bootstrap_servers_only, resolve each bootstrap address into a list of canonical names. After the bootstrap phase, this behaves the same as use_all_dns_ips. If set to default (deprecated), attempt to connect to the first IP address returned by the lookup, even if the lookup returns multiple IP addresses.

10. Request Timeout

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 30000
	* **说明:** 		The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted.

11. Batch Size

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 16384
	* **说明:** 

		The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition.
		
		控制发送者在发布到kafka之前等待批处理的字节数。满足batch.size和ling.ms之一，producer便开始发送消息

12. Linger ms

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 0
	* **说明:** 		The producer groups together any records that arrive in between request transmissions into a single batched request.

13. Client ID

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		An ID string to pass to the server when making requests. The purpose of this is to be able to track the source of requests beyond just ip/port by allowing a logical application name to be included in server-side request logging.

14. Max Request Size

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1048576
	* **说明:** 		The maximum size of a request in bytes.

15. Enable Idempotence

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		When set to 'true', the producer will ensure that exactly one copy of each message is written in the stream. If 'false', producer retries due to broker failures, etc., may write duplicates of the retried message in the stream.

16. Max in Flight Requests per Connection

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5
	* **说明:** 		The maximum number of unacknowledged requests the client will send on a single connection before blocking. Can be greater than 1, and the maximum value supported with idempotency is 5.

17. Retries

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 100
	* **说明:** 		Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially transient error.

18. Socket Connection Setup Timeout

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 		The amount of time the client will wait for the socket connection to be established.

19. Socket Connection Setup Max Timeout

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 30000
	* **说明:** 		The maximum amount of time the client will wait for the socket connection to be established. The connection setup timeout will increase exponentially for each consecutive connection failure up to this maximum.

20. Buffer Memory

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 33554432
	* **说明:** 		The total bytes of memory the producer can use to buffer records waiting to be sent to the server.

21. Max Block ms

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 60000
	* **说明:** 		The configuration controls how long the KafkaProducer's send(), partitionsFor(), initTransactions(), sendOffsetsToTransaction(), commitTransaction() and abortTransaction() methods will block.

22. Sync Producer

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 		Wait synchronously until the record has been sent to Kafka.

23. Receive Buffer bytes

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 32768
	* **说明:** 		The size of the TCP receive buffer (SO_RCVBUF) to use when reading data. If the value is -1, the OS default will be used.

### com.qlangtech.tis.plugin.datax.kingbase.DataXKingBaseWriter

* **显示名:** KingBase 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kingbase.DataXKingBaseWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-kingbase-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kingbase/DataXKingBaseWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-kingbase-plugin.tpi](./tpis#tis-datax-kingbase-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. preSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 `@table` 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, ... datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：`"preSql":["delete from 表名"]`，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称

3. postSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ）

4. batchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 1000
	* **说明:** 

		* 描述：一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。

5. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXPostgresqlWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXMariaWriter

* **显示名:** MariaDB 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXMariaWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax-mariadb-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXMariaWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-mariadb-plugin.tpi](./tpis#tis-datax-mariadb-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. writeMode

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** replace
	* **说明:** 

		控制写入数据到目标表采用 `insert into` 或者 `replace into` 或者 `ON DUPLICATE KEY UPDATE` 语句

3. preSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 `@table` 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, ... datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：`"preSql":["delete from 表名"]`，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称

4. postSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ）

5. session

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		DataX在获取Mysql连接时，执行session指定的SQL语句，修改当前connection session属性 

6. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		解析Reader的元数据，自动生成Writer create table DDL语句，有三种选择：
		* `off`：关闭自动生成及同步目标端建表DDL语句，当目标端表实例已经存在可选择此选项。
		* `default`：打开动生成及自动执行目标端建表DDL语句，执行任务状态由程序自动控制毋需人为干涉。
		* `customized`：用户可自定义设置`自动执行目标端建表DDL语句逻辑`，如：是否需要生成列注释等。

7. batchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 1000
	* **说明:** 

		* 描述：一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。

8. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataxMySQLWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXMongodbWriter

* **显示名:** MongoDB 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXMongodbWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-mongodb-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXMongodbWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-mongodb-plugin.tpi](./tpis#tis-datax-mongodb-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXMongodbWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXOdpsWriter

* **显示名:** Aliyun-ODPS 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXOdpsWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-odps-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXOdpsWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-odps-plugin.tpi](./tpis#tis-datax-odps-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. truncate

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 		描述：ODPSWriter通过配置"truncate": true，保证写入的幂等性，即当出现写入失败再次运行时，ODPSWriter将清理前述数据，并导入新数据，这样可以保证每次重跑之后的数据都保持一致。 

3. 生命周期

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 3
	* **说明:** 

		表的生命周期，仅支持正整数。单位：天
		
		* `非分区表`：自最后一次修改表数据开始计算，经过days天后数据无改动，则您无需干预此表，MaxCompute会自动回收（类似drop table操作）。
		* `分区表`：系统根据各分区的LastModifiedTime判断是否需要回收分区。不同于非分区表，分区表的最后一个分区被回收后，该表不会被删除。生命周期只能设定到表级别，不支持在分区级别设置生命周期。

4. partitionFormat

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** yyyyMMddHHmmss
	* **说明:** 		每进行一次DataX导入在Hive表中会生成一个新的分区，现在系统分区名称为'pt'格式为开始导入数据的时间戳，格式为'yyyyMMddHHmmss'或者'yyyyMMdd' 

5. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		解析Reader的元数据，自动生成Writer create table DDL语句，有三种选择：
		* `off`：关闭自动生成及同步目标端建表DDL语句，当目标端表实例已经存在可选择此选项。
		* `default`：打开动生成及自动执行目标端建表DDL语句，执行任务状态由程序自动控制毋需人为干涉。
		* `customized`：用户可自定义设置`自动执行目标端建表DDL语句逻辑`，如：是否需要生成列注释等。

6. batchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 1000
	* **说明:** 

		* 描述：一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。

7. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXOdpsWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXOracleWriter

* **显示名:** Oracle 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXOracleWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-oracle-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXOracleWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-oracle-plugin.tpi](./tpis#tis-datax-oracle-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. preSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 `@table` 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, ... datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：`"preSql":["delete from 表名"]`，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称

3. postSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ）

4. session

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		DataX在获取Mysql连接时，执行session指定的SQL语句，修改当前connection session属性 

5. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		解析Reader的元数据，自动生成Writer create table DDL语句，有三种选择：
		* `off`：关闭自动生成及同步目标端建表DDL语句，当目标端表实例已经存在可选择此选项。
		* `default`：打开动生成及自动执行目标端建表DDL语句，执行任务状态由程序自动控制毋需人为干涉。
		* `customized`：用户可自定义设置`自动执行目标端建表DDL语句逻辑`，如：是否需要生成列注释等。

6. batchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 1000
	* **说明:** 

		* 描述：一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。

7. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXOracleWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXPostgresqlWriter

* **显示名:** PostgreSQL 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXPostgresqlWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-postgresql-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXPostgresqlWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-postgresql-plugin.tpi](./tpis#tis-datax-postgresql-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. preSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 `@table` 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, ... datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：`"preSql":["delete from 表名"]`，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称

3. postSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ）

4. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		解析Reader的元数据，自动生成Writer create table DDL语句，有三种选择：
		* `off`：关闭自动生成及同步目标端建表DDL语句，当目标端表实例已经存在可选择此选项。
		* `default`：打开动生成及自动执行目标端建表DDL语句，执行任务状态由程序自动控制毋需人为干涉。
		* `customized`：用户可自定义设置`自动执行目标端建表DDL语句逻辑`，如：是否需要生成列注释等。

5. batchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 1000
	* **说明:** 

		* 描述：一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。

6. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXPostgresqlWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXSqlserverWriter

* **显示名:** SqlServer 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXSqlserverWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-sqlserver-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXSqlserverWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-sqlserver-plugin.tpi](./tpis#tis-datax-sqlserver-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. preSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 `@table` 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, ... datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：`"preSql":["delete from 表名"]`，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称

3. postSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ）

4. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		解析Reader的元数据，自动生成Writer create table DDL语句，有三种选择：
		* `off`：关闭自动生成及同步目标端建表DDL语句，当目标端表实例已经存在可选择此选项。
		* `default`：打开动生成及自动执行目标端建表DDL语句，执行任务状态由程序自动控制毋需人为干涉。
		* `customized`：用户可自定义设置`自动执行目标端建表DDL语句逻辑`，如：是否需要生成列注释等。

5. batchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 1000
	* **说明:** 

		* 描述：一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。

6. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXSqlserverWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.starrocks.DataXStarRocksWriter

* **显示名:** StarRocks 

* **全路径名:** [com.qlangtech.tis.plugin.datax.starrocks.DataXStarRocksWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-starrocks-plugin/src/main/java/com/qlangtech/tis/plugin/datax/starrocks/DataXStarRocksWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-starrocks-plugin.tpi](./tpis#tis-datax-starrocks-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. preSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 `@table` 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, ... datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：`"preSql":["delete from 表名"]`，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称

3. postSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ）

4. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		解析Reader的元数据，自动生成Writer create table DDL语句，有三种选择：
		* `off`：关闭自动生成及同步目标端建表DDL语句，当目标端表实例已经存在可选择此选项。
		* `default`：打开动生成及自动执行目标端建表DDL语句，执行任务状态由程序自动控制毋需人为干涉。
		* `customized`：用户可自定义设置`自动执行目标端建表DDL语句逻辑`，如：是否需要生成列注释等。

5. loadProps

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.starrocks.DataXStarRocksWriter.getDftLoadProps()
	* **说明:** 

		StreamLoad 的请求参数，默认传入的数据均会被转为字符串，并以 **\t** 作为列分隔符，**\n** 作为行分隔符，组成csv文件进行 [StreamLoad导入参数说明](https://docs.starrocks.io/zh-cn/latest/loading/stream_load_transaction_interface)。 如需更改列分隔符， 则正确配置 loadProps 即可：
		
		```json
		 {
		    "column_separator": "\\x01",
		    "row_delimiter": "\\x02"
		}
		```

6. maxBatchRows

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 10000
	* **说明:** 

		- 描述：单次StreamLoad导入的最大行数
		- 必选：否
		- 默认值：10000 (1W)

7. maxBatchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 104857600
	* **说明:** 

		- 描述：单次StreamLoad导入的最大字节数。
		- 必选：否
		- 默认值：104857600 (100M)

8. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.starrocks.DataXStarRocksWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataxMySQLWriter

* **显示名:** MySQL 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataxMySQLWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-ds-mysql-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataxMySQLWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-ds-mysql-plugin.tpi](./tpis#tis-ds-mysql-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. writeMode

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** replace
	* **说明:** 

		控制写入数据到目标表采用 `insert into` 或者 `replace into` 或者 `ON DUPLICATE KEY UPDATE` 语句

3. preSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 `@table` 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, ... datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：`"preSql":["delete from 表名"]`，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称

4. postSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ）

5. session

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		DataX在获取Mysql连接时，执行session指定的SQL语句，修改当前connection session属性 

6. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		解析Reader的元数据，自动生成Writer create table DDL语句，有三种选择：
		* `off`：关闭自动生成及同步目标端建表DDL语句，当目标端表实例已经存在可选择此选项。
		* `default`：打开动生成及自动执行目标端建表DDL语句，执行任务状态由程序自动控制毋需人为干涉。
		* `customized`：用户可自定义设置`自动执行目标端建表DDL语句逻辑`，如：是否需要生成列注释等。

7. batchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 1000
	* **说明:** 

		* 描述：一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。

8. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataxMySQLWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXHiveWriter

* **显示名:** Hive 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXHiveWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXHiveWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. hiveserver2

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. 分区时间戳格式

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** yyyyMMddHHmmss
	* **说明:** 

		每进行一次DataX导入在Hive表中会生成一个新的分区，现在系统分区名称为'pt'格式为开始导入数据的当前时间戳，格式为`yyyyMMddHHmmss`或者`yyyyMMdd`

3. fsName

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：Hadoop hdfs文件系统namenode节点地址。格式：hdfs://ip:端口；例如：hdfs://127.0.0.1:9000

4. 分区保留数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2
	* **说明:** 

		每进行一次DataX导入在Hive表中会生成一个新的分区，现在系统分区名称为`pt`格式为开始导入数据的时间戳

5. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		解析Reader的元数据，自动生成Writer create table DDL语句

6. fileType

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** TEXT
	* **说明:** 		描述：文件的类型，目前只支持用户配置为"text"

7. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXHiveWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

8. writeMode

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** append
	* **说明:** 

		hdfswriter写入前数据清理处理模式：
		
		- **append**: 写入前不做任何处理，DataX hdfswriter直接使用filename写入，并保证文件名不冲突，
		- **nonConflict**：如果目录下有fileName前缀的文件，直接报错

9. encoding

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** utf-8
	* **说明:** 		描述：写文件的编码配置。

### com.qlangtech.tis.plugin.datax.DataXSparkWriter

* **显示名:** Spark 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXSparkWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXSparkWriter.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. hiveserver2

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. 分区时间戳格式

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** yyyyMMddHHmmss
	* **说明:** 

		每进行一次DataX导入在Hive表中会生成一个新的分区，现在系统分区名称为'pt'格式为开始导入数据的当前时间戳，格式为`yyyyMMddHHmmss`或者`yyyyMMdd`

3. fsName

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：Hadoop hdfs文件系统namenode节点地址。格式：hdfs://ip:端口；例如：hdfs://127.0.0.1:9000

4. 分区保留数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2
	* **说明:** 

		每进行一次DataX导入在Hive表中会生成一个新的分区，现在系统分区名称为`pt`格式为开始导入数据的时间戳

5. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		解析Reader的元数据，自动生成Writer create table DDL语句

6. fileType

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** TEXT
	* **说明:** 		描述：文件的类型，目前只支持用户配置为"text"

7. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXHiveWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

8. writeMode

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** append
	* **说明:** 

		hdfswriter写入前数据清理处理模式：
		
		- **append**: 写入前不做任何处理，DataX hdfswriter直接使用filename写入，并保证文件名不冲突，
		- **nonConflict**：如果目录下有fileName前缀的文件，直接报错

9. encoding

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** utf-8
	* **说明:** 		描述：写文件的编码配置。

## com.qlangtech.tis.config.spark.SparkConnStrategy

### com.qlangtech.tis.config.spark.impl.StandaloneConnStrategy

* **显示名:** Standalone 

* **全路径名:** [com.qlangtech.tis.config.spark.impl.StandaloneConnStrategy](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/config/spark/impl/StandaloneConnStrategy.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. master

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

### com.qlangtech.tis.config.spark.impl.YarnConnStrategy

* **显示名:** Yarn 

* **全路径名:** [com.qlangtech.tis.config.spark.impl.YarnConnStrategy](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/config/spark/impl/YarnConnStrategy.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. yarnSite

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.config.spark.impl.YarnConnStrategy.dftYarnSiteContent()
	* **说明:** 

		```xml
		<?xml version="1.0"?>
		<configuration>
		 <!-- Site specific YARN configuration properties -->
		  <!--RM的主机名 -->
		  <property>
		    <name>yarn.resourcemanager.hostname</name>
		    <value>192.168.28.200</value>
		  </property>
		
		  <!--RM对客户端暴露的地址,客户端通过该地址向RM提交应用程序、杀死应用程序等-->
		  <property>
		    <name>yarn.resourcemanager.address</name>
		    <value>${yarn.resourcemanager.hostname}:8032</value>
		  </property>
		
		  <!--RM对AM暴露的访问地址,AM通过该地址向RM申请资源、释放资源等-->
		  <property>
		    <name>yarn.resourcemanager.scheduler.address</name>
		    <value>${yarn.resourcemanager.hostname}:8030</value>
		  </property>
		
		  <!--RM对外暴露的web http地址,用户可通过该地址在浏览器中查看集群信息-->
		  <property>
		    <name>yarn.resourcemanager.webapp.address</name>
		    <value>${yarn.resourcemanager.hostname}:8088</value>
		  </property>
		
		  <!--RM对NM暴露地址,NM通过该地址向RM汇报心跳、领取任务等-->
		  <property>
		    <name>yarn.resourcemanager.resource-tracker.address</name>
		    <value>${yarn.resourcemanager.hostname}:8031</value>
		  </property>
		
		  <!--RM对管理员暴露的访问地址,管理员通过该地址向RM发送管理命令等-->
		  <property>
		    <name>yarn.resourcemanager.admin.address</name>
		    <value>${yarn.resourcemanager.hostname}:8033</value>
		  </property>
		</configuration>
		```

## com.qlangtech.tis.plugin.MemorySpecification

### :closed_lock_with_key:com.qlangtech.tis.plugin.memory.CustomizeMemorySpecification

* **显示名:** customize 

* **全路径名:** [com.qlangtech.tis.plugin.memory.CustomizeMemorySpecification](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-datax-commercial/tis-datax-common-commercial-plugin/src/main/java/com/qlangtech/tis/plugin/memory/CustomizeMemorySpecification.java) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-datax-common-commercial-plugin.tpi](./tpis#tis-datax-common-commercial-plugintpi)

* **配置项说明:** 

1. request

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.memory.CustomizeMemorySpecification.dftMemory()
	* **说明:** 		单个DataX任务内存初始申请，单位：兆。当任务并发数目设置为：n，内存总体初始开销为'n*memoryRequest'，注意防止执行节点OOM

2. limit

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.memory.CustomizeMemorySpecification.dftMemory()
	* **说明:** 		单个DataX任务内存最大极限申请，单位：兆。当任务并发数目设置为：n，内存总体最大极限开销为'n*memoryLimit'，注意防止执行节点OOM

## com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.format.FormatFactory

### com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.format.canaljson.TISCanalJsonFormatFactory

* **显示名:** canal-json 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.format.canaljson.TISCanalJsonFormatFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-msg-format-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/kafka/format/canaljson/TISCanalJsonFormatFactory.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-msg-format-plugin.tpi](./tpis#tis-flink-msg-format-plugintpi)

* **配置项说明:** 

1. ignoreParseErrors

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to skip fields and rows with parse errors instead of failing;
		fields are set to null in case of errors, false by default.

2. timestampFormat

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** SQL
	* **说明:** 

		Optional flag to specify timestamp format, SQL by default. Option ISO-8601 will parse input timestamp in "yyyy-MM-ddTHH:mm:ss.s{precision}" format and output timestamp in the same format. Option SQL will parse input timestamp in "yyyy-MM-dd HH:mm:ss.s{precision}" format and output timestamp in the same format.

3. dbInclude

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		An optional regular expression to only read the specific databases changelog rows by regular matching the "database" meta field in the Canal record.The pattern string is compatible with Java's Pattern.

4. tableInclude

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		An optional regular expression to only read the specific tables changelog rows by regular matching the "table" meta field in the Canal record.The pattern string is compatible with Java's Pattern.

5. nullKeyMode

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** FAIL
	* **说明:** 

		Optional flag to control the handling mode when serializing null key for map data, FAIL by default. Option DROP will drop null key entries for map data. Option LITERAL will use 'map-null-key.literal' as key literal.

6. nullKeyLiteral

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** null
	* **说明:** 

		Optional flag to specify string literal for null keys when 'map-null-key.mode' is LITERAL, "null" by default.

7. encodeDecimal

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to specify whether to encode all decimals as plain numbers instead of possible scientific notations, false by default.

### com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.format.canaljson.TISSourceCanalJsonFormatFactory

* **显示名:** canal-json 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.format.canaljson.TISSourceCanalJsonFormatFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-msg-format-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/kafka/format/canaljson/TISSourceCanalJsonFormatFactory.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-msg-format-plugin.tpi](./tpis#tis-flink-msg-format-plugintpi)

* **配置项说明:** 

1. Table Name(s)

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		导入流实体名称，目标端以此作为表名，多个表以逗号分隔

2. ignoreParseErrors

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to skip fields and rows with parse errors instead of failing;
		fields are set to null in case of errors, false by default.

3. timestampFormat

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** SQL
	* **说明:** 

		Optional flag to specify timestamp format, SQL by default. Option ISO-8601 will parse input timestamp in "yyyy-MM-ddTHH:mm:ss.s{precision}" format and output timestamp in the same format. Option SQL will parse input timestamp in "yyyy-MM-dd HH:mm:ss.s{precision}" format and output timestamp in the same format.

4. dbInclude

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		An optional regular expression to only read the specific databases changelog rows by regular matching the "database" meta field in the Canal record.The pattern string is compatible with Java's Pattern.

5. tableInclude

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		An optional regular expression to only read the specific tables changelog rows by regular matching the "table" meta field in the Canal record.The pattern string is compatible with Java's Pattern.

6. nullKeyMode

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** FAIL
	* **说明:** 

		Optional flag to control the handling mode when serializing null key for map data, FAIL by default. Option DROP will drop null key entries for map data. Option LITERAL will use 'map-null-key.literal' as key literal.

7. nullKeyLiteral

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** null
	* **说明:** 

		Optional flag to specify string literal for null keys when 'map-null-key.mode' is LITERAL, "null" by default.

8. encodeDecimal

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to specify whether to encode all decimals as plain numbers instead of possible scientific notations, false by default.

### com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.format.debeziumjson.TISSinkDebeziumJsonFormatFactory

* **显示名:** debezium-json 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.format.debeziumjson.TISSinkDebeziumJsonFormatFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-msg-format-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/kafka/format/debeziumjson/TISSinkDebeziumJsonFormatFactory.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-msg-format-plugin.tpi](./tpis#tis-flink-msg-format-plugintpi)

* **配置项说明:** 

1. ignoreParseErrors

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to skip fields and rows with parse errors instead of failing;
		fields are set to null in case of errors, false by default.

2. timestampFormat

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** SQL
	* **说明:** 

		Optional flag to specify timestamp format, SQL by default. Option ISO-8601 will parse input timestamp in "yyyy-MM-ddTHH:mm:ss.s{precision}" format and output timestamp in the same format. Option SQL will parse input timestamp in "yyyy-MM-dd HH:mm:ss.s{precision}" format and output timestamp in the same format.

3. nullKeyMode

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** FAIL
	* **说明:** 

		Optional flag to control the handling mode when serializing null key for map data, FAIL by default. Option DROP will drop null key entries for map data. Option LITERAL will use 'map-null-key.literal' as key literal.

4. nullKeyLiteral

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** null
	* **说明:** 

		Optional flag to specify string literal for null keys when 'map-null-key.mode' is LITERAL, "null" by default.

5. encodeDecimal

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to specify whether to encode all decimals as plain numbers instead of possible scientific notations, false by default.

### com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.format.debeziumjson.TISSourceDebeziumJsonFormatFactory

* **显示名:** debezium-json 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.format.debeziumjson.TISSourceDebeziumJsonFormatFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-msg-format-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/kafka/format/debeziumjson/TISSourceDebeziumJsonFormatFactory.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-msg-format-plugin.tpi](./tpis#tis-flink-msg-format-plugintpi)

* **配置项说明:** 

1. Table Name(s)

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		导入流实体名称，目标端以此作为表名，多个表以逗号分隔

2. ignoreParseErrors

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to skip fields and rows with parse errors instead of failing;
		fields are set to null in case of errors, false by default.

3. timestampFormat

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** SQL
	* **说明:** 

		Optional flag to specify timestamp format, SQL by default. Option ISO-8601 will parse input timestamp in "yyyy-MM-ddTHH:mm:ss.s{precision}" format and output timestamp in the same format. Option SQL will parse input timestamp in "yyyy-MM-dd HH:mm:ss.s{precision}" format and output timestamp in the same format.

4. nullKeyMode

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** FAIL
	* **说明:** 

		Optional flag to control the handling mode when serializing null key for map data, FAIL by default. Option DROP will drop null key entries for map data. Option LITERAL will use 'map-null-key.literal' as key literal.

5. nullKeyLiteral

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** null
	* **说明:** 

		Optional flag to specify string literal for null keys when 'map-null-key.mode' is LITERAL, "null" by default.

6. encodeDecimal

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to specify whether to encode all decimals as plain numbers instead of possible scientific notations, false by default.

### com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.format.json.SinkJsonFormatFactory

* **显示名:** json 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.format.json.SinkJsonFormatFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-msg-format-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/kafka/format/json/SinkJsonFormatFactory.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-msg-format-plugin.tpi](./tpis#tis-flink-msg-format-plugintpi)

* **配置项说明:** 

1. ignoreParseErrors

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to skip fields and rows with parse errors instead of failing;
		fields are set to null in case of errors, false by default.

2. failOnMissingField

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to specify whether to fail if a field is missing or not, false by default.

3. timestampFormat

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** SQL
	* **说明:** 

		Optional flag to specify timestamp format, SQL by default. Option ISO-8601 will parse input timestamp in "yyyy-MM-ddTHH:mm:ss.s{precision}" format and output timestamp in the same format. Option SQL will parse input timestamp in "yyyy-MM-dd HH:mm:ss.s{precision}" format and output timestamp in the same format.

4. nullKeyMode

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** FAIL
	* **说明:** 

		Optional flag to control the handling mode when serializing null key for map data, FAIL by default. Option DROP will drop null key entries for map data. Option LITERAL will use 'map-null-key.literal' as key literal.

5. nullKeyLiteral

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** null
	* **说明:** 

		Optional flag to specify string literal for null keys when 'map-null-key.mode' is LITERAL, "null" by default.

6. encodeJsonParserEnabled

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** true
	* **说明:** 

		Optional flag to specify whether to use the Jackson JsonParser to decode json with better performance, true by default.

7. encodeDecimal

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to specify whether to encode all decimals as plain numbers instead of possible scientific notations, false by default.

### com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.format.json.SourceJsonFormatFactory

* **显示名:** json 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.kafka.format.json.SourceJsonFormatFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-msg-format-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/kafka/format/json/SourceJsonFormatFactory.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-msg-format-plugin.tpi](./tpis#tis-flink-msg-format-plugintpi)

* **配置项说明:** 

1. Table Name

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		导入流实体名称，目标端以此作为表名

2. ignoreParseErrors

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to skip fields and rows with parse errors instead of failing;
		fields are set to null in case of errors, false by default.

3. failOnMissingField

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to specify whether to fail if a field is missing or not, false by default.

4. timestampFormat

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** SQL
	* **说明:** 

		Optional flag to specify timestamp format, SQL by default. Option ISO-8601 will parse input timestamp in "yyyy-MM-ddTHH:mm:ss.s{precision}" format and output timestamp in the same format. Option SQL will parse input timestamp in "yyyy-MM-dd HH:mm:ss.s{precision}" format and output timestamp in the same format.

5. nullKeyMode

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** FAIL
	* **说明:** 

		Optional flag to control the handling mode when serializing null key for map data, FAIL by default. Option DROP will drop null key entries for map data. Option LITERAL will use 'map-null-key.literal' as key literal.

6. nullKeyLiteral

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** null
	* **说明:** 

		Optional flag to specify string literal for null keys when 'map-null-key.mode' is LITERAL, "null" by default.

7. encodeJsonParserEnabled

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** true
	* **说明:** 

		Optional flag to specify whether to use the Jackson JsonParser to decode json with better performance, true by default.

8. encodeDecimal

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 

		Optional flag to specify whether to encode all decimals as plain numbers instead of possible scientific notations, false by default.

## com.qlangtech.tis.offline.FileSystemFactory

### com.qlangtech.tis.hdfs.impl.AliayunJindoFSFactory

* **显示名:** Aliyun-Jindo-HDFS 

* **全路径名:** [com.qlangtech.tis.hdfs.impl.AliayunJindoFSFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-aliyun-jindo-sdk-extends/tis-datax-hdfs-aliyun-emr-plugin/src/main/java/com/qlangtech/tis/hdfs/impl/AliayunJindoFSFactory.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-hdfs-aliyun-emr-plugin/tis-datax-hdfs-aliyun-emr-plugin_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-datax-hdfs-aliyun-emr-plugin/tis-datax-hdfs-aliyun-emr-plugin_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. 使用域名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 

		当客户端导入数据到HDFS过程中，客户端会使用hostname（域名）而不是ip地址的方式去连接HDFS DataNode地址。当用户利用Docker Compose的方式启动hadoop环境(例如：[Hudi测试环境](https://hudi.apache.org/docs/next/docker_demo))
		，客户端取得的DataNode地址一般会是Docker容器的内部Ip地址，从容器外部是访问不到的，此时将该选项设置为`是`，可以解决数据无法导入到HDFS的问题。
		
		详细请查看[https://segmentfault.com/q/1010000008473574](https://segmentfault.com/q/1010000008473574)
		
		当选择`是`，在创HDFS FileSystem实例时加上如下参数：
		```java
		  conf.set("dfs.client.use.datanode.hostname", "true");
		```

3. endpoint

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：OSS Server的EndPoint信息

4. bucket

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：OSS的bucket  

5. rootDir

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		系统会将源数据导入到该子目录下，用户需要保证该子目录有读/写权限

6. userToken

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 		当选择为'on', 开启kerberos客户端认证

7. hdfs-site.xml

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.hdfs.impl.AliayunJindoFSFactory.nullHdfsSiteContent()
	* **说明:** 

		配置实例,实现了HDFS HA高可用方案：
		
		[hdfs-site.xml参数详解](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml)
		
		```xml
		<configuration>
		    <property>
		        <name>fs.defaultFS</name>
		        <value>hdfs://192.168.28.200</value>
		    </property>
		</configuration>
		```

### com.qlangtech.tis.hdfs.impl.HdfsFileSystemFactory

* **显示名:** HDFS 

* **全路径名:** [com.qlangtech.tis.hdfs.impl.HdfsFileSystemFactory](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-hdfs-plugin/src/main/java/com/qlangtech/tis/hdfs/impl/HdfsFileSystemFactory.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-hdfs-plugin/tis-datax-hdfs-plugin_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-datax-hdfs-plugin/tis-datax-hdfs-plugin_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. 使用域名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 

		当客户端导入数据到HDFS过程中，客户端会使用hostname（域名）而不是ip地址的方式去连接HDFS DataNode地址。当用户利用Docker Compose的方式启动hadoop环境(例如：[Hudi测试环境](https://hudi.apache.org/docs/next/docker_demo))
		，客户端取得的DataNode地址一般会是Docker容器的内部Ip地址，从容器外部是访问不到的，此时将该选项设置为`是`，可以解决数据无法导入到HDFS的问题。
		
		详细请查看[https://segmentfault.com/q/1010000008473574](https://segmentfault.com/q/1010000008473574)
		
		当选择`是`，在创HDFS FileSystem实例时加上如下参数：
		```java
		  conf.set("dfs.client.use.datanode.hostname", "true");
		```

3. rootDir

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		系统会将源数据导入到该子目录下，用户需要保证该子目录有读/写权限

4. userToken

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 		当选择为'on', 开启kerberos客户端认证

5. hdfs-site.xml

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.hdfs.impl.HdfsFileSystemFactory.dftHdfsSiteContent()
	* **说明:** 

		配置实例,实现了HDFS HA高可用方案：
		
		[hdfs-site.xml参数详解](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml)
		
		```xml
		<configuration>
		    <property>
		        <name>fs.defaultFS</name>
		        <value>hdfs://192.168.28.200</value>
		    </property>
		</configuration>
		```

## com.qlangtech.tis.plugin.ds.SplitTableStrategy

### :closed_lock_with_key:com.qlangtech.tis.plugin.ds.split.DefaultSplitTableStrategy

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.ds.split.DefaultSplitTableStrategy](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-split-table-strategy-plugin/src/main/java/com/qlangtech/tis/plugin/ds/split/DefaultSplitTableStrategy.java) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-split-table-strategy-plugin.tpi](./tpis#tis-split-table-strategy-plugintpi)

* **配置项说明:** 

1. 分库节点

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		将分布在多个数据库冗余节点中的物理表视作一个逻辑表，在数据同步管道中进行配置，输入框中可输入以下内容：
		
		* `192.168.28.200[00-07]` ： 单节点多库，导入 192.168.28.200:3306 节点的 order00,order01,order02,order03,order04,order05,order06,order078个库。也可以将节点描述写成：`192.168.28.200[0-7]`，则会导入 192.168.28.200:3306 节点的 order0,order1,order2,order3,order4,order5,order6,order78个库
		* `192.168.28.200[00-07],192.168.28.201[08-15]`：会导入 192.168.28.200:3306 节点的 order00,order01,order02,order03,order04,order05,order06,order078个库 和 192.168.28.201:3306 节点的 order08,order09,order10,order11,order12,order13,order14,order158个库，共计16个库
		
		[详细说明](http://tis.pub/docs/guide/datasource/multi-ds-rule)

2. 分表识别

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		识别分表的正则式，默认识别分表策略为 `(tabname)_\d+` , 如需使用其他分表策略，如带字母[a-z]的后缀则需要用户自定义
		
		`注意`：如输入自定义正则式，表达式中逻辑表名部分，必须要用括号括起来，不然无法从物理表名中抽取出逻辑表名。
		
		**可参考**：https://github.com/qlangtech/tis/issues/361

3. 测试表

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		提交表单用户测试，所填正则式是否能正确识别物理分表。输入需要识别的逻辑表名，点击‘校验’按钮会进行自动识别。

4. 增量前缀匹配

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 

		使用前缀匹配的样式，在flink-cdc表前缀通配匹配的场景中使用
		* 选择`是`：在增量监听流程中使用`逻辑表`+`*`的方式对目标表监听，例如，逻辑表名为`base`,启动时使用`base*` 对数据库中 `base01`,`base02`启用增量监听，在运行期用户又增加了`base03`表则执行逻辑会自动对`base03`表开启监听
		* 选择`否`：在增量监听流程中使用物理表全匹配的方式进行匹配。在运行期用户增加的新的分表忽略，如需对新加的分表增量监听生效，需要重启增量执行管道。

## com.qlangtech.tis.datax.impl.DataxReader

### com.qlangtech.tis.plugin.datax.dameng.reader.DataXDaMengReader

* **显示名:** DaMeng 

* **全路径名:** [com.qlangtech.tis.plugin.datax.dameng.reader.DataXDaMengReader](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dameng-plugin/src/main/java/com/qlangtech/tis/plugin/datax/dameng/reader/DataXDaMengReader.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dameng-plugin.tpi](./tpis#tis-datax-dameng-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. fetchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2000
	* **说明:** 		执行数据批量导出时单次从数据库中提取记录条数，可以有效减少网络IO次数，提升导出效率。切忌不能设置太大以免OOM发生

3. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.dameng.reader.DataXDaMengReader.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXDFSReader

* **显示名:** TDFS 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXDFSReader](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dfs-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXDFSReader.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dfs-plugin.tpi](./tpis#tis-datax-dfs-plugintpi)

* **配置项说明:** 

1. 资源

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		DFS服务端连接配置

2. 目标文件匹配

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** Wildcard
	* **说明:** 

		到指定目录中获取目标资源文件，TIS已经为您准备了两种类型的匹配器：
		
		* Wildcard：
		
		   通过 `wildcard` 表达式（如：`user*.json`,`"a/b/*"`），到指定目录扫描所有资源文件，如果与`wildcard`匹配，则作为TDFS Reader的目标资源文件，在后续全量导入流程中读取
		* ByMeta：
		
		  `Writer TDFS`作为目标Writer，流程中开启了`添加元数据`选项，将源数据的Schema写入到目标文件系统中，后续，以该`TDFS`作为源数据类型则可以依赖该预写入的Schema文件作为数据源的Schema信息，可大大简化流程

3. 文件格式

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		可以根据目标文件不同的格式，对文件进行解析

4. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXDFSReader.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.kingbase.DataXKingBaseReader

* **显示名:** KingBase 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kingbase.DataXKingBaseReader](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-kingbase-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kingbase/DataXKingBaseReader.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-kingbase-plugin.tpi](./tpis#tis-datax-kingbase-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. splitPk

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		描述：数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。推荐splitPk用户使用表主键，因为表主键通常情况下比较均匀，因此切分出来的分片也不容易出现数据热点。
		目前splitPk仅支持整形数据切分，不支持浮点、字符串型、日期等其他类型。如果用户指定其他非支持类型，将报错！
		splitPk设置为空，底层将视作用户不允许对单表进行切分，因此使用单通道进行抽取。

3. fetchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2000
	* **说明:** 		描述：该配置项定义了插件和数据库服务器端每次批量数据获取条数，该值决定了DataX和服务器端的网络交互次数，能够较大的提升数据抽取性能。注意，该值过大(>2048)可能造成DataX进程OOM

4. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXPostgresqlReader.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXMariaReader

* **显示名:** MariaDB 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXMariaReader](https://github.com/qlangtech/plugins/tree/master/tis-datax-mariadb-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXMariaReader.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-mariadb-plugin.tpi](./tpis#tis-datax-mariadb-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. splitPk

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。
		推荐splitPk用户使用表主键，因为表主键通常情况下比较均匀，因此切分出来的分片也不容易出现数据热点。
		 目前splitPk仅支持整形数据切分，不支持浮点、字符串、日期等其他类型。如果用户指定其他非支持类型，MysqlReader将报错！
		 如果splitPk不填写，包括不提供splitPk或者splitPk值为空，DataX视作使用单通道同步该表数据。

3. fetchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2000
	* **说明:** 		执行数据批量导出时单次从数据库中提取记录条数，可以有效减少网络IO次数，提升导出效率。切忌不能设置太大以免OOM发生

4. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataxMySQLReader.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXMongodbReader

* **显示名:** MongoDB 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXMongodbReader](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-mongodb-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXMongodbReader.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-mongodb-plugin.tpi](./tpis#tis-datax-mongodb-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. 所在时区

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.async.message.client.consumer.impl.MQListenerFactory.dftZoneId()
	* **说明:** 		设置所在时区

3. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXMongodbReader.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXOracleReader

* **显示名:** Oracle 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXOracleReader](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-oracle-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXOracleReader.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-oracle-plugin.tpi](./tpis#tis-datax-oracle-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. splitPk

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 		描述：OracleReader进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。

3. session

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		描述：控制写入数据的时间格式，时区等的配置，如果表中有时间字段，配置该值以明确告知写入 oracle 的时间格式。通常配置的参数为：NLS_DATE_FORMAT,NLS_TIME_FORMAT。其配置的值为 json 格式，例如：[
		              "alter session set NLS_DATE_FORMAT='yyyy-mm-dd hh24:mi:ss'",
		              "alter session set NLS_TIMESTAMP_FORMAT='yyyy-mm-dd hh24:mi:ss'",
		              "alter session set NLS_TIMESTAMP_TZ_FORMAT='yyyy-mm-dd hh24:mi:ss'",
		              "alter session set TIME_ZONE='US/Pacific'"
		            ]

4. fetchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2000
	* **说明:** 		描述：该配置项定义了插件和数据库服务器端每次批量数据获取条数，该值决定了DataX和服务器端的网络交互次数，能够较大的提升数据抽取性能。

5. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXOracleReader.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXPostgresqlReader

* **显示名:** PostgreSQL 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXPostgresqlReader](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-postgresql-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXPostgresqlReader.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-postgresql-plugin.tpi](./tpis#tis-datax-postgresql-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. splitPk

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		描述：数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。推荐splitPk用户使用表主键，因为表主键通常情况下比较均匀，因此切分出来的分片也不容易出现数据热点。
		目前splitPk仅支持整形数据切分，不支持浮点、字符串型、日期等其他类型。如果用户指定其他非支持类型，将报错！
		splitPk设置为空，底层将视作用户不允许对单表进行切分，因此使用单通道进行抽取。

3. fetchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2000
	* **说明:** 		描述：该配置项定义了插件和数据库服务器端每次批量数据获取条数，该值决定了DataX和服务器端的网络交互次数，能够较大的提升数据抽取性能。注意，该值过大(>2048)可能造成DataX进程OOM

4. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXPostgresqlReader.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataXSqlserverReader

* **显示名:** SqlServer 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXSqlserverReader](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-sqlserver-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXSqlserverReader.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-sqlserver-plugin.tpi](./tpis#tis-datax-sqlserver-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. splitPk

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** false
	* **说明:** 		SqlServerReader进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。
		推荐splitPk用户使用表主键，因为表主键通常情况下比较均匀，因此切分出来的分片也不容易出现数据热点。
		目前splitPk仅支持整形型数据切分，不支持浮点、字符串、日期等其他类型。如果用户指定其他非支持类型，SqlServerReader将报错！
		splitPk设置为空，底层将视作用户不允许对单表进行切分，因此使用单通道进行抽取。

3. fetchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2000
	* **说明:** 		该配置项定义了插件和数据库服务器端每次批量数据获取条数，该值决定了DataX和服务器端的网络交互次数，能够较大的提升数据抽取性能。

4. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXSqlserverReader.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.DataxMySQLReader

* **显示名:** MySQL 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataxMySQLReader](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-ds-mysql-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataxMySQLReader.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-ds-mysql-plugin.tpi](./tpis#tis-ds-mysql-plugintpi)

* **配置项说明:** 

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. splitPk

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。
		推荐splitPk用户使用表主键，因为表主键通常情况下比较均匀，因此切分出来的分片也不容易出现数据热点。
		 目前splitPk仅支持整形数据切分，不支持浮点、字符串、日期等其他类型。如果用户指定其他非支持类型，MysqlReader将报错！
		 如果splitPk不填写，包括不提供splitPk或者splitPk值为空，DataX视作使用单通道同步该表数据。

3. fetchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2000
	* **说明:** 		执行数据批量导出时单次从数据库中提取记录条数，可以有效减少网络IO次数，提升导出效率。切忌不能设置太大以免OOM发生

4. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataxMySQLReader.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

### com.qlangtech.tis.plugin.datax.kafka.reader.DataXKafkaReader

* **显示名:** Kafka 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kafka.reader.DataXKafkaReader](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-kafka-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kafka/reader/DataXKafkaReader.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-kafka-plugin.tpi](./tpis#tis-flink-cdc-kafka-plugintpi)

* **配置项说明:** 

1. Bootstrap Servers

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		A list of host/port pairs to use for establishing the initial connection to the Kafka cluster. The client will make use of all servers irrespective of which servers are specified here for bootstrapping&mdash;this list only impacts the initial hosts used to discover the full set of servers. This list should be in the form <code>host1:port1,host2:port2,...</code>. Since these servers are just used for the initial connection to discover the full cluster membership (which may change dynamically), this list need not contain the full set of servers (you may want more than one, though, in case a server is down).

2. Subscription Method

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		You can choose to manually assign a list of partitions, or subscribe to all topics matching specified pattern to get dynamically assigned partitions.

3. Test Topic

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		The Topic to test in case the can consume messages.

4. MessageFormat

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** json
	* **说明:** 		The serialization used based on this.

5. Request Timeout, ms

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 30000
	* **说明:** 		The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted.

6. 猜测字段类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		通过TIS提供的的内部算法，预先读取Kafka事件流中一定数量的记录，猜测对应列的类型，以帮助最大化提高录入表单效率。最后通过分析得到的类型不够准确，需要用户手动微调。

7. Group ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		The Group ID is how you distinguish different consumer groups.

8. Client DNS Lookup

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** use_all_dns_ips
	* **说明:** 		Controls how the client uses DNS lookups. If set to use_all_dns_ips, connect to each returned IP address in sequence until a successful connection is established. After a disconnection, the next IP is used. Once all IPs have been used once, the client resolves the IP(s) from the hostname again. If set to resolve_canonical_bootstrap_servers_only, resolve each bootstrap address into a list of canonical names. After the bootstrap phase, this behaves the same as use_all_dns_ips. If set to default (deprecated), attempt to connect to the first IP address returned by the lookup, even if the lookup returns multiple IP addresses.

9. Protocol

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** PLAINTEXT
	* **说明:** 		The Protocol used to communicate with brokers.

10. Enable Auto Commit

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** true
	* **说明:** 		If true, the consumer's offset will be periodically committed in the background.

11. Client ID

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		An ID string to pass to the server when making requests. The purpose of this is to be able to track the source of requests beyond just ip/port by allowing a logical application name to be included in server-side request logging.

12. Retry Backoff, ms

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 100
	* **说明:** 		The amount of time to wait before attempting to retry a failed request to a given topic partition. This avoids repeatedly sending requests in a tight loop under some failure scenarios.

13. Auto Commit Interval, ms

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 5000
	* **说明:** 		The frequency in milliseconds that the consumer offsets are auto-committed to Kafka if enable.auto.commit is set to true.

14. Max Poll Records

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 500
	* **说明:** 		The maximum number of records returned in a single call to poll(). Note, that max_poll_records does not impact the underlying fetching behavior. The consumer will cache the records from each fetch request and returns them incrementally from each poll.

15. Receive Buffer, bytes

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 32768
	* **说明:** 		The size of the TCP receive buffer (SO_RCVBUF) to use when reading data. If the value is -1, the OS default will be used.

16. Socket Setup TimeoutMs

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 10000
	* **说明:** 		The amount of time the client will wait for the socket connection to be established. If the connection is not built before the timeout elapses, clients will close the socket channel.

17. Socket Setup Timeout MaxMs

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 30000
	* **说明:** 		The maximum amount of time the client will wait for the socket connection to be established. The connection setup timeout will increase exponentially for each consecutive connection failure up to this maximum. To avoid connection storms, a randomization factor of 0.2 will be applied to the timeout resulting in a random range between 20% below and 20% above the computed value.

18. Maximum Records

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 100000
	* **说明:** 		The Maximum to be processed per execution

19. Repeated Calls

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 3
	* **说明:** 		The number of repeated calls to poll() if no messages were received.

20. Polling Time

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 1000
	* **说明:** 		Amount of time Kafka connector should try to poll for messages.

### com.qlangtech.tis.hive.reader.DataXHiveReader

* **显示名:** HiveMetaStore 

* **全路径名:** [com.qlangtech.tis.hive.reader.DataXHiveReader](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/hive/reader/DataXHiveReader.java) 

* **提供者:** [DataX](https://github.com/alibaba/DataX) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. 资源

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		DFS服务端连接配置

2. 目标分区

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		如果目标表设置了分区键，请设置该选项

3. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.hive.reader.DataXHiveReader.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

## com.qlangtech.tis.config.kerberos.Krb5Res

### com.qlangtech.tis.kerberos.impl.SystemPathKrb5Res

* **显示名:** SystemPath 

* **全路径名:** [com.qlangtech.tis.kerberos.impl.SystemPathKrb5Res](https://github.com/qlangtech/plugins/tree/master/tis-kerberos-plugin/src/main/java/com/qlangtech/tis/kerberos/impl/SystemPathKrb5Res.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-kerberos-plugin.tpi](./tpis#tis-kerberos-plugintpi)

* **配置项说明:** 

1. path

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** /etc/krb5.conf
	* **说明:** 		config file `krb5.conf` located in system path

### com.qlangtech.tis.kerberos.impl.UploadKrb5Res

* **显示名:** Upload 

* **全路径名:** [com.qlangtech.tis.kerberos.impl.UploadKrb5Res](https://github.com/qlangtech/plugins/tree/master/tis-kerberos-plugin/src/main/java/com/qlangtech/tis/kerberos/impl/UploadKrb5Res.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-kerberos-plugin.tpi](./tpis#tis-kerberos-plugintpi)

* **配置项说明:** 

1. file
	* **类型:** 文件
	* **必须:** 是
## com.qlangtech.tis.plugin.datax.powerjob.ServerPortExport

### com.qlangtech.tis.plugin.datax.powerjob.impl.serverport.Ingress

* **显示名:** Ingress 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.impl.serverport.Ingress](https://github.com/qlangtech/plugins/tree/master/tis-k8s-plugin/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/impl/serverport/Ingress.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-k8s-plugin.tpi](./tpis#tis-k8s-plugintpi)

* **配置项说明:** 

1. serverPort

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.trigger.util.UnCacheString@197d5a87
	* **说明:** 		SpringBoot配置，HTTP端口号，默认7700，不建议更改

2. host
	* **类型:** 单行文本
	* **必须:** 是
3. path
	* **类型:** 单行文本
	* **必须:** 是
### com.qlangtech.tis.plugin.datax.powerjob.impl.serverport.LoadBalance

* **显示名:** LoadBalance 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.impl.serverport.LoadBalance](https://github.com/qlangtech/plugins/tree/master/tis-k8s-plugin/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/impl/serverport/LoadBalance.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-k8s-plugin.tpi](./tpis#tis-k8s-plugintpi)

* **配置项说明:** 

1. serverPort

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.trigger.util.UnCacheString@4f552aa2
	* **说明:** 		SpringBoot配置，HTTP端口号，默认7700，不建议更改

### com.qlangtech.tis.plugin.datax.powerjob.impl.serverport.NodePort

* **显示名:** NodePort 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.impl.serverport.NodePort](https://github.com/qlangtech/plugins/tree/master/tis-k8s-plugin/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/impl/serverport/NodePort.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-k8s-plugin.tpi](./tpis#tis-k8s-plugintpi)

* **配置项说明:** 

1. serverPort

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.trigger.util.UnCacheString@1c411474
	* **说明:** 		SpringBoot配置，HTTP端口号，默认7700，不建议更改

2. INTERNAL-IP

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		通过执行如下命令：
		```shell
		kubectl get nodes -o wide
		```
		得到如下输出结果：
		```shell
		NAME            STATUS   ROLES           AGE    VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION           CONTAINER-RUNTIME
		baisui-test-2   Ready    control-plane   242d   v1.28.3   192.168.28.201   <none>        CentOS Linux 7 (Core)   3.10.0-1127.el7.x86_64   docker://24.0.5
		```
		可`任选一条`记录的`INTERNAL-IP`填入输入框中

3. nodePort

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 31000
	* **说明:** 

		NodePort服务是让外部请求直接访问服务的最原始方式，NodePort是在所有的节点上开放指定的端口，所有发送到这个端口的请求都会直接转发到服务中的pod里；
		
		这种方式不足：
		1. 一个端口只提供一个服务使用
		2. 只能使用30000-32767之间的端口
		3. 如果节点/虚拟机的IP地址发送变化，需要人工处理；
		
		所以在生产环境，不推荐这种方式发布服务

## com.qlangtech.tis.plugin.datax.format.FileFormat

### com.qlangtech.tis.plugin.datax.format.CSVFormat

* **显示名:** CSV 

* **全路径名:** [com.qlangtech.tis.plugin.datax.format.CSVFormat](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dfs-plugin/src/main/java/com/qlangtech/tis/plugin/datax/format/CSVFormat.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dfs-plugin.tpi](./tpis#tis-datax-dfs-plugintpi)

* **配置项说明:** 

1. 字段分隔符

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** comma
	* **说明:** 		描述：读取的字段分隔符，可以用'\t','\001'等字符 

2. 压缩格式

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** none
	* **说明:** 		描述：文本压缩类型，默认不填写意味着没有压缩。支持压缩类型为zip、gzip、bzip2。 

3. encoding

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** utf-8
	* **说明:** 		描述：读取文件的编码配置。

4. 空值替代符

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** null
	* **说明:** 		描述：文本文件中无法使用标准字符串定义null(空指针)，DataX提供nullFormat定义哪些字符串可以表示为null。例如如果用户配置: nullFormat="\N"，那么如果源头数据是"\N"，DataX视作null字段。

5. 日期格式

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.format.BasicPainFormat.defaultNullFormat()
	* **说明:** 		描述：日期类型的数据序列化到文件中时的格式，例如 "dateFormat": "yyyy-MM-dd"。

6. csvConfig

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：（读取/写入）CSV类型文件参数配置，Map类型。
		 * 写入CSV类型文件使用的CsvWriter进行写入，会有很多配置，不配置则使用默认值。
		      ```json
		    { "forceQualifier": true,  
		      "textQualifier": "\"",
		       "useTextQualifier": true,
		       "delimiter": ",",
		       "recordDelimiter": 0,
		       "comment": "#",
		       "escapeMode": 1
		      } 
		      ```
		
		 * 读取CSV类型文件使用的CsvReader进行读取，会有很多配置，不配置则使用默认值。
		
		 ```json
		{ "safetySwitch": false,  
		  "skipEmptyRecords": false,       
		  "useTextQualifier": false} 
		 ```
		 所有配置项及默认值,配置时 csvReaderConfig 的map中请严格按照以下字段名字进行配置：
		 ```java
		 boolean caseSensitive = true;
		 char textQualifier = 34;
		 boolean trimWhitespace = true;
		 boolean useTextQualifier = true;//是否使用csv转义字符
		 char delimiter = 44;//分隔符
		 char recordDelimiter = 0;
		 char comment = 35;
		 boolean useComments = false;
		 int escapeMode = 1;
		 boolean safetySwitch = true;//单列长度是否限制100000字符
		 boolean skipEmptyRecords = true;//是否跳过空行
		 boolean captureRawRecord = true;
		 ```

7. header

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 		描述：写出时的表头，列名(s)是否在文件头写入

8. 猜测字段类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		通过TIS提供的的内部算法，尝试读取部分DFS文件内容，猜测对应列的类型，以帮助最大化提高录入表单效率。最后通过分析得到的类型不够准确，需要用户手动微调。

### com.qlangtech.tis.plugin.datax.format.TextFormat

* **显示名:** TEXT 

* **全路径名:** [com.qlangtech.tis.plugin.datax.format.TextFormat](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dfs-plugin/src/main/java/com/qlangtech/tis/plugin/datax/format/TextFormat.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dfs-plugin.tpi](./tpis#tis-datax-dfs-plugintpi)

* **配置项说明:** 

1. 字段分隔符

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** comma
	* **说明:** 		描述：读取的字段分隔符，可以用'\t','\001'等字符 

2. 压缩格式

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** none
	* **说明:** 		描述：文本压缩类型，默认不填写意味着没有压缩。支持压缩类型为zip、gzip、bzip2。 

3. encoding

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** utf-8
	* **说明:** 		描述：读取文件的编码配置。

4. 空值替代符

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** null
	* **说明:** 		描述：文本文件中无法使用标准字符串定义null(空指针)，DataX提供nullFormat定义哪些字符串可以表示为null。例如如果用户配置: nullFormat="\N"，那么如果源头数据是"\N"，DataX视作null字段。

5. 日期格式

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.format.BasicPainFormat.defaultNullFormat()
	* **说明:** 		描述：日期类型的数据序列化到文件中时的格式，例如 "dateFormat": "yyyy-MM-dd"。

6. header

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 		描述：写出时的表头，列名(s)是否在文件头写入

7. 猜测字段类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		通过TIS提供的的内部算法，尝试读取部分DFS文件内容，猜测对应列的类型，以帮助最大化提高录入表单效率。最后通过分析得到的类型不够准确，需要用户手动微调。

## com.qlangtech.tis.plugin.datax.powerjob.PowerjobCoreDataSource

### com.qlangtech.tis.plugin.datax.powerjob.impl.coresource.DefaultPowerjobCoreDataSource

* **显示名:** Customized 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.impl.coresource.DefaultPowerjobCoreDataSource](https://github.com/qlangtech/plugins/tree/master/tis-k8s-plugin/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/impl/coresource/DefaultPowerjobCoreDataSource.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-k8s-plugin.tpi](./tpis#tis-k8s-plugintpi)

* **配置项说明:** 

1. dbName

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		可先在生产环境中部署MySQL8版本数据库，使用SQL脚本[powerjob-mysql.sql](https://github.com/PowerJob/PowerJob/blob/v4.3.6/others/powerjob-mysql.sql)

### com.qlangtech.tis.plugin.datax.powerjob.impl.coresource.EmbeddedPowerjobCoreDataSource

* **显示名:** Embedded 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.impl.coresource.EmbeddedPowerjobCoreDataSource](https://github.com/qlangtech/plugins/tree/master/tis-k8s-plugin/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/impl/coresource/EmbeddedPowerjobCoreDataSource.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-k8s-plugin.tpi](./tpis#tis-k8s-plugintpi)

## com.qlangtech.tis.plugin.datax.meta.MetaDataWriter

### com.qlangtech.tis.plugin.datax.meta.DefaultMetaDataWriter

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.meta.DefaultMetaDataWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dfs-plugin/src/main/java/com/qlangtech/tis/plugin/datax/meta/DefaultMetaDataWriter.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dfs-plugin.tpi](./tpis#tis-datax-dfs-plugintpi)

### com.qlangtech.tis.plugin.datax.meta.NoneMetaDataWriter

* **显示名:** off 

* **全路径名:** [com.qlangtech.tis.plugin.datax.meta.NoneMetaDataWriter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dfs-plugin/src/main/java/com/qlangtech/tis/plugin/datax/meta/NoneMetaDataWriter.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dfs-plugin.tpi](./tpis#tis-datax-dfs-plugintpi)

## com.qlangtech.tis.plugin.AuthToken

### com.qlangtech.tis.plugin.aliyun.NoneToken

* **显示名:** none 

* **全路径名:** [com.qlangtech.tis.plugin.aliyun.NoneToken](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-common-plugin/src/main/java/com/qlangtech/tis/plugin/aliyun/NoneToken.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-common-plugin.tpi](./tpis#tis-datax-common-plugintpi)

### com.qlangtech.tis.plugin.aliyun.UsernamePassword

* **显示名:** user 

* **全路径名:** [com.qlangtech.tis.plugin.aliyun.UsernamePassword](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-common-plugin/src/main/java/com/qlangtech/tis/plugin/aliyun/UsernamePassword.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-common-plugin.tpi](./tpis#tis-datax-common-plugintpi)

* **配置项说明:** 

1. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		用在私有云环境下，例如自建Elasticsearch，服务端如不需要连接凭证，则该项可为空

2. 密码

	* **类型:** 密码
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		用在私有云环境下，例如自建Elasticsearch，服务端如不需要连接凭证，则该项可为空

### :closed_lock_with_key:com.qlangtech.tis.plugin.aliyun.AccessKey

* **显示名:** accessKey 

* **全路径名:** [com.qlangtech.tis.plugin.aliyun.AccessKey](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-datax-commercial/tis-datax-oss-plugin/src/main/java/com/qlangtech/tis/plugin/aliyun/AccessKey.java) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-datax-oss-plugin.tpi](./tpis#tis-datax-oss-plugintpi)

* **配置项说明:** 

1. keyId

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		aliyun服务的accessId，用在私有云环境下，例如自建Elasticsearch，服务端如不需要连接凭证，则该项可为空

2. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		aliyun服务的accessKeySecret，用在私有云环境下，例如自建Elasticsearch，服务端如不需要连接凭证，则该项可为空

## com.qlangtech.plugins.incr.flink.launch.CheckpointFactory

### com.qlangtech.plugins.incr.flink.launch.ckpt.CKOff

* **显示名:** off 

* **全路径名:** [com.qlangtech.plugins.incr.flink.launch.ckpt.CKOff](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-realtime-flink/src/main/java/com/qlangtech/plugins/incr/flink/launch/ckpt/CKOff.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-realtime-flink.tpi](./tpis#tis-realtime-flinktpi)

### com.qlangtech.plugins.incr.flink.launch.ckpt.CKOn

* **显示名:** on 

* **全路径名:** [com.qlangtech.plugins.incr.flink.launch.ckpt.CKOn](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-realtime-flink/src/main/java/com/qlangtech/plugins/incr/flink/launch/ckpt/CKOn.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-realtime-flink.tpi](./tpis#tis-realtime-flinktpi)

* **配置项说明:** 

1. ckpointInterval

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 200
	* **说明:** 

		Gets the interval in which checkpoints are periodically scheduled.<br /><br />This setting defines the base interval. Checkpoint triggering may be delayed by the settings <code class="highlighter-rouge">execution.checkpointing.max-concurrent-checkpoints</code> and <code class="highlighter-rouge">execution.checkpointing.min-pause</code>
		
		 单位：`秒`

2. checkpointMode

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** EXACTLY_ONCE
	* **说明:** 

		The checkpointing mode (exactly-once vs. at-least-once).

3. checkpointTimeout

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 600
	* **说明:** 

		The maximum time that a checkpoint may take before being discarded.
		
		 单位：`秒`

4. maxConcurrentNum

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 

		The maximum number of checkpoint attempts that may be in progress at the same time. If this value is n, then no checkpoints will be triggered while n checkpoint attempts are currently in flight. For the next checkpoint to be triggered, one checkpoint attempt would need to finish or expire.

5. minPause

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 0
	* **说明:** 

		The minimal pause between checkpointing attempts. This setting defines how soon thecheckpoint coordinator may trigger another checkpoint after it becomes possible to triggeranother checkpoint with respect to the maximum number of concurrent checkpoints(see <code class="highlighter-rouge">execution.checkpointing.max-concurrent-checkpoints</code>).<br /><br />If the maximum number of concurrent checkpoints is set to one, this setting makes effectively sure that a minimum amount of time passes where no checkpoint is in progress at all.
		
		 单位：`秒`

6. maxFaildNum

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 0
	* **说明:** 

		The tolerable checkpoint consecutive failure number. If set to 0, that means we do not tolerance any checkpoint failure. This only applies to the following failure reasons: IOException on the Job Manager, failures in the async phase on the Task Managers and checkpoint expiration due to a timeout. Failures originating from the sync phase on the Task Managers are always forcing failover of an affected task. Other types of checkpoint failures (such as checkpoint being subsumed) are being ignored.

7. enableExternal

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** RETAIN_ON_CANCELLATION
	* **说明:** 

		Externalized checkpoints write their meta data out to persistent storage and are not automatically cleaned up when the owning job fails or is suspended (terminating with job status <code class="highlighter-rouge">JobStatus#FAILED</code> or <code class="highlighter-rouge">JobStatus#SUSPENDED</code>). In this case, you have to manually clean up the checkpoint state, both the meta data and actual program state.<br /><br />The mode defines how an externalized checkpoint should be cleaned up on job cancellation. If you choose to retain externalized checkpoints on cancellation you have to handle checkpoint clean up manually when you cancel the job as well (terminating with job status <code class="highlighter-rouge">JobStatus#CANCELED</code>).<br /><br />The target directory for externalized checkpoints is configured via <code class="highlighter-rouge">state.checkpoints.dir</code>.

8. enableUnaligned

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 

		Enables unaligned checkpoints, which greatly reduce checkpointing times under backpressure.<br /><br />Unaligned checkpoints contain data stored in buffers as part of the checkpoint state, which allows checkpoint barriers to overtake these buffers. Thus, the checkpoint duration becomes independent of the current throughput as checkpoint barriers are effectively not embedded into the stream of data anymore.<br /><br />Unaligned checkpoints can only be enabled if <code class="highlighter-rouge">execution.checkpointing.mode</code> is <code class="highlighter-rouge">EXACTLY_ONCE</code> and if <code class="highlighter-rouge">execution.checkpointing.max-concurrent-checkpoints</code> is 1

9. forceUnaligned

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 

		Forces unaligned checkpoints, particularly allowing them for iterative jobs.

## com.qlangtech.tis.config.ParamsConfig

### com.qlangtech.tis.plugin.HttpEndpoint

* **显示名:** httpToken 

* **全路径名:** [com.qlangtech.tis.plugin.HttpEndpoint](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-common-plugin/src/main/java/com/qlangtech/tis/plugin/HttpEndpoint.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-common-plugin.tpi](./tpis#tis-datax-common-plugintpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. endpoint

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** http://oss.aliyuncs.com
	* **说明:** 		Server的EndPoint地址，例如http://oss.aliyuncs.com

3. 认证方式

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** none
	* **说明:** 		无

### com.qlangtech.tis.plugin.datax.DataXGlobalConfig

* **显示名:** DataX-global 

* **全路径名:** [com.qlangtech.tis.plugin.datax.DataXGlobalConfig](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-common-plugin/src/main/java/com/qlangtech/tis/plugin/datax/DataXGlobalConfig.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-common-plugin.tpi](./tpis#tis-datax-common-plugintpi)

* **配置项说明:** 

1. 名称

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. channel

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 3
	* **说明:** 		无

3. 最大错误记录数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 0
	* **说明:** 		无

4. 最大错误百分比

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 0.02
	* **说明:** 		无

5. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.datax.IDataxGlobalCfg.getDefaultTemplate()
	* **说明:** 		无

### com.qlangtech.tis.plugin.datax.server.FTPServer

* **显示名:** FTPServer 

* **全路径名:** [com.qlangtech.tis.plugin.datax.server.FTPServer](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dfs-plugin/src/main/java/com/qlangtech/tis/plugin/datax/server/FTPServer.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dfs-plugin.tpi](./tpis#tis-datax-dfs-plugintpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. protocol

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** ftp
	* **说明:** 

		SFTP 和 FTP 非常相似，都支持批量传输（一次传输多个文件），文件夹 / 目录导航，文件移动，文件夹 / 目录创建，文件删除等。但还是存在着差异，SFTP 和 FTP 之间的区别：
		
		* 链接方式不同
		
		    FTP 使用 TCP 端口 21 上的控制连接建立连接。而 SFTP 是在客户端和服务器之间通过 SSH 协议 (TCP 端口 22) 建立的安全连接来传输文件。
		
		* 安全性不同
		
		    SFTP 使用加密传输认证信息和传输的数据，所以使用 SFTP 相对于 FTP 是非常安全。
		
		* 效率不同
		
		    SFTP 这种传输方式使用了加密解密技术，所以传输效率比普通的 FTP 要低得多。
		
		* 使用的协议不同
		
		    FTP 使用 TCP / IP 协议。而，SFTP 是 SSH 协议的一部分，它是一种远程登录信息。
		
		* 安全通道
		
		    FTP 不提供任何安全通道来在主机之间传输文件；而 SFTP 协议提供了一个安全通道，用于在网络上的主机之间传输文件。

3. host

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：ftp服务器地址。 

4. port

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 21
	* **说明:** 		描述：ftp服务器端口。 

5. timeout

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 60000
	* **说明:** 		描述：连接ftp服务器连接超时时间，单位毫秒。默认值：60000（1分钟）

6. 连接模式

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** PASV
	* **说明:** 

		连接模式（主动模式或者被动模式）。该参数只在传输协议是标准ftp协议时使用，值只能为：**PORT (主动)**，**PASV（被动）**。两种模式主要的不同是数据连接建立的不同。
		
		 1. 对于Port模式，是客户端在本地打开一个端口等服务器去连接建立数据连接，
		
		 2. 而Pasv模式就是服务器打开一个端口等待客户端去建立一个数据连接。

7. username

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：ftp服务器访问用户名。 

8. password

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：ftp服务器访问密码。 

### com.qlangtech.tis.plugin.datax.doplinscheduler.export.DolphinSchedulerEndpoint

* **显示名:** ds-endpoint 

* **全路径名:** [com.qlangtech.tis.plugin.datax.doplinscheduler.export.DolphinSchedulerEndpoint](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dolphinscheduler-plugin/src/main/java/com/qlangtech/tis/plugin/datax/doplinscheduler/export/DolphinSchedulerEndpoint.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dolphinscheduler-plugin.tpi](./tpis#tis-datax-dolphinscheduler-plugintpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. serverPath

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

3. serverToken

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

### com.qlangtech.tis.plugin.datax.elastic.ElasticEndpoint

* **显示名:** elasticToken 

* **全路径名:** [com.qlangtech.tis.plugin.datax.elastic.ElasticEndpoint](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-elasticsearch-plugin/src/main/java/com/qlangtech/tis/plugin/datax/elastic/ElasticEndpoint.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-elasticsearch-plugin.tpi](./tpis#tis-datax-elasticsearch-plugintpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. endpoint

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** http://oss.aliyuncs.com
	* **说明:** 		Server的EndPoint地址，例如http://oss.aliyuncs.com

3. 认证方式

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** none
	* **说明:** 		无

### com.qlangtech.tis.plugin.datax.LocalDataXJobSubmitParams

* **显示名:** DataXSubmitParams 

* **全路径名:** [com.qlangtech.tis.plugin.datax.LocalDataXJobSubmitParams](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-local-executor/src/main/java/com/qlangtech/tis/plugin/datax/LocalDataXJobSubmitParams.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-local-executor.tpi](./tpis#tis-datax-local-executortpi)

* **配置项说明:** 

1. name

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** local_submit_params
	* **说明:** 		设置一个有意义的名称作为标识

2. maxJobs

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.datax.DataXJobSubmitParams.dftMaxJobs()
	* **说明:** 		单个管道最大DataX同步任务数量，超过该任务数量管道触发执行时会报错

3. 管道任务并发数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.datax.DataXJobSubmitParams.dftParallelism()
	* **说明:** 		在单个管道同步过程中允许任务并发数目

4. VM任务并发数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.datax.DataXJobSubmitParams.dftParallelism()
	* **说明:** 		单机版中允许多个同步管道并行执行，由于单机节点内存有限，需要确保VM级别设置DataX任务并发执行数目

5. 任务超时时间

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 6
	* **说明:** 		执行单个DataX 表任务执行超时时间。超过设置的超时时间，TIS会主动将任务关闭。单位：小时

6. 内存规格

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** default
	* **说明:** 		执行DataX任务申请内存规格,默认为1024兆，如执行大表同步任务请按照实际需求量设置自定义规格

### :closed_lock_with_key:com.qlangtech.tis.plugin.aliyun.AliyunEndpoint

* **显示名:** aliyunToken 

* **全路径名:** [com.qlangtech.tis.plugin.aliyun.AliyunEndpoint](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-datax-commercial/tis-datax-oss-plugin/src/main/java/com/qlangtech/tis/plugin/aliyun/AliyunEndpoint.java) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-datax-oss-plugin.tpi](./tpis#tis-datax-oss-plugintpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. endpoint

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** http://oss.aliyuncs.com
	* **说明:** 		Server的EndPoint地址，例如http://oss.aliyuncs.com

3. 认证方式

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** accessKey
	* **说明:** 		无

### com.qlangtech.tis.config.spark.impl.DefaultSparkConnGetter

* **显示名:** SparkConn 

* **全路径名:** [com.qlangtech.tis.config.spark.impl.DefaultSparkConnGetter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/config/spark/impl/DefaultSparkConnGetter.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. 连接方式

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		客户端连接Spark服务端可选择以下连接方式之一：
		
		* [Amazon EC2](https://github.com/amplab/spark-ec2): scripts that let you launch a cluster on EC2 in about 5 minutes
		* [Standalone Deploy Mode](https://spark.apache.org/docs/2.4.4/spark-standalone.html): launch a standalone cluster quickly without a third-party cluster manager
		* [Mesos](https://spark.apache.org/docs/2.4.4/running-on-mesos.html): deploy a private cluster using Apache Mesos
		* [YARN](https://spark.apache.org/docs/2.4.4/running-on-yarn.html): deploy Spark on top of Hadoop NextGen (YARN)
		* [Kubernetes](https://spark.apache.org/docs/2.4.4/running-on-kubernetes.html#cluster-mode): deploy Spark on top of Kubernetes
		
		例如，选择**Standalone Deploy Mode**模式模式，可设置：`spark://192.168.28.201:7077`

### com.qlangtech.tis.config.yarn.YarnConfig

* **显示名:** yarn 

* **全路径名:** [com.qlangtech.tis.config.yarn.YarnConfig](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/config/yarn/YarnConfig.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. rmAddress
	* **类型:** 单行文本
	* **必须:** 是
3. schedulerAddress
	* **类型:** 单行文本
	* **必须:** 是
### com.qlangtech.tis.hive.DefaultHiveConnGetter

* **显示名:** HiveConn 

* **全路径名:** [com.qlangtech.tis.hive.DefaultHiveConnGetter](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/hive/DefaultHiveConnGetter.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. dbName

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** default
	* **说明:** 		Hive 数据库使用的库名，请在执行任务前先创建完成

3. metaStoreUrls
	* **类型:** 单行文本
	* **必须:** 是
4. hiveAddress
	* **类型:** 单行文本
	* **必须:** 是
5. userToken
	* **类型:** 单行文本
	* **必须:** 是
### com.qlangtech.tis.config.k8s.impl.DefaultK8sContext

* **显示名:** k8s 

* **全路径名:** [com.qlangtech.tis.config.k8s.impl.DefaultK8sContext](https://github.com/qlangtech/plugins/tree/master/tis-k8s-plugin/src/main/java/com/qlangtech/tis/config/k8s/impl/DefaultK8sContext.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-k8s-plugin.tpi](./tpis#tis-k8s-plugintpi)

* **配置项说明:** 

1. 名称

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. 连接地址

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

3. Yaml配置内容

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		为了通过CS模式连接K8S服务端可以先通过kubectl config命令生成服务端连接的证书配置文件，config命令请查看
		[kubectl-commands#config](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#config)
		
		执行 `kubectl config view  --flatten=true` 将得到的内容粘贴到上面输入框中
		
		> TIS中有较多组件是运行在K8S容器中的，需要在TIS运行环境中安装部署K8S环境。有多种方式安装K8S环境，[详细请查看](http://tis.pub/blog/k8s-using/)

### com.qlangtech.tis.kerberos.KerberosCfg

* **显示名:** kerberos 

* **全路径名:** [com.qlangtech.tis.kerberos.KerberosCfg](https://github.com/qlangtech/plugins/tree/master/tis-kerberos-plugin/src/main/java/com/qlangtech/tis/kerberos/KerberosCfg.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-kerberos-plugin.tpi](./tpis#tis-kerberos-plugintpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. principal

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		[详细说明](https://docs.cloudera.com/documentation/enterprise/5-3-x/topics/cm_sg_principal_keytab.html)
		
		Kerberos 下的用户可以称为 Principal，缩写可以是 pric（见于一些配置文件中），由三个部分组成，分别是 primary, instance 和 realm。Kerberos principal 用于使用 Kerberos 做为安全加固的系统中，来代表一个用户唯一的身份。primary 又称为用户 user component，可以是任意的字符串或者就是操作系统下的用户名等等。
		
		然后接着的部分叫做 instance，是用来给某个角色的用户或者服务来创建 principal 的。一个 instance，会被 "/" 和 primary 分隔。最后一个部分是 realm，概念上很像 DNS 上的 domain 域名，可以用来定义一组相似的对象，也可以说 realm 定义了一组 principals。每一个 realm 可以有私有的配置，包括 KDC 的地址和加密的算法，都可以独立存在。有些大型公司通常会创建一个独立的 realm 来分发管理员的权限。
		
		Kerberos 给 principal 指定 ticket 票据，让他们可以访问用 Kerberos 做安全加固的 Hadoop 服务。principal 可以形如: username/fully.qualified.domain.name@YOUR_REALM.COM。username 是指原型 Hadoop 服务的 Unix 账户，例如 hdfs 或者 mapred 之类的。
		
		而对于个人用户（指那些需要访问集群，比如 Hive Client 或者 HDFS Client 连接的这些），username 也是指 Unix 账号，例如 Tony, runzhliu 之类。只包含 primary 的 principal 也是可以接受的，例如 runzhliu@YOUR_REALM.COM。

3. keytabPath

	* **类型:** 文件
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		Keytab 就是一个包含了（若干）principals 和一个加密了的 principal key的文件。一个 Keytab 文件每个 host 都是唯一的，因为 principal 的定义了包含了 hostname 的。这个文件可以用来认证，而不需要传递公开的密码，因为只要有这个 Keytab 就可以代表这个 principal 来操作 Hadoop 的服务。所以说 Keytab 是需要保管好的。

4. krb5Res

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** SystemPath
	* **说明:** 

		maintains key-value pairs of Kerberos configurable constants from configuration file or from user specified system properties.
		
		The content is path of file with default path '/etc/krb5.conf'
		
		There are two types of input method 
		1. Upload 
		
		   By upload a File that the content is compatible with '/etc/krb5.conf'
		
		2. SystemPath
		
		   By reference to the path of `krb5.conf` with default location of '/etc/krb5.conf'

### com.qlangtech.plugins.incr.flink.common.FlinkCluster

* **显示名:** Flink-Cluster 

* **全路径名:** [com.qlangtech.plugins.incr.flink.common.FlinkCluster](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-realtime-flink/src/main/java/com/qlangtech/plugins/incr/flink/common/FlinkCluster.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-realtime-flink.tpi](./tpis#tis-realtime-flinktpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. JMAddress

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 127.0.0.1:8081
	* **说明:** 

		The JobManager is serving the web interface accessible at localhost:8081

3. maxRetry

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 

		The number of retries the client will attempt if a retryable operations fails.

4. retryDelay

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 3000
	* **说明:** 

		The time in ms that the client waits between retries (See also `rest.retry.max-attempts`).

## com.qlangtech.tis.plugin.tdfs.DFSResMatcher

### com.qlangtech.tis.plugin.datax.resmatcher.MetaAwareDFSResMatcher

* **显示名:** ByMeta 

* **全路径名:** [com.qlangtech.tis.plugin.datax.resmatcher.MetaAwareDFSResMatcher](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dfs-plugin/src/main/java/com/qlangtech/tis/plugin/datax/resmatcher/MetaAwareDFSResMatcher.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dfs-plugin.tpi](./tpis#tis-datax-dfs-plugintpi)

### com.qlangtech.tis.plugin.datax.resmatcher.WildcardDFSResMatcher

* **显示名:** Wildcard 

* **全路径名:** [com.qlangtech.tis.plugin.datax.resmatcher.WildcardDFSResMatcher](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dfs-plugin/src/main/java/com/qlangtech/tis/plugin/datax/resmatcher/WildcardDFSResMatcher.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dfs-plugin.tpi](./tpis#tis-datax-dfs-plugintpi)

* **配置项说明:** 

1. wildcard

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		路径中可以使用统配符匹配资源目录下的所有匹配的文件资源
		
		Checks a fileName to see if it matches the specified wildcard matcher,
		always testing case-sensitive.
		      <p>
		      The wildcard matcher uses the characters '?' and '*' to represent a
		      single or multiple (zero or more) wildcard characters.
		      This is the same as often found on Dos/Unix command lines.
		      The check is case-sensitive always.
		      </p>
		<pre>
		      wildcardMatch("c.txt", "*.txt")      --&gt; true
		      wildcardMatch("c.txt", "*.jpg")      --&gt; false
		      wildcardMatch("a/b/c.txt", "a/b/*")  --&gt; true
		      wildcardMatch("c.txt", "*.???")      --&gt; true
		      wildcardMatch("c.txt", "*.????")     --&gt; false
		</pre>
		
		* N.B. the sequence "*?" does not work properly at present in match strings.

2. 遍历层数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		描述：允许遍历文件夹的最大层数。

## com.qlangtech.tis.plugin.datax.kingbase.KingBaseDispatch

### com.qlangtech.tis.plugin.datax.kingbase.dispatch.Off

* **显示名:** off 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kingbase.dispatch.Off](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-kingbase-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kingbase/dispatch/Off.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-kingbase-plugin.tpi](./tpis#tis-datax-kingbase-plugintpi)

### com.qlangtech.tis.plugin.datax.kingbase.dispatch.On

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kingbase.dispatch.On](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-kingbase-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kingbase/dispatch/On.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-kingbase-plugin.tpi](./tpis#tis-datax-kingbase-plugintpi)

* **配置项说明:** 

1. 备机地址

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		备机地址，可配置多条，按行分隔，每行一条地址，样例如下：
		``` shell
		192.168.8.223:54321
		192.168.8.130:54321
		```

2. loadRate

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 0
	* **说明:** 		主机读负载率，备机之间轮询平分，取值范围0-100,例如0表示读语句全部分发备机，100表示读语句全部发送主机

## com.qlangtech.tis.plugin.datax.kafka.reader.StartOffset

### com.qlangtech.tis.plugin.datax.kafka.reader.offsets.CommittedOffsets

* **显示名:** Committed Offset 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kafka.reader.offsets.CommittedOffsets](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-kafka-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kafka/reader/offsets/CommittedOffsets.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-kafka-plugin.tpi](./tpis#tis-flink-cdc-kafka-plugintpi)

### com.qlangtech.tis.plugin.datax.kafka.reader.offsets.EarliestOffsets

* **显示名:** Earliest Offset 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kafka.reader.offsets.EarliestOffsets](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-kafka-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kafka/reader/offsets/EarliestOffsets.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-kafka-plugin.tpi](./tpis#tis-flink-cdc-kafka-plugintpi)

### com.qlangtech.tis.plugin.datax.kafka.reader.offsets.EarliestWhenNoneCommittedOffsets

* **显示名:** Earliest When None Committed Offset 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kafka.reader.offsets.EarliestWhenNoneCommittedOffsets](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-kafka-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kafka/reader/offsets/EarliestWhenNoneCommittedOffsets.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-kafka-plugin.tpi](./tpis#tis-flink-cdc-kafka-plugintpi)

### com.qlangtech.tis.plugin.datax.kafka.reader.offsets.LatestOffsets

* **显示名:** Latest Offset 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kafka.reader.offsets.LatestOffsets](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-kafka-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kafka/reader/offsets/LatestOffsets.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-kafka-plugin.tpi](./tpis#tis-flink-cdc-kafka-plugintpi)

### com.qlangtech.tis.plugin.datax.kafka.reader.offsets.TimestampOffsets

* **显示名:** Timestamp Offset 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kafka.reader.offsets.TimestampOffsets](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-kafka-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kafka/reader/offsets/TimestampOffsets.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-kafka-plugin.tpi](./tpis#tis-flink-cdc-kafka-plugintpi)

* **配置项说明:** 

1. timestamp
	* **类型:** 日期
	* **必须:** 是
## com.qlangtech.tis.plugin.ds.DataSourceFactoryManipulate

### :closed_lock_with_key:com.qlangtech.tis.plugin.ds.manipulate.CloneDataSourceFactory

* **显示名:** Clone 

* **全路径名:** [com.qlangtech.tis.plugin.ds.manipulate.CloneDataSourceFactory](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-split-table-strategy-plugin/src/main/java/com/qlangtech/tis/plugin/ds/manipulate/CloneDataSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-split-table-strategy-plugin.tpi](./tpis#tis-split-table-strategy-plugintpi)

* **配置项说明:** 

1. 新实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		填写新实例名称，不能与已存在的数据源实例重名

## com.qlangtech.plugins.incr.flink.launch.clustertype.ClusterType

### :closed_lock_with_key:com.qlangtech.plugins.incr.flink.launch.clustertype.KubernetesApplication

* **显示名:** kubernetes-application 

* **全路径名:** [com.qlangtech.plugins.incr.flink.launch.clustertype.KubernetesApplication](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-incr-commercial/tis-flink-k8s-plugin/src/main/java/com/qlangtech/plugins/incr/flink/launch/clustertype/KubernetesApplication.java) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-flink-k8s-plugin.tpi](./tpis#tis-flink-k8s-plugintpi)

* **配置项说明:** 

1. clusterId

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** tis-flink-cluster-2
	* **说明:** 

		The cluster-id, which should be no more than 45 characters, is used for identifying a unique Flink cluster. The id must only contain lowercase alphanumeric characters and "-". The required format is <code class="highlighter-rouge">[a-z](.)</code>. If not set, the client will automatically generate it with a random ID.

2. 集群配置

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		管理已创建的集群配置引用，如还未创建则不选，在下一步流程中创建集群配置

### :closed_lock_with_key:com.qlangtech.plugins.incr.flink.launch.clustertype.KubernetesSession

* **显示名:** kubernetes-session 

* **全路径名:** [com.qlangtech.plugins.incr.flink.launch.clustertype.KubernetesSession](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-incr-commercial/tis-flink-k8s-plugin/src/main/java/com/qlangtech/plugins/incr/flink/launch/clustertype/KubernetesSession.java) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-flink-k8s-plugin.tpi](./tpis#tis-flink-k8s-plugintpi)

* **配置项说明:** 

1. flinkCluster

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

### com.qlangtech.plugins.incr.flink.launch.clustertype.Standalone

* **显示名:** Standalone 

* **全路径名:** [com.qlangtech.plugins.incr.flink.launch.clustertype.Standalone](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-realtime-flink/src/main/java/com/qlangtech/plugins/incr/flink/launch/clustertype/Standalone.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-realtime-flink.tpi](./tpis#tis-realtime-flinktpi)

* **配置项说明:** 

1. flinkCluster

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		Standalone 集群: [详细请查看](https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/deployment/resource-providers/standalone/overview/)
		
		[安装说明](http://tis.pub/docs/install/flink-cluster/standalone/):
		1. 下载、解压
		
		   ```shell script
		     wget http://tis-release.oss-cn-beijing.aliyuncs.com/4.2.0-SNAPSHOT/tis/flink-tis-1.18.1-bin.tar.gz && rm -rf flink-tis-1.18.1 && mkdir flink-tis-1.18.1 && tar xvf flink-tis-1.18.1-bin.tar.gz -C ./flink-tis-1.18.1
		   ```
		2. 修改 `$FLINK_HOME/conf/flink-conf.yaml`
		
		   ```yaml
		   # The address that the REST & web server binds to
		   # By default, this is localhost, which prevents the REST & web server from
		   # being able to communicate outside of the machine/container it is running on.
		   #
		   # To enable this, set the bind address to one that has access to outside-facing
		   # network interface, such as 0.0.0.0.
		   #
		   rest.bind-address: 0.0.0.0
		    ```
		   这样使Flink启动之后，可以从其他机器节点访问flink所在的节点
		
		   ```yaml
		   # The number of task slots that each TaskManager offers. Each slot runs one parallel pipeline.
		   taskmanager.numberOfTaskSlots: 1
		   ```
		   默认值是1，需要在单个Flink节点上运行多个Flink任务，可修改成大于1的值就行（一般情况slot代表了服务节点的资源并行处理能力，一般配置于节点CPU核数相一致即可）
		
		3. 启动Flink-Cluster：
		   ```shell script
		    ./bin/start-cluster.sh
		   ```

## com.qlangtech.tis.plugin.datax.doplinscheduler.export.DSTargetTables

### :closed_lock_with_key:com.qlangtech.tis.plugin.datax.doplinscheduler.export.impl.UnlimitDSTargetTables

* **显示名:** Unlimited 

* **全路径名:** [com.qlangtech.tis.plugin.datax.doplinscheduler.export.impl.UnlimitDSTargetTables](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-datax-commercial/tis-datax-dolphinscheduler-commercial-plugin/src/main/java/com/qlangtech/tis/plugin/datax/doplinscheduler/export/impl/UnlimitDSTargetTables.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-datax-dolphinscheduler-commercial-plugin.tpi](./tpis#tis-datax-dolphinscheduler-commercial-plugintpi)

* **配置项说明:** 

1. 目标表

	* **类型:** 多选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		请选择需要同步到DolphinScheduler的表

### com.qlangtech.tis.plugin.datax.doplinscheduler.export.impl.LimitDSTargetTables

* **显示名:** Limited 

* **全路径名:** [com.qlangtech.tis.plugin.datax.doplinscheduler.export.impl.LimitDSTargetTables](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dolphinscheduler-plugin/src/main/java/com/qlangtech/tis/plugin/datax/doplinscheduler/export/impl/LimitDSTargetTables.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dolphinscheduler-plugin.tpi](./tpis#tis-datax-dolphinscheduler-plugintpi)

* **配置项说明:** 

1. 目标表

	* **类型:** 多选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

## com.qlangtech.tis.datax.DataXJobSubmit

### com.qlangtech.tis.plugin.datax.doplinscheduler.DolphinschedulerDistributedSPIDataXJobSubmit

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dolphinscheduler-plugin.tpi](./tpis#tis-datax-dolphinscheduler-plugintpi)

### com.qlangtech.tis.plugin.datax.EmbeddedDataXJobSubmit

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-local-embedded-executor.tpi](./tpis#tis-datax-local-embedded-executortpi)

### com.qlangtech.tis.plugin.datax.LocalDataXJobSubmit

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-local-executor.tpi](./tpis#tis-datax-local-executortpi)

### com.qlangtech.tis.plugin.datax.DistributedPowerJobDataXJobSubmit

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-local-powerjob-executor.tpi](./tpis#tis-datax-local-powerjob-executortpi)

## com.qlangtech.tis.plugin.datax.powerjob.TriggerStrategy

### com.qlangtech.tis.plugin.datax.powerjob.impl.trigger.CrontabTriggerStrategy

* **显示名:** Crontab 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.impl.trigger.CrontabTriggerStrategy](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-local-powerjob-executor/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/impl/trigger/CrontabTriggerStrategy.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-local-powerjob-executor.tpi](./tpis#tis-datax-local-powerjob-executortpi)

* **配置项说明:** 

1. 表达式

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		填写 CRON 表达式 [在线生成网站](https://cron.qqe2.com/)
		
		例子：
		
		1. `0 0 12 * * ?`    每天中午12点触发
		2. `0 15 10 ? * *`    每天上午10:15触发
		3. `0 15 10 * * ? 2005`    2005年的每天上午10:15触发

### com.qlangtech.tis.plugin.datax.powerjob.impl.trigger.NoneTriggerStrategy

* **显示名:** off 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.impl.trigger.NoneTriggerStrategy](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-local-powerjob-executor/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/impl/trigger/NoneTriggerStrategy.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-local-powerjob-executor.tpi](./tpis#tis-datax-local-powerjob-executortpi)

## com.qlangtech.tis.plugin.datax.kingbase.KingBaseCompatibleMode

### com.qlangtech.tis.plugin.datax.kingbase.mode.MySQLMode

* **显示名:** MySQL 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kingbase.mode.MySQLMode](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-chunjun-mysql-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kingbase/mode/MySQLMode.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-mysql-plugin.tpi](./tpis#tis-flink-chunjun-mysql-plugintpi)

* **配置项说明:** 

1. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		当该数据源作为目标端，是否支持自动在目标端中创建表？

### com.qlangtech.tis.plugin.datax.kingbase.mode.OracleMode

* **显示名:** Oracle 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kingbase.mode.OracleMode](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-chunjun-oracle-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kingbase/mode/OracleMode.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-oracle-plugin.tpi](./tpis#tis-flink-chunjun-oracle-plugintpi)

* **配置项说明:** 

1. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		当该数据源作为目标端，是否支持自动在目标端中创建表？

### com.qlangtech.tis.plugin.datax.kingbase.mode.PGMode

* **显示名:** Postgres 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kingbase.mode.PGMode](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-chunjun-postgresql-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kingbase/mode/PGMode.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-chunjun-postgresql-plugin.tpi](./tpis#tis-flink-chunjun-postgresql-plugintpi)

* **配置项说明:** 

1. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		当该数据源作为目标端，是否支持自动在目标端中创建表？

## com.qlangtech.tis.async.message.client.consumer.impl.MQListenerFactory

### com.qlangtech.tis.plugin.kafka.consumer.KafkaMQListenerFactory

* **显示名:** Kafka 

* **全路径名:** [com.qlangtech.tis.plugin.kafka.consumer.KafkaMQListenerFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-kafka-plugin/src/main/java/com/qlangtech/tis/plugin/kafka/consumer/KafkaMQListenerFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-kafka-plugin.tpi](./tpis#tis-flink-cdc-kafka-plugintpi)

* **配置项说明:** 

1. 独立监听

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 

		执行Flink任务过程中，监听分配独立的Slot计算资源不会与下游计算算子混合在一起。
		
		如开启，带来的好处是运算时资源各自独立不会相互相互影响，弊端是，上游算子与下游算子独立在两个Solt中需要额外的网络传输开销

2. Startint Offsets

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** Latest Offset
	* **说明:** 

		Kafka消费起始位置，有以下策略可供选择
		
		* `Committed Offset`: Start from committed offset of the consuming group, without reset strategy. An exception will be
		  thrown at runtime if there is no committed offsets.
		* `Earliest Offset`: Start from earliest offset
		* `Earliest When None Committed Offset`:  Start from committed offset, also use EARLIEST as reset strategy if committed
		  offset doesn't exist
		* `Latest Offset`: (default) Start from latest offset
		* `Timestamp Offset`: Start from the first record whose timestamp is greater than or equals a timestamp (milliseconds)

3. 过滤

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		可以将数据流中将某一种事件类型的事件过滤掉，有以下几种类型可以选择：INSERT, UPDATE_BEFORE, UPDATE_AFTER, DELETE

### com.qlangtech.plugins.incr.flink.cdc.kingbase.FlinkCDCKingBaseSourceFactory

* **显示名:** Flink-CDC-KingBase 

* **全路径名:** [com.qlangtech.plugins.incr.flink.cdc.kingbase.FlinkCDCKingBaseSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-kingbase-plugin/src/main/java/com/qlangtech/plugins/incr/flink/cdc/kingbase/FlinkCDCKingBaseSourceFactory.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-kingbase-plugin.tpi](./tpis#tis-flink-cdc-kingbase-plugintpi)

* **配置项说明:** 

1. 解码器

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** decoderbufs
	* **说明:** 		The name of the KingBase logical decoding plug-in installed on the server. Supported values are decoderbufs

2. 起始位点

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** latest
	* **说明:** 

		Debezium startup options
		
		参数详细请参考：[https://ververica.github.io/flink-cdc-connectors/master/content/connectors/postgres-cdc.html#incremental-snapshot-options](https://ververica.github.io/flink-cdc-connectors/master/content/connectors/postgres-cdc.html#incremental-snapshot-options)
		
		* `Initial`:
		  Performs an initial snapshot on the monitored database tables upon first startup, and continue to read the latest binlog.     
		
		* `Latest`:
		  Never to perform snapshot on the monitored database tables upon first startup, just read from the end of the binlog which means only have the changes since the connector was started.

3. REPLICA IDENTITY

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** DEFAULT
	* **说明:** 

		在 PostgreSQL 中，ALTER TABLE ... REPLICA IDENTITY 命令用于指定在逻辑复制或行级触发器中如何标识已更新或删除的行。https://developer.aliyun.com/ask/575334
		
		可选项有以下两个
		* `FULL`: 使用此值需要确保对应的表执行`ALTER TABLE your_table_name REPLICA IDENTITY FULL;`，表记录更新时会带上更新Before值，使用此方式比较耗费性能。
		* `DEFAULT`: 默认值，更新删除操作时不会带上Before值。

4. 过滤

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		可以将数据流中将某一种事件类型的事件过滤掉，有以下几种类型可以选择：INSERT, UPDATE_BEFORE, UPDATE_AFTER, DELETE

### com.qlangtech.plugins.incr.flink.cdc.mongdb.FlinkCDCMongoDBSourceFactory

* **显示名:** Flink-CDC-MongoDB 

* **全路径名:** [com.qlangtech.plugins.incr.flink.cdc.mongdb.FlinkCDCMongoDBSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-mongdb-plugin/src/main/java/com/qlangtech/plugins/incr/flink/cdc/mongdb/FlinkCDCMongoDBSourceFactory.java) 

* **提供者:** [FlinkCDC](https://ververica.github.io/flink-cdc-connectors) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-mongdb-plugin.tpi](./tpis#tis-flink-cdc-mongdb-plugintpi)

* **配置项说明:** 

1. 起始位点

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** LATEST_OFFSET
	* **说明:** 

		Debezium startup options
		
		参数详细请参考：[https://nightlies.apache.org/flink/flink-cdc-docs-master/docs/connectors/flink-sources/mongodb-cdc/#startup-reading-position](https://nightlies.apache.org/flink/flink-cdc-docs-master/docs/connectors/flink-sources/mongodb-cdc/#startup-reading-position)
		
		* `Initial`:
		  Performs an initial snapshot on the monitored database tables upon first startup, and continue to read the latest oplog.
		
		* `Latest`(default):
		  Never to perform snapshot on the monitored database tables upon first startup, just read from the end of the oplog which means only have the changes since the connector was started.
		
		* `Timestamp`:
		  Skip snapshot phase and start reading oplog events from a specific timestamp.

2. 补全策略

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** UPDATE_LOOKUP
	* **说明:** 

		MongoDB 发生更新时候，before数据获取策略，目前有两种方式
		1. FULL_CHANGE_LOG: （包括： `RowKind.UPDATE_BEFORE`,`RowKind.UPDATE_AFTER` 两种类型消息） [Full Changelog详细参考](https://nightlies.apache.org/flink/flink-cdc-docs-master/docs/connectors/flink-sources/mongodb-cdc/#full-changeloga-namefull-changelog-id003-a)
		2. UPDATE_LOOKUP: 通过 CDC内部合并更新内容和更新之前的整条记录值（包括： 只有`RowKind.UPDATE_AFTER`一种类型消息）

3. 过滤

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		可以将数据流中将某一种事件类型的事件过滤掉，有以下几种类型可以选择：INSERT, UPDATE_BEFORE, UPDATE_AFTER, DELETE

4. Conn Options

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		The ampersand-separated connection options of MongoDB. eg: `replicaSet=test&connectTimeoutMS=300000`
		
		Default: none
		
		https://docs.mongodb.com/manual/reference/connection-string/#std-label-connections-connection-options

5. copyExistingPipeline

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		An array of JSON objects describing the pipeline operations to run when copying existing data.
		
		This can improve the use of indexes by the copying manager and make copying more efficient. 
		eg. 
		```json
		[{"$match": {"closed": "false"}}] 
		```
		ensures that only documents in which the closed field is set to false are copied.

### com.qlangtech.tis.plugins.incr.flink.cdc.maria.FlinkCDCMariaDBSourceFactory

* **显示名:** Flink-CDC-MariaDB 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.cdc.maria.FlinkCDCMariaDBSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-mysql-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/cdc/maria/FlinkCDCMariaDBSourceFactory.java) 

* **提供者:** [FlinkCDC](https://ververica.github.io/flink-cdc-connectors) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-mysql-plugin.tpi](./tpis#tis-flink-cdc-mysql-plugintpi)

* **配置项说明:** 

1. 起始位点

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** LATEST_OFFSET
	* **说明:** 

		Debezium startup options
		
		参数详细请参考：[https://ververica.github.io/flink-cdc-connectors/master/content/connectors/mysql-cdc.html#connector-options](https://ververica.github.io/flink-cdc-connectors/master/content/connectors/mysql-cdc.html#connector-options)
		，[https://debezium.io/documentation/reference/1.5/connectors/mysql.html#mysql-property-snapshot-mode](https://debezium.io/documentation/reference/1.5/connectors/mysql.html#mysql-property-snapshot-mode)
		
		* `Initial`:
		  Performs an initial snapshot on the monitored database tables upon first startup, and continue to read the latest binlog.
		
		* `Earliest`:
		  Never to perform snapshot on the monitored database tables upon first startup, just read from the beginning of the binlog. This should be used with care, as it is only valid when the binlog is guaranteed to contain the entire history of the database.
		
		* `Latest`:
		  Never to perform snapshot on the monitored database tables upon first startup, just read from the end of the binlog which means only have the changes since the connector was started.
		
		* `Timestamp`:
		   Never to perform snapshot on the monitored database tables upon first startup, and directly read binlog from the specified timestamp.
		
		   The consumer will traverse the binlog from the beginning and ignore change events whose timestamp is smaller than the specified timestamp.

2. BinLog独立监听

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 

		执行Flink任务过程中，Binlog监听分配独立的Slot计算资源不会与下游计算算子混合在一起。
		
		如开启，带来的好处是运算时资源各自独立不会相互相互影响，弊端是，上游算子与下游算子独立在两个Solt中需要额外的网络传输开销

3. 所在时区

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugins.incr.flink.cdc.mysql.FlinkCDCMySQLSourceFactory.dftZoneId()
	* **说明:** 		设置MySQL服务端所在时区

4. 过滤

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		可以将数据流中将某一种事件类型的事件过滤掉，有以下几种类型可以选择：INSERT, UPDATE_BEFORE, UPDATE_AFTER, DELETE

### com.qlangtech.tis.plugins.incr.flink.cdc.mysql.FlinkCDCMySQLSourceFactory

* **显示名:** Flink-CDC-MySQL 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.cdc.mysql.FlinkCDCMySQLSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-mysql-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/cdc/mysql/FlinkCDCMySQLSourceFactory.java) 

* **提供者:** [FlinkCDC](https://ververica.github.io/flink-cdc-connectors) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-mysql-plugin.tpi](./tpis#tis-flink-cdc-mysql-plugintpi)

* **配置项说明:** 

1. 起始位点

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** LATEST_OFFSET
	* **说明:** 

		Debezium startup options
		
		参数详细请参考：[https://ververica.github.io/flink-cdc-connectors/master/content/connectors/mysql-cdc.html#connector-options](https://ververica.github.io/flink-cdc-connectors/master/content/connectors/mysql-cdc.html#connector-options)
		，[https://debezium.io/documentation/reference/1.5/connectors/mysql.html#mysql-property-snapshot-mode](https://debezium.io/documentation/reference/1.5/connectors/mysql.html#mysql-property-snapshot-mode)
		
		* `Initial`:
		  Performs an initial snapshot on the monitored database tables upon first startup, and continue to read the latest binlog.
		
		* `Earliest`:
		  Never to perform snapshot on the monitored database tables upon first startup, just read from the beginning of the binlog. This should be used with care, as it is only valid when the binlog is guaranteed to contain the entire history of the database.
		
		* `Latest`:
		  Never to perform snapshot on the monitored database tables upon first startup, just read from the end of the binlog which means only have the changes since the connector was started.
		
		* `Timestamp`:
		   Never to perform snapshot on the monitored database tables upon first startup, and directly read binlog from the specified timestamp.
		
		   The consumer will traverse the binlog from the beginning and ignore change events whose timestamp is smaller than the specified timestamp.

2. BinLog独立监听

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 

		执行Flink任务过程中，Binlog监听分配独立的Slot计算资源不会与下游计算算子混合在一起。
		
		如开启，带来的好处是运算时资源各自独立不会相互相互影响，弊端是，上游算子与下游算子独立在两个Solt中需要额外的网络传输开销

3. 所在时区

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugins.incr.flink.cdc.mysql.FlinkCDCMySQLSourceFactory.dftZoneId()
	* **说明:** 		设置MySQL服务端所在时区

4. 过滤

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		可以将数据流中将某一种事件类型的事件过滤掉，有以下几种类型可以选择：INSERT, UPDATE_BEFORE, UPDATE_AFTER, DELETE

### com.qlangtech.plugins.incr.flink.cdc.oracle.FlinkCDCOracleSourceFactory

* **显示名:** Flink-CDC-Oracle 

* **全路径名:** [com.qlangtech.plugins.incr.flink.cdc.oracle.FlinkCDCOracleSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-oracle-plugin/src/main/java/com/qlangtech/plugins/incr/flink/cdc/oracle/FlinkCDCOracleSourceFactory.java) 

* **提供者:** [FlinkCDC](https://ververica.github.io/flink-cdc-connectors) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-oracle-plugin.tpi](./tpis#tis-flink-cdc-oracle-plugintpi)

* **配置项说明:** 

1. startupOptions

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** latest
	* **说明:** 

		Optional startup mode for Oracle CDC consumer, valid enumerations are "initial" and "latest-offset". Please see Startup Reading Positionsection for more detailed information.
		
		参数详细请参考：[https://ververica.github.io/flink-cdc-connectors/master/content/connectors/oracle-cdc.html#connector-options](https://ververica.github.io/flink-cdc-connectors/master/content/connectors/oracle-cdc.html#connector-options)
		，[https://debezium.io/documentation/reference/1.5/connectors/oracle.html#oracle-connector-properties](https://debezium.io/documentation/reference/1.5/connectors/oracle.html#oracle-connector-properties)
		
		* `Initial`:
		  Performs an initial snapshot on the monitored database tables upon first startup, and continue to read the latest binlog.
		
		* `Latest`:
		 Never to perform a snapshot on the monitored database tables upon first startup, just read from the change since the connector was started.
		
		 **Note**: the mechanism of `scan.startup.mode` option relying on Debezium’s `snapshot.mode` configuration. So please do not use them together. 
		 If you specific both `scan.startup.mode` and `debezium.snapshot.mode` options in the table DDL, it may make `scan.startup.mode` doesn’t work.

2. Log Mining Strategy

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** redo_log_catalog
	* **说明:** 

		There are strategies: Online catalog with faster mining but no captured DDL. Another - with data dictionary loaded into REDO LOG files

3. Supports mining LOB fields and operations

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 

		When set to `false`, the default, LOB fields will not be captured nor emitted. When set to `true`, the connector will capture LOB fields and emit changes for those fields like any other column type.

4. Poll interval (ms)

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 500
	* **说明:** 

		Time to wait for new change events to appear after receiving no events, given in milliseconds. Defaults to 500 ms.

5. Event deserialization failure handling

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** fail
	* **说明:** 

		Specify how failures during processing of events (i.e. when encountering a corrupted event) should be handled, including:'fail' (the default) an exception indicating the problematic event and its position is raised, causing the connector to be stopped; 'warn' the problematic event and its position will be logged and the event will be skipped;'ignore' the problematic event will be skipped.

6. 过滤

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		可以将数据流中将某一种事件类型的事件过滤掉，有以下几种类型可以选择：INSERT, UPDATE_BEFORE, UPDATE_AFTER, DELETE

7. BinLog独立监听

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		无

### com.qlangtech.plugins.incr.flink.cdc.postgresql.FlinkCDCPostreSQLSourceFactory

* **显示名:** Flink-CDC-PostgreSQL 

* **全路径名:** [com.qlangtech.plugins.incr.flink.cdc.postgresql.FlinkCDCPostreSQLSourceFactory](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-postgresql-plugin/src/main/java/com/qlangtech/plugins/incr/flink/cdc/postgresql/FlinkCDCPostreSQLSourceFactory.java) 

* **提供者:** [FlinkCDC](https://ververica.github.io/flink-cdc-connectors) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-postgresql-plugin.tpi](./tpis#tis-flink-cdc-postgresql-plugintpi)

* **配置项说明:** 

1. 解码器

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** decoderbufs
	* **说明:** 		The name of the Postgres logical decoding plug-in installed on the server. Supported values are decoderbufs, wal2json, wal2json_rds, wal2json_streaming, wal2json_rds_streaming and pgoutput.

2. 起始位点

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** latest
	* **说明:** 

		Debezium startup options
		
		参数详细请参考：[https://ververica.github.io/flink-cdc-connectors/master/content/connectors/postgres-cdc.html#incremental-snapshot-options](https://ververica.github.io/flink-cdc-connectors/master/content/connectors/postgres-cdc.html#incremental-snapshot-options)
		
		* `Initial`:
		  Performs an initial snapshot on the monitored database tables upon first startup, and continue to read the latest binlog.     
		
		* `Latest`:
		  Never to perform snapshot on the monitored database tables upon first startup, just read from the end of the binlog which means only have the changes since the connector was started.

3. REPLICA IDENTITY

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** DEFAULT
	* **说明:** 

		在 PostgreSQL 中，ALTER TABLE ... REPLICA IDENTITY 命令用于指定在逻辑复制或行级触发器中如何标识已更新或删除的行。https://developer.aliyun.com/ask/575334
		
		可选项有以下两个
		* `FULL`: 使用此值需要确保对应的表执行`ALTER TABLE your_table_name REPLICA IDENTITY FULL;`，表记录更新时会带上更新Before值，使用此方式比较耗费性能。
		* `DEFAULT`: 默认值，更新删除操作时不会带上Before值。

4. 过滤

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		可以将数据流中将某一种事件类型的事件过滤掉，有以下几种类型可以选择：INSERT, UPDATE_BEFORE, UPDATE_AFTER, DELETE

### com.qlangtech.tis.plugins.incr.flink.cdc.sqlserver.FlinkCDCSqlServerSourceFactory

* **显示名:** Flink-CDC-SqlServer 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.cdc.sqlserver.FlinkCDCSqlServerSourceFactory](https://github.com/qlangtech/tis-sqlserver-plugin/tis-flink-cdc-sqlserver-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/cdc/sqlserver/FlinkCDCSqlServerSourceFactory.java) 

* **提供者:** [FlinkCDC](https://ververica.github.io/flink-cdc-connectors) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-sqlserver-plugin.tpi](./tpis#tis-flink-cdc-sqlserver-plugintpi)

* **配置项说明:** 

1. 起始位点

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** LatestOffset
	* **说明:** 

		* `Initial` : Takes a snapshot of structure and data of captured tables; useful if topics should be populated with a complete representation of the data from the captured tables.
		* `Snapshot`: Takes a snapshot of structure and data like initial but instead does not transition into streaming changes once the snapshot has completed.
		* `LatestOffset` (default): Takes a snapshot of the structure of captured tables only; useful if only changes happening from now onwards should be propagated to topics.

2. 所在时区

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugins.incr.flink.cdc.sqlserver.FlinkCDCSqlServerSourceFactory.dftZoneId()
	* **说明:** 		设置MySQL服务端所在时区

3. BinLog独立监听

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 

		执行Flink任务过程中，Binlog监听分配独立的Slot计算资源不会与下游计算算子混合在一起。
		
		如开启，带来的好处是运算时资源各自独立不会相互相互影响，弊端是，上游算子与下游算子独立在两个Solt中需要额外的网络传输开销

4. 过滤

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		可以将数据流中将某一种事件类型的事件过滤掉，有以下几种类型可以选择：INSERT, UPDATE_BEFORE, UPDATE_AFTER, DELETE

## com.qlangtech.tis.plugin.datax.doplinscheduler.export.DSTISCallback

### com.qlangtech.tis.plugin.datax.doplinscheduler.export.DSTISCallback

* **显示名:** Default 

* **全路径名:** [com.qlangtech.tis.plugin.datax.doplinscheduler.export.DSTISCallback](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dolphinscheduler-plugin/src/main/java/com/qlangtech/tis/plugin/datax/doplinscheduler/export/DSTISCallback.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dolphinscheduler-plugin.tpi](./tpis#tis-datax-dolphinscheduler-plugintpi)

* **配置项说明:** 

1. tisHTTPHost

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.doplinscheduler.export.DSTISCallback.dftTISHTTPHost()
	* **说明:** 		dolphinscheduler中会通过此地址作为REST API请求的根路径，向TIS发送数据数据管道的配置及插件资源请求，请务必确保dolphinscheduler端对此地址可用

2. tisAddress

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.doplinscheduler.export.DSTISCallback.dftTISAddress()
	* **说明:** 		dolphinscheduler中会通过此地址访问TIS提供的日志收集服务，TIS可收集dolphinscheduler端数据管道的执行日志。请务必确保dolphinscheduler端对此地址可用

## com.qlangtech.tis.hive.HiveMeta

### com.qlangtech.tis.hive.HiveMeta

* **显示名:** HiveMeta 

* **全路径名:** [com.qlangtech.tis.hive.HiveMeta](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/hive/HiveMeta.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. 元数据地址

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** thrift://{{hiveserver}}:9083
	* **说明:** 

		Hive元数据服务地址，用于获取Hive中存放的表的元数据信息
		
		地址格式如：`thrift://{{hiveserver}}:9083`

2. userToken

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 		当选择为'on', 用户需要填写用户名和密码

## com.qlangtech.tis.plugin.datax.kafka.reader.subscriptionmethod.KafkaSubscriptionMethod

### com.qlangtech.tis.plugin.datax.kafka.reader.subscriptionmethod.KafkaListOfTopics

* **显示名:** List Of Topics 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kafka.reader.subscriptionmethod.KafkaListOfTopics](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-kafka-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kafka/reader/subscriptionmethod/KafkaListOfTopics.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-kafka-plugin.tpi](./tpis#tis-flink-cdc-kafka-plugintpi)

* **配置项说明:** 

1. Topics

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		multiple topics，use common"," as separator

### com.qlangtech.tis.plugin.datax.kafka.reader.subscriptionmethod.KafkaManuallyAssignAListOfPartitions

* **显示名:** List Of Partitions 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kafka.reader.subscriptionmethod.KafkaManuallyAssignAListOfPartitions](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-kafka-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kafka/reader/subscriptionmethod/KafkaManuallyAssignAListOfPartitions.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-kafka-plugin.tpi](./tpis#tis-flink-cdc-kafka-plugintpi)

* **配置项说明:** 

1. topic:partition

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

### com.qlangtech.tis.plugin.datax.kafka.reader.subscriptionmethod.KafkaSubscribeToAllTopicsMatchingSpecifiedPattern

* **显示名:** Topics Match Specified Pattern 

* **全路径名:** [com.qlangtech.tis.plugin.datax.kafka.reader.subscriptionmethod.KafkaSubscribeToAllTopicsMatchingSpecifiedPattern](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-kafka-plugin/src/main/java/com/qlangtech/tis/plugin/datax/kafka/reader/subscriptionmethod/KafkaSubscribeToAllTopicsMatchingSpecifiedPattern.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-kafka-plugin.tpi](./tpis#tis-flink-cdc-kafka-plugintpi)

* **配置项说明:** 

1. Topic Pattern

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

## com.qlangtech.tis.plugin.datax.SelectedTabExtend

### com.qlangtech.tis.plugins.incr.flink.chunjun.sink.SinkTabPropsExtends

* **显示名:** SinkTabPropsExtends 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.sink.SinkTabPropsExtends](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-chunjun-base-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/sink/SinkTabPropsExtends.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-chunjun-base-plugin.tpi](./tpis#tis-chunjun-base-plugintpi)

* **配置项说明:** 

1. tabName

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.trigger.util.UnCacheString@472719df
	* **说明:** 		无

2. incrMode

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** Insert
	* **说明:** 

		控制写入数据到目标表采用 insert into 或者 replace into 或者 ON DUPLICATE KEY UPDATE 语句

### com.qlangtech.tis.plugins.incr.flink.chunjun.sink.UniqueKeySetter

* **显示名:** UniqueKeySetter 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.sink.UniqueKeySetter](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-chunjun-base-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/sink/UniqueKeySetter.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-chunjun-base-plugin.tpi](./tpis#tis-chunjun-base-plugintpi)

* **配置项说明:** 

1. tabName

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.trigger.util.UnCacheString@f42336c
	* **说明:** 		无

### com.qlangtech.tis.plugins.incr.flink.chunjun.source.SelectedTabPropsExtends

* **显示名:** SelectedTabPropsExtends 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.source.SelectedTabPropsExtends](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-chunjun-base-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/source/SelectedTabPropsExtends.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-chunjun-base-plugin.tpi](./tpis#tis-chunjun-base-plugintpi)

* **配置项说明:** 

1. tabName

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.trigger.util.UnCacheString@a63643e
	* **说明:** 		无

2. 轮询策略

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** RunInterval
	* **说明:** 

		间隔轮询，开启后会根据pollingInterval轮询间隔时间周期性的从数据库拉取数据。开启间隔轮询还需配置参数pollingInterval，increColumn，可以选择配置参数startLocation。若不配置参数startLocation，任务启动时将会从数据库中查询增量字段最大值作为轮询的起始位置。

3. splitPk

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：当speed配置中的channel大于1时指定此参数，Reader插件根据并发数和此参数指定的字段拼接sql，使每个并发读取不同的数据，提升读取速率。
		
		注意：
		    推荐splitPk使用表主键，因为表主键通常情况下比较均匀，因此切分出来的分片也不容易出现数据热点。
		    目前splitPk仅支持整形数据切分，不支持浮点、字符串、日期等其他类型。如果用户指定其他非支持类型，ChunJun将报错。
		    如果channel大于1但是没有配置此参数，任务将置为失败。
		
		必选：否
		参数类型：String
		默认值：无

4. where

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：筛选条件，reader插件根据指定的column、table、where条件拼接SQL，并根据这个SQL进行数据抽取。在实际业务场景中，往往会选择当天的数据进行同步，可以将where条件指定为gmt_create > time。
		注意：不可以将where条件指定为limit 10，limit不是SQL的合法where子句。
		必选：否
		参数类型：String
		默认值：无

### com.qlangtech.tis.plugin.datax.mongo.MongoSelectedTabExtend

* **显示名:** MongoSelectedTabExtend 

* **全路径名:** [com.qlangtech.tis.plugin.datax.mongo.MongoSelectedTabExtend](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-mongodb-plugin/src/main/java/com/qlangtech/tis/plugin/datax/mongo/MongoSelectedTabExtend.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-mongodb-plugin.tpi](./tpis#tis-datax-mongodb-plugintpi)

* **配置项说明:** 

1. tabName

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.trigger.util.UnCacheString@42ffbab6
	* **说明:** 		无

2. 过滤

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 		遍历MongoDB Collection只读取部分记录集，需要填写合适的查询条件

## com.qlangtech.tis.datax.DefaultDataXProcessorManipulate

### com.qlangtech.tis.plugin.datax.doplinscheduler.export.ExportTISPipelineToDolphinscheduler

* **显示名:** Export To Dolphinscheduler 

* **全路径名:** [com.qlangtech.tis.plugin.datax.doplinscheduler.export.ExportTISPipelineToDolphinscheduler](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dolphinscheduler-plugin/src/main/java/com/qlangtech/tis/plugin/datax/doplinscheduler/export/ExportTISPipelineToDolphinscheduler.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dolphinscheduler-plugin.tpi](./tpis#tis-datax-dolphinscheduler-plugintpi)

* **配置项说明:** 

1. 工作流名称

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.doplinscheduler.export.ExportTISPipelineToDolphinscheduler.dftProcessName()
	* **说明:** 		对应的dolphinscheduler中工作流名称，确保同一项目下工作流名称唯一，不能重复

2. endpoint

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		dolphinscheduler中对应的连接端配置

3. projectCode

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		dolphinscheduler中对应的项目编码

4. createHistory

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		dolphinscheduler执过程中，是否在TIS端生成执行历史记录？

5. TIS端回调

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** Default
	* **说明:** 		对应的dolphinscheduler中工作流执行过程中需要回调TIS，设置相应参数

6. 目标

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** Unlimited
	* **说明:** 		请选择需要同步到DolphinScheduler的表

7. 部署目录

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		TIS数据管道任务执行会在dolphinscheduler所在节点机器部署TIS运行所依赖的工程包，默认自动部署在dolphinscheduler $HOME目录

8. 描述

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		同步到dolphinscheduler的工作流名称描述

9. 资源组

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** Default
	* **说明:** 		对应dolphinScheduler中任务组概念，用以来控制工作流中的job并发数目，可以有效防止由于大量同步任务并发执行导致业务数据库过载

10. 内存规格

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** default
	* **说明:** 		执行DataX任务申请内存规格,默认为1024兆，如执行大表同步任务请按照实际需求量设置自定义规格

### :closed_lock_with_key:com.qlangtech.tis.plugin.ds.manipulate.CloneDefaultDataXProcessor

* **显示名:** Clone 

* **全路径名:** [com.qlangtech.tis.plugin.ds.manipulate.CloneDefaultDataXProcessor](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-split-table-strategy-plugin/src/main/java/com/qlangtech/tis/plugin/ds/manipulate/CloneDefaultDataXProcessor.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-split-table-strategy-plugin.tpi](./tpis#tis-split-table-strategy-plugintpi)

* **配置项说明:** 

1. 新实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		填写新实例名称，不能与已存在的数据管道实例重名

## com.qlangtech.tis.plugin.datax.mongo.UpsertSupport

### com.qlangtech.tis.plugin.datax.mongo.OffUpsertSupport

* **显示名:** off 

* **全路径名:** [com.qlangtech.tis.plugin.datax.mongo.OffUpsertSupport](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-mongodb-plugin/src/main/java/com/qlangtech/tis/plugin/datax/mongo/OffUpsertSupport.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-mongodb-plugin.tpi](./tpis#tis-datax-mongodb-plugintpi)

### com.qlangtech.tis.plugin.datax.mongo.OnUpsertSupport

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.mongo.OnUpsertSupport](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-mongodb-plugin/src/main/java/com/qlangtech/tis/plugin/datax/mongo/OnUpsertSupport.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-mongodb-plugin.tpi](./tpis#tis-datax-mongodb-plugintpi)

* **配置项说明:** 

1. upsertKey

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.trigger.util.UnCacheString@5fb514c2
	* **说明:** 		replaceKey指定了每行记录的业务主键。用来做更新时使用

## com.qlangtech.tis.plugin.datax.powerjob.PowerJobOMS

### com.qlangtech.tis.plugin.datax.powerjob.PowerJobOMS

* **显示名:** OMSProfile 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.PowerJobOMS](https://github.com/qlangtech/plugins/tree/master/tis-k8s-plugin/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/PowerJobOMS.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-k8s-plugin.tpi](./tpis#tis-k8s-plugintpi)

* **配置项说明:** 

1. akkaPort

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10086
	* **说明:** 		PowerJob配置，Akka端口号，默认10086

2. httpPort

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10010
	* **说明:** 		PowerJob配置，多语言客户端HTTP端口号，默认10010, 不建议更改

3. retentionLocal

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 7
	* **说明:** 		本地容器保留天数，负数代表永久保留

4. retentionRemote

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 7
	* **说明:** 		远程容器保留天数，负数代表永久保留

## com.qlangtech.tis.plugins.incr.flink.connector.UpdateMode

### com.qlangtech.tis.plugins.incr.flink.connector.impl.InsertType

* **显示名:** Insert 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.connector.impl.InsertType](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-chunjun-base-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/connector/impl/InsertType.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-chunjun-base-plugin.tpi](./tpis#tis-chunjun-base-plugintpi)

### com.qlangtech.tis.plugins.incr.flink.connector.impl.ReplaceType

* **显示名:** Replace 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.connector.impl.ReplaceType](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-chunjun-base-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/connector/impl/ReplaceType.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-chunjun-base-plugin.tpi](./tpis#tis-chunjun-base-plugintpi)

### com.qlangtech.tis.plugins.incr.flink.connector.impl.UpdateType

* **显示名:** Update 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.connector.impl.UpdateType](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-chunjun-base-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/connector/impl/UpdateType.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-chunjun-base-plugin.tpi](./tpis#tis-chunjun-base-plugintpi)

### com.qlangtech.tis.plugins.incr.flink.connector.impl.UpsertType

* **显示名:** Upsert 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.connector.impl.UpsertType](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-chunjun-base-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/connector/impl/UpsertType.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-chunjun-base-plugin.tpi](./tpis#tis-chunjun-base-plugintpi)

## com.qlangtech.tis.plugin.datax.FSFormat

### com.qlangtech.tis.plugin.datax.impl.TextFSFormat

* **显示名:** TEXT 

* **全路径名:** [com.qlangtech.tis.plugin.datax.impl.TextFSFormat](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-hdfs-plugin/src/main/java/com/qlangtech/tis/plugin/datax/impl/TextFSFormat.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-hdfs-plugin/tis-datax-hdfs-plugin_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-datax-hdfs-plugin/tis-datax-hdfs-plugin_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. 列分割符

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** char001
	* **说明:** 		描述：读取的字段分隔符，可以用'\t','\001'等字符 

### com.qlangtech.tis.hive.impl.OrcFSFormat

* **显示名:** ORC 

* **全路径名:** [com.qlangtech.tis.hive.impl.OrcFSFormat](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/hive/impl/OrcFSFormat.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

### com.qlangtech.tis.hive.impl.ParquetFSFormat

* **显示名:** PARQUET 

* **全路径名:** [com.qlangtech.tis.hive.impl.ParquetFSFormat](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/hive/impl/ParquetFSFormat.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

## com.qlangtech.tis.plugins.incr.flink.cdc.mysql.startup.StartupOptions

### com.qlangtech.tis.plugins.incr.flink.cdc.mysql.startup.EarliestStartupOptions

* **显示名:** EARLIEST_OFFSET 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.cdc.mysql.startup.EarliestStartupOptions](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-mysql-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/cdc/mysql/startup/EarliestStartupOptions.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-mysql-plugin.tpi](./tpis#tis-flink-cdc-mysql-plugintpi)

### com.qlangtech.tis.plugins.incr.flink.cdc.mysql.startup.InitialStartupOptions

* **显示名:** INITIAL 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.cdc.mysql.startup.InitialStartupOptions](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-mysql-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/cdc/mysql/startup/InitialStartupOptions.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-mysql-plugin.tpi](./tpis#tis-flink-cdc-mysql-plugintpi)

### com.qlangtech.tis.plugins.incr.flink.cdc.mysql.startup.LatestStartupOptions

* **显示名:** LATEST_OFFSET 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.cdc.mysql.startup.LatestStartupOptions](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-mysql-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/cdc/mysql/startup/LatestStartupOptions.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-mysql-plugin.tpi](./tpis#tis-flink-cdc-mysql-plugintpi)

### com.qlangtech.tis.plugins.incr.flink.cdc.mysql.startup.TimestampStartupOptions

* **显示名:** TIMESTAMP 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.cdc.mysql.startup.TimestampStartupOptions](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-mysql-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/cdc/mysql/startup/TimestampStartupOptions.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-mysql-plugin.tpi](./tpis#tis-flink-cdc-mysql-plugintpi)

* **配置项说明:** 

1. 开始时间

	* **类型:** 日期
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		timestamp for the startup offsets, as milliseconds from epoch.

## com.qlangtech.tis.plugin.k8s.K8sImage

### com.qlangtech.tis.config.k8s.impl.DefaultK8SImage

* **显示名:** dft-image 

* **全路径名:** [com.qlangtech.tis.config.k8s.impl.DefaultK8SImage](https://github.com/qlangtech/plugins/tree/master/tis-k8s-plugin/src/main/java/com/qlangtech/tis/config/k8s/impl/DefaultK8SImage.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-k8s-plugin.tpi](./tpis#tis-k8s-plugintpi)

* **配置项说明:** 

1. 名称

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. k8sCfg

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

3. 命名空间

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** default
	* **说明:** 

		Kubernetes中的Namespace是一种用于在集群内部组织和隔离资源的机制。一个Namespace可以看作是一个虚拟的集群，它将物理集群划分为多个逻辑部分，每个部分都有自己的一组资源（如Pod、Service、ConfigMap等）。
		
		例如：输入框中录入的值为`tis`,该命名空间尚未创建，则可通过输入命令行：`kubectl create namespace tis` 创建。
		
		Kubernetes 默认包含 ：`default` 这个名字空间，以便于你无需创建新的名字空间即可开始使用新集群。

4. 镜像地址

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

5. 使用ExternalIP

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		当TIS控制台不在K8S的网络中，选择'是'，TIS控制台节点使用ExternalIP作为连接地址。

6. hostAliases

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		启动Pod时会在容器内的hosts文件中添加所输入的内容，例子：
		 ``` yaml
		  - ip: "127.0.0.1"
		    hostnames:
		      - "foo.local"
		      - "bar.local"
		 ```

### com.qlangtech.tis.plugin.datax.powerjob.PowerJobK8SImage

* **显示名:** powerjob-image 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.PowerJobK8SImage](https://github.com/qlangtech/plugins/tree/master/tis-k8s-plugin/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/PowerJobK8SImage.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-k8s-plugin.tpi](./tpis#tis-k8s-plugintpi)

* **配置项说明:** 

1. 名称

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. k8sCfg

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

3. 命名空间

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** default
	* **说明:** 

		Kubernetes中的Namespace是一种用于在集群内部组织和隔离资源的机制。一个Namespace可以看作是一个虚拟的集群，它将物理集群划分为多个逻辑部分，每个部分都有自己的一组资源（如Pod、Service、ConfigMap等）。
		
		例如：输入框中录入的值为`tis`,该命名空间尚未创建，则可通过输入命令行：`kubectl create namespace tis` 创建。
		
		Kubernetes 默认包含 ：`default` 这个名字空间，以便于你无需创建新的名字空间即可开始使用新集群。

4. serverImage

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.powerjob.PowerJobK8SImage.powerjobServerImagePath()
	* **说明:** 		Powerjob Server 镜像地址

5. workerImage

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.powerjob.PowerJobK8SImage.dftPowerJobWorkerImagePath()
	* **说明:** 		Powerjob Worker Image Path 由TIS定制

6. 使用ExternalIP

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		当TIS控制台不在K8S的网络中，选择'是'，TIS控制台节点使用ExternalIP作为连接地址。

7. metaImage

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.powerjob.PowerJobK8SImage.powerjobMetaStoreImagePath()
	* **说明:** 		Powerjob Server MetaStore 持久化存储 PowerJob机群配置化信息

8. hostAliases

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		启动Pod时会在容器内的hosts文件中添加所输入的内容，例子：
		 ``` yaml
		  - ip: "127.0.0.1"
		    hostnames:
		      - "foo.local"
		      - "bar.local"
		 ```

### com.qlangtech.plugins.incr.flink.common.FlinkK8SImage

* **显示名:** flink-image 

* **全路径名:** [com.qlangtech.plugins.incr.flink.common.FlinkK8SImage](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-realtime-flink/src/main/java/com/qlangtech/plugins/incr/flink/common/FlinkK8SImage.java) 

* **提供者:** [TIS](https://github.com/qlangtech/tis) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-realtime-flink.tpi](./tpis#tis-realtime-flinktpi)

* **配置项说明:** 

1. 名称

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. k8sCfg

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

3. 命名空间

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** default
	* **说明:** 

		Kubernetes中的Namespace是一种用于在集群内部组织和隔离资源的机制。一个Namespace可以看作是一个虚拟的集群，它将物理集群划分为多个逻辑部分，每个部分都有自己的一组资源（如Pod、Service、ConfigMap等）。
		
		例如：输入框中录入的值为`tis`,该命名空间尚未创建，则可通过输入命令行：`kubectl create namespace tis` 创建。
		
		Kubernetes 默认包含 ：`default` 这个名字空间，以便于你无需创建新的名字空间即可开始使用新集群。

4. 镜像地址

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugins.incr.flink.FlinkCommon.dftImagePath()
	* **说明:** 		Flink Docker Image Path 由TIS定制

5. 使用ExternalIP

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		当TIS控制台不在K8S的网络中，选择'是'，TIS控制台节点使用ExternalIP作为连接地址。

6. hostAliases

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		启动Pod时会在容器内的hosts文件中添加所输入的内容，例子：
		 ``` yaml
		  - ip: "127.0.0.1"
		    hostnames:
		      - "foo.local"
		      - "bar.local"
		 ```

## com.qlangtech.tis.plugins.incr.flink.cdc.sqlserver.startup.CDCStartupOptions

### com.qlangtech.tis.plugins.incr.flink.cdc.sqlserver.startup.Initial

* **显示名:** Initial 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.cdc.sqlserver.startup.Initial](https://github.com/qlangtech/tis-sqlserver-plugin/tis-flink-cdc-sqlserver-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/cdc/sqlserver/startup/Initial.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-sqlserver-plugin.tpi](./tpis#tis-flink-cdc-sqlserver-plugintpi)

### com.qlangtech.tis.plugins.incr.flink.cdc.sqlserver.startup.LatestOffset

* **显示名:** LatestOffset 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.cdc.sqlserver.startup.LatestOffset](https://github.com/qlangtech/tis-sqlserver-plugin/tis-flink-cdc-sqlserver-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/cdc/sqlserver/startup/LatestOffset.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-sqlserver-plugin.tpi](./tpis#tis-flink-cdc-sqlserver-plugintpi)

### com.qlangtech.tis.plugins.incr.flink.cdc.sqlserver.startup.Snapshot

* **显示名:** Snapshot 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.cdc.sqlserver.startup.Snapshot](https://github.com/qlangtech/tis-sqlserver-plugin/tis-flink-cdc-sqlserver-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/cdc/sqlserver/startup/Snapshot.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-sqlserver-plugin.tpi](./tpis#tis-flink-cdc-sqlserver-plugintpi)

## com.qlangtech.plugins.incr.flink.launch.StateBackendFactory

### com.qlangtech.plugins.incr.flink.launch.statbackend.FileSystemState

* **显示名:** FSState 

* **全路径名:** [com.qlangtech.plugins.incr.flink.launch.statbackend.FileSystemState](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-realtime-flink/src/main/java/com/qlangtech/plugins/incr/flink/launch/statbackend/FileSystemState.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-realtime-flink.tpi](./tpis#tis-realtime-flinktpi)

* **配置项说明:** 

1. checkpointDir

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** file:///opt/data/savepoint
	* **说明:** 

		The default directory used for storing the data files and meta data of checkpoints in a Flink supported filesystem. The storage path must be accessible from all participating processes/nodes(i.e. all TaskManagers and JobManagers).
		
		The scheme (hdfs://, file://, etc) is null. Please specify the file system scheme explicitly in the URI.

2. enableSavePoint

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 

		支持任务执行**savepoint**，Flink任务管理器执行停机操作时会主动触发创建**savepoint**操作，存放位置为属性`checkpointDir`平行目录下的一个以时间戳命名的子目录中

3. smallFileThreshold

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 20
	* **说明:** 

		The minimum size of state data files. All state chunks smaller than that are stored inline in the root checkpoint metadata file. The max memory threshold for this configuration is 1MB.
		
		 单位：`kb`

4. writeBufferSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 4096
	* **说明:** 

		The default size of the write buffer for the checkpoint streams that write to file systems. The actual write buffer size is determined to be the maximum of the value of this option and option 'state.storage.fs.memory-threshold'.

### com.qlangtech.plugins.incr.flink.launch.statbackend.MemoryState

* **显示名:** HashMapState 

* **全路径名:** [com.qlangtech.plugins.incr.flink.launch.statbackend.MemoryState](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-realtime-flink/src/main/java/com/qlangtech/plugins/incr/flink/launch/statbackend/MemoryState.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-realtime-flink.tpi](./tpis#tis-realtime-flinktpi)

* **配置项说明:** 

1. latencyTrackEnable

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 

		Whether to track latency of keyed state operations, e.g value state put/get/clear.

2. trackSampleInterval

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 100
	* **说明:** 

		The sample interval of latency track once 'state.backend.latency-track.keyed-state-enabled' is enabled. The default value is 100, which means we would track the latency every 100 access requests.

3. trackHistorySize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 128
	* **说明:** 

		Defines the number of measured latencies to maintain at each state access operation.

### com.qlangtech.plugins.incr.flink.launch.statbackend.OFF

* **显示名:** off 

* **全路径名:** [com.qlangtech.plugins.incr.flink.launch.statbackend.OFF](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-realtime-flink/src/main/java/com/qlangtech/plugins/incr/flink/launch/statbackend/OFF.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-realtime-flink.tpi](./tpis#tis-realtime-flinktpi)

## com.qlangtech.tis.plugin.datax.SelectedTab

### com.qlangtech.tis.plugin.datax.doris.DorisSelectedTab

* **显示名:** DorisSelectedTab 

* **全路径名:** [com.qlangtech.tis.plugin.datax.doris.DorisSelectedTab](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-doris-plugin/src/main/java/com/qlangtech/tis/plugin/datax/doris/DorisSelectedTab.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-doris-plugin.tpi](./tpis#tis-datax-doris-plugintpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. 主键(s)

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.trigger.util.UnCacheString@3639b04
	* **说明:** 		选择列作为表的主键

3. Sequence列

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** off
	* **说明:** 

		用户需要确保每次更新记录该列的值会递增，支持使用：整型数字、DATE、DATETIME类型的列，通过设置Sequence可以保证在乱序情况下可以保证数据不会发生脏写
		
		详细请查阅 Doris文档：https://doris.apache.org/zh-CN/docs/dev/data-operate/update-delete/sequence-column-manual

4. where

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		筛选条件，MysqlReader根据指定的column、table、where条件拼接SQL，并根据这个SQL进行数据抽取。在实际业务场景中，往往会选择当天的数据进行同步，可以将where条件指定为gmt_create > $bizdate 。注意：不可以将where条件指定为limit 10，limit不是SQL的合法where子句。
		 where条件可以有效地进行业务增量同步。如果不填写where语句，包括不提供where的key或者value，DataX均视作同步全量数据。

5. 同步列

	* **类型:** 多选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		需要同步的数据列

### com.qlangtech.tis.plugins.datax.kafka.writer.KafkaSelectedTab

* **显示名:** KafkaSelectedTab 

* **全路径名:** [com.qlangtech.tis.plugins.datax.kafka.writer.KafkaSelectedTab](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-kafka-plugin/src/main/java/com/qlangtech/tis/plugins/datax/kafka/writer/KafkaSelectedTab.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-kafka-plugin.tpi](./tpis#tis-datax-kafka-plugintpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. 主键(s)

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.trigger.util.UnCacheString@5c740c5a
	* **说明:** 		选择列作为表的主键

3. 分区字段

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		kafka sink分区字段

4. where

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		筛选条件，MysqlReader根据指定的column、table、where条件拼接SQL，并根据这个SQL进行数据抽取。在实际业务场景中，往往会选择当天的数据进行同步，可以将where条件指定为gmt_create > $bizdate 。注意：不可以将where条件指定为limit 10，limit不是SQL的合法where子句。
		 where条件可以有效地进行业务增量同步。如果不填写where语句，包括不提供where的key或者value，DataX均视作同步全量数据。

5. 同步列

	* **类型:** 多选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		需要同步的数据列

### com.qlangtech.tis.plugin.datax.mongo.MongoWriterSelectedTab

* **显示名:** MongoWriterSelectedTab 

* **全路径名:** [com.qlangtech.tis.plugin.datax.mongo.MongoWriterSelectedTab](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-mongodb-plugin/src/main/java/com/qlangtech/tis/plugin/datax/mongo/MongoWriterSelectedTab.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-mongodb-plugin.tpi](./tpis#tis-datax-mongodb-plugintpi)

* **配置项说明:** 

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. 主键(s)

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.trigger.util.UnCacheString@5f5a33ed
	* **说明:** 		选择列作为表的主键

3. upsert

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 

		指定了传输数据时更新的信息，当设置为‘on’时，表示针对相同的replaceKey做更新操作，详细功能介绍请查看 
		[DataX Mongodb Writer](https://github.com/alibaba/DataX/blob/master/mongodbwriter/doc/mongodbwriter.md)

4. where

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		筛选条件，MysqlReader根据指定的column、table、where条件拼接SQL，并根据这个SQL进行数据抽取。在实际业务场景中，往往会选择当天的数据进行同步，可以将where条件指定为gmt_create > $bizdate 。注意：不可以将where条件指定为limit 10，limit不是SQL的合法where子句。
		 where条件可以有效地进行业务增量同步。如果不填写where语句，包括不提供where的key或者value，DataX均视作同步全量数据。

5. 同步列

	* **类型:** 多选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		需要同步的数据列

## com.qlangtech.tis.plugin.datax.powerjob.PowerJobOMSStorage

### com.qlangtech.tis.plugin.datax.powerjob.impl.oms.MySQLPowerJobOMSStorage

* **显示名:** MySQL 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.impl.oms.MySQLPowerJobOMSStorage](https://github.com/qlangtech/plugins/tree/master/tis-k8s-plugin/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/impl/oms/MySQLPowerJobOMSStorage.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-k8s-plugin.tpi](./tpis#tis-k8s-plugintpi)

* **配置项说明:** 

1. dbName

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

### com.qlangtech.tis.plugin.datax.powerjob.impl.oms.NonePowerJobOMSStorage

* **显示名:** None 

* **全路径名:** [com.qlangtech.tis.plugin.datax.powerjob.impl.oms.NonePowerJobOMSStorage](https://github.com/qlangtech/plugins/tree/master/tis-k8s-plugin/src/main/java/com/qlangtech/tis/plugin/datax/powerjob/impl/oms/NonePowerJobOMSStorage.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-k8s-plugin.tpi](./tpis#tis-k8s-plugintpi)

## com.qlangtech.tis.plugins.incr.flink.chunjun.offset.StartLocation

### com.qlangtech.tis.plugins.incr.flink.chunjun.offset.DesignatedLocation

* **显示名:** Designated 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.offset.DesignatedLocation](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-chunjun-base-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/offset/DesignatedLocation.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-chunjun-base-plugin.tpi](./tpis#tis-chunjun-base-plugintpi)

* **配置项说明:** 

1. startLocation

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		增量查询起始位置

### com.qlangtech.tis.plugins.incr.flink.chunjun.offset.LatestLocation

* **显示名:** Latest 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.offset.LatestLocation](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-chunjun-base-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/offset/LatestLocation.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-chunjun-base-plugin.tpi](./tpis#tis-chunjun-base-plugintpi)

### com.qlangtech.tis.plugins.incr.flink.chunjun.offset.ScanAll

* **显示名:** Initial 

* **全路径名:** [com.qlangtech.tis.plugins.incr.flink.chunjun.offset.ScanAll](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-chunjun-base-plugin/src/main/java/com/qlangtech/tis/plugins/incr/flink/chunjun/offset/ScanAll.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-chunjun-base-plugin.tpi](./tpis#tis-chunjun-base-plugintpi)

## com.qlangtech.tis.plugin.datax.common.AutoCreateTable

### com.qlangtech.tis.plugin.datax.ClickhouseAutoCreateTable

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.ClickhouseAutoCreateTable](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-clickhouse-plugin/src/main/java/com/qlangtech/tis/plugin/datax/ClickhouseAutoCreateTable.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-clickhouse-plugin.tpi](./tpis#tis-datax-clickhouse-plugintpi)

* **配置项说明:** 

1. 添加列注释

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

2. 别名前缀

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

### com.qlangtech.tis.plugin.datax.dameng.writer.DaMengAutoCreateTable

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.dameng.writer.DaMengAutoCreateTable](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dameng-plugin/src/main/java/com/qlangtech/tis/plugin/datax/dameng/writer/DaMengAutoCreateTable.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dameng-plugin.tpi](./tpis#tis-datax-dameng-plugintpi)

* **配置项说明:** 

1. 添加列注释

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

2. 别名前缀

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

### com.qlangtech.tis.plugin.datax.doris.DorisAutoCreateTable

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.doris.DorisAutoCreateTable](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-doris-plugin/src/main/java/com/qlangtech/tis/plugin/datax/doris/DorisAutoCreateTable.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-doris-plugin.tpi](./tpis#tis-datax-doris-plugintpi)

* **配置项说明:** 

1. 添加列注释

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

2. 建表模型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** Unique
	* **说明:** 

		TIS可以帮助用户自动生成Doris端的建表DDL语句，如Doris中已存在对应的表可选择`Off`,如需要生成可以选择`Unique`和`Duplicate`之一，如需要使用`Aggregate`模型，由于Agg模型需要设置非聚合列的聚合函数，系统无法预知。
		可先选择`Unique`和`Duplicate`任意一种，待到DDL生成之后，手动在DDL之上进行修改。
		
		Doris 支持三种数据模型：
		
		1. Aggregate
		2. Unique
		3. Duplicate
		
		[数据模型详细](https://doris.apache.org/docs/table-design/data-model/overview)

3. 副本数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 

		设置Doris create table脚本中的副本数目：
		```sql
		CREATE TABLE `test`
		(
		    `id`      VARCHAR(96) NOT NULL,
		)
		 ENGINE=olap
		UNIQUE KEY(`id`)
		PROPERTIES("replication_num" = "1"  )
		```

4. 分桶数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10
	* **说明:** 

		表Bucket的作用主要有以下几点：
		
		1. 数据分布：Bucket可以帮助数据在集群中更均匀地分布，提高数据的可靠性和容错性。
		2. 加快数据查询速度：通过对数据进行分桶，查询时可以只扫描涉及的Bucket，减少扫描的数据量，从而加快查询速度。
		3. 数据归档：Bucket可以用于数据的归档管理，将不再更新的数据移动到较为冷的Bucket中。
		4. 数据安全：Bucket也可以用于数据备份，一般会有多个Bucket副本以防止数据丢失。
		
		创建带Bucket的表的示例SQL语句如下：
		```sql
		CREATE TABLE `test`
		(
		    `id`      VARCHAR(96) NOT NULL,
		)
		 ENGINE=olap
		UNIQUE KEY(`id`)
		BUCKETS 16
		PROPERTIES("replication_num" = "1"  )
		```

5. 别名前缀

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

### com.qlangtech.tis.plugin.datax.OdpsAutoCreateTable

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.OdpsAutoCreateTable](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-odps-plugin/src/main/java/com/qlangtech/tis/plugin/datax/OdpsAutoCreateTable.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-odps-plugin.tpi](./tpis#tis-datax-odps-plugintpi)

* **配置项说明:** 

1. 添加列注释

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

2. 别名前缀

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

### com.qlangtech.tis.plugin.datax.OracleAutoCreateTable

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.OracleAutoCreateTable](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-oracle-plugin/src/main/java/com/qlangtech/tis/plugin/datax/OracleAutoCreateTable.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-oracle-plugin.tpi](./tpis#tis-datax-oracle-plugintpi)

* **配置项说明:** 

1. 添加列注释

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

2. 别名前缀

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

### com.qlangtech.tis.plugin.datax.PostgreSQLAutoCreateTable

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.PostgreSQLAutoCreateTable](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-postgresql-plugin/src/main/java/com/qlangtech/tis/plugin/datax/PostgreSQLAutoCreateTable.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-postgresql-plugin.tpi](./tpis#tis-datax-postgresql-plugintpi)

* **配置项说明:** 

1. 添加列注释

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

2. 别名前缀

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

### com.qlangtech.tis.plugin.datax.SqlServerAutoCreateTable

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.SqlServerAutoCreateTable](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-sqlserver-plugin/src/main/java/com/qlangtech/tis/plugin/datax/SqlServerAutoCreateTable.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-sqlserver-plugin.tpi](./tpis#tis-datax-sqlserver-plugintpi)

* **配置项说明:** 

1. 添加列注释

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

2. 别名前缀

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

### com.qlangtech.tis.plugin.datax.starrocks.StarRocksAutoCreateTable

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.starrocks.StarRocksAutoCreateTable](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-starrocks-plugin/src/main/java/com/qlangtech/tis/plugin/datax/starrocks/StarRocksAutoCreateTable.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-starrocks-plugin.tpi](./tpis#tis-datax-starrocks-plugintpi)

* **配置项说明:** 

1. 添加列注释

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

2. 副本数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 

		设置Doris create table脚本中的副本数目：
		```sql
		CREATE TABLE `test`
		(
		    `id`      VARCHAR(96) NOT NULL,
		)
		 ENGINE=olap
		UNIQUE KEY(`id`)
		PROPERTIES("replication_num" = "1"  )
		```

3. 分桶数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10
	* **说明:** 

		表Bucket的作用主要有以下几点：
		
		1. 数据分布：Bucket可以帮助数据在集群中更均匀地分布，提高数据的可靠性和容错性。
		2. 加快数据查询速度：通过对数据进行分桶，查询时可以只扫描涉及的Bucket，减少扫描的数据量，从而加快查询速度。
		3. 数据归档：Bucket可以用于数据的归档管理，将不再更新的数据移动到较为冷的Bucket中。
		4. 数据安全：Bucket也可以用于数据备份，一般会有多个Bucket副本以防止数据丢失。
		
		创建带Bucket的表的示例SQL语句如下：
		```sql
		CREATE TABLE `test`
		(
		    `id`      VARCHAR(96) NOT NULL,
		)
		 ENGINE=olap
		UNIQUE KEY(`id`)
		BUCKETS 16
		PROPERTIES("replication_num" = "1"  )
		```

4. 别名前缀

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

### com.qlangtech.tis.plugin.datax.KingBaseMySQLModeAutoCreateTable

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.KingBaseMySQLModeAutoCreateTable](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-ds-mysql-plugin/src/main/java/com/qlangtech/tis/plugin/datax/KingBaseMySQLModeAutoCreateTable.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-ds-mysql-plugin.tpi](./tpis#tis-ds-mysql-plugintpi)

* **配置项说明:** 

1. 添加列注释

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

2. 别名前缀

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

### com.qlangtech.tis.plugin.datax.MySQLAutoCreateTable

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.MySQLAutoCreateTable](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-ds-mysql-plugin/src/main/java/com/qlangtech/tis/plugin/datax/MySQLAutoCreateTable.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-ds-mysql-plugin.tpi](./tpis#tis-ds-mysql-plugintpi)

* **配置项说明:** 

1. 添加列注释

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

2. 别名前缀

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

### com.qlangtech.tis.plugin.datax.HiveAutoCreateTable

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.HiveAutoCreateTable](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/plugin/datax/HiveAutoCreateTable.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. 添加列注释

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

2. 别名前缀

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

## com.qlangtech.tis.plugin.datax.common.AutoCreateTableColCommentSwitch

### :closed_lock_with_key:com.qlangtech.tis.plugin.datax.common.impl.AutoCreateTableColCommentSwitchON

* **显示名:** on 

* **全路径名:** [com.qlangtech.tis.plugin.datax.common.impl.AutoCreateTableColCommentSwitchON](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-datax-commercial/tis-datax-common-commercial-plugin/src/main/java/com/qlangtech/tis/plugin/datax/common/impl/AutoCreateTableColCommentSwitchON.java) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-datax-common-commercial-plugin.tpi](./tpis#tis-datax-common-commercial-plugintpi)

## com.qlangtech.tis.config.authtoken.UserToken

### com.qlangtech.tis.config.authtoken.impl.KerberosUserToken

* **显示名:** kerberos 

* **全路径名:** [com.qlangtech.tis.config.authtoken.impl.KerberosUserToken](https://github.com/qlangtech/plugins/tree/master/tis-kerberos-plugin/src/main/java/com/qlangtech/tis/config/authtoken/impl/KerberosUserToken.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-kerberos-plugin.tpi](./tpis#tis-kerberos-plugintpi)

* **配置项说明:** 

1. kerberos

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		开启kerberos客户端认证

## com.qlangtech.plugins.incr.flink.cdc.mongdb.MongoCDCStartupOptions

### com.qlangtech.plugins.incr.flink.cdc.mongdb.impl.startup.Initial

* **显示名:** INITIAL 

* **全路径名:** [com.qlangtech.plugins.incr.flink.cdc.mongdb.impl.startup.Initial](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-mongdb-plugin/src/main/java/com/qlangtech/plugins/incr/flink/cdc/mongdb/impl/startup/Initial.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-mongdb-plugin.tpi](./tpis#tis-flink-cdc-mongdb-plugintpi)

* **配置项说明:** 

1. copyExistingMaxThreads

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		The number of threads to use when performing the data copy. Defaults to the number of
		 * processors. Default: defaults to the number of processors

2. copyExistingQueueSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		The max size of the queue to use when copying data. 
		* Default: `10240`

3. pollMaxBatchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		Maximum number of change stream documents to include in a single batch when polling for new data. This setting can be used to limit the amount of data buffered internally in the connector.
		* Default: `1024`

4. pollAwaitTimeMillis

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		The amount of time to wait before checking for new results on the change stream.
		* Default: `1000`

5. heartbeatIntervalMillis

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		The length of time in milliseconds between sending heartbeat messages. Heartbeat messages contain the post batch resume token and are sent when no source records have been published in the specified interval. 
		This improves the resumability of the connector for low volume namespaces. 
		
		Use `0` to disable.

### com.qlangtech.plugins.incr.flink.cdc.mongdb.impl.startup.LatestOffset

* **显示名:** LATEST_OFFSET 

* **全路径名:** [com.qlangtech.plugins.incr.flink.cdc.mongdb.impl.startup.LatestOffset](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-mongdb-plugin/src/main/java/com/qlangtech/plugins/incr/flink/cdc/mongdb/impl/startup/LatestOffset.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-mongdb-plugin.tpi](./tpis#tis-flink-cdc-mongdb-plugintpi)

### com.qlangtech.plugins.incr.flink.cdc.mongdb.impl.startup.Timestamp

* **显示名:** TIMESTAMP 

* **全路径名:** [com.qlangtech.plugins.incr.flink.cdc.mongdb.impl.startup.Timestamp](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-flink-cdc-mongdb-plugin/src/main/java/com/qlangtech/plugins/incr/flink/cdc/mongdb/impl/startup/Timestamp.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-flink-cdc-mongdb-plugin.tpi](./tpis#tis-flink-cdc-mongdb-plugintpi)

* **配置项说明:** 

1. 开始时间

	* **类型:** 日期
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		timestamp for the startup offsets, as milliseconds from epoch.

## com.qlangtech.tis.plugin.datax.mongo.reader.ReaderFilter

### com.qlangtech.tis.plugin.datax.mongo.reader.ReaderFilteOff

* **显示名:** off 

* **全路径名:** [com.qlangtech.tis.plugin.datax.mongo.reader.ReaderFilteOff](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-mongodb-plugin/src/main/java/com/qlangtech/tis/plugin/datax/mongo/reader/ReaderFilteOff.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-mongodb-plugin.tpi](./tpis#tis-datax-mongodb-plugintpi)

### com.qlangtech.tis.plugin.datax.mongo.reader.ReaderFilterNormalQuery

* **显示名:** normalQuery 

* **全路径名:** [com.qlangtech.tis.plugin.datax.mongo.reader.ReaderFilterNormalQuery](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-mongodb-plugin/src/main/java/com/qlangtech/tis/plugin/datax/mongo/reader/ReaderFilterNormalQuery.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-mongodb-plugin.tpi](./tpis#tis-datax-mongodb-plugintpi)

* **配置项说明:** 

1. query

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		MongoDB 普通过滤文档集合查询语法，具体可以查询 文档：https://www.mongodb.com/docs/manual/tutorial/query-documents/

### com.qlangtech.tis.plugin.datax.mongo.reader.ReaderFilterOn

* **显示名:** rangeQuery 

* **全路径名:** [com.qlangtech.tis.plugin.datax.mongo.reader.ReaderFilterOn](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-mongodb-plugin/src/main/java/com/qlangtech/tis/plugin/datax/mongo/reader/ReaderFilterOn.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-mongodb-plugin.tpi](./tpis#tis-datax-mongodb-plugintpi)

* **配置项说明:** 

1. ObjectId

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** true
	* **说明:** 		以下查询条件，作为MongoDB 主键的ObjectId类型使用

2. 下边界

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		无

3. 上边界

	* **类型:** 单行文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		无

## com.qlangtech.tis.hive.Hms

### com.qlangtech.tis.hive.Hms

* **显示名:** HMS 

* **全路径名:** [com.qlangtech.tis.hive.Hms](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-hive-flat-table-builder-plugin/src/main/java/com/qlangtech/tis/hive/Hms.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_2.1.1-cdh6.3.2_hadoop_3.0.0-cdh6.3.2.tpi](./tpis#tis-hive-flat-table-builder-plugin/tis-hive-flat-table-builder-plugin_hive_211-cdh632_hadoop_300-cdh632tpi)

* **配置项说明:** 

1. hiveAddress

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** {ip|host}:10000
	* **说明:** 		描述：Hive Thrift Server2。格式：ip:端口；例如：127.0.0.1:9000

2. userToken

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** off
	* **说明:** 		当选择为'on', 用户需要填写用户名和密码

## com.qlangtech.plugins.incr.flink.launch.RestartStrategyFactory

### :closed_lock_with_key:com.qlangtech.plugins.incr.flink.launch.restart.ExponentialDelay

* **显示名:** exponential-delay 

* **全路径名:** [com.qlangtech.plugins.incr.flink.launch.restart.ExponentialDelay](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-incr-commercial/tis-flink-k8s-plugin/src/main/java/com/qlangtech/plugins/incr/flink/launch/restart/ExponentialDelay.java) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-flink-k8s-plugin.tpi](./tpis#tis-flink-k8s-plugintpi)

* **配置项说明:** 

1. initialBackoff

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 

		Starting duration between restarts if <code class="highlighter-rouge">restart-strategy.type</code> has been set to <code class="highlighter-rouge">exponential-delay</code>. It can be specified using notation: "1 min", "20 s"
		
		 单位：`秒`

2. maxBackoff

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 300
	* **说明:** 

		The highest possible duration between restarts if <code class="highlighter-rouge">restart-strategy.type</code> has been set to <code class="highlighter-rouge">exponential-delay</code>. It can be specified using notation: "1 min", "20 s"
		
		 单位：`秒`

3. backoffMultiplier

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 2.0
	* **说明:** 

		Backoff value is multiplied by this value after every failure,until max backoff is reached if <code class="highlighter-rouge">restart-strategy.type</code> has been set to <code class="highlighter-rouge">exponential-delay</code>.

4. resetBackoffThreshold

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 3600
	* **说明:** 

		Threshold when the backoff is reset to its initial value if <code class="highlighter-rouge">restart-strategy.type</code> has been set to <code class="highlighter-rouge">exponential-delay</code>. It specifies how long the job must be running without failure to reset the exponentially increasing backoff to its initial value. It can be specified using notation: "1 min", "20 s"
		
		 单位：`秒`

5. jitter

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 0.1
	* **说明:** 

		Jitter specified as a portion of the backoff if <code class="highlighter-rouge">restart-strategy.type</code> has been set to <code class="highlighter-rouge">exponential-delay</code>. It represents how large random value will be added or subtracted to the backoff. Useful when you want to avoid restarting multiple jobs at the same time.

### :closed_lock_with_key:com.qlangtech.plugins.incr.flink.launch.restart.FailureRate

* **显示名:** failure-rate 

* **全路径名:** [com.qlangtech.plugins.incr.flink.launch.restart.FailureRate](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-incr-commercial/tis-flink-k8s-plugin/src/main/java/com/qlangtech/plugins/incr/flink/launch/restart/FailureRate.java) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-flink-k8s-plugin.tpi](./tpis#tis-flink-k8s-plugintpi)

* **配置项说明:** 

1. maxFailures

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 

		Maximum number of restarts in given time interval before failing a job if <code class="highlighter-rouge">restart-strategy.type</code> has been set to <code class="highlighter-rouge">failure-rate</code>.

2. failureRateInterval

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 60
	* **说明:** 

		Time interval for measuring failure rate if <code class="highlighter-rouge">restart-strategy.type</code> has been set to <code class="highlighter-rouge">failure-rate</code>. It can be specified using notation: "1 min", "20 s"
		
		 单位：`秒`

3. failureRateDelay

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 

		Delay between two consecutive restart attempts if <code class="highlighter-rouge">restart-strategy.type</code> has been set to <code class="highlighter-rouge">failure-rate</code>. It can be specified using notation: "1 min", "20 s"
		
		 单位：`秒`

### :closed_lock_with_key:com.qlangtech.plugins.incr.flink.launch.restart.FixedDelay

* **显示名:** fixed-delay 

* **全路径名:** [com.qlangtech.plugins.incr.flink.launch.restart.FixedDelay](https://github.com/qlangtech/tis-plugins-commercial/tree/master/tis-incr-commercial/tis-flink-k8s-plugin/src/main/java/com/qlangtech/plugins/incr/flink/launch/restart/FixedDelay.java) 

* **费用:** :closed_lock_with_key: `社区协作`

* **插件包:** [tis-flink-k8s-plugin.tpi](./tpis#tis-flink-k8s-plugintpi)

* **配置项说明:** 

1. attempts

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 

		The number of times that Flink retries the execution before the job is declared as failed if <code class="highlighter-rouge">restart-strategy.type</code> has been set to <code class="highlighter-rouge">fixed-delay</code>.

2. delay

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 

		Delay between two consecutive restart attempts if <code class="highlighter-rouge">restart-strategy.type</code> has been set to <code class="highlighter-rouge">fixed-delay</code>. Delaying the retries can be helpful when the program interacts with external systems where for example connections or pending transactions should reach a timeout before re-execution is attempted. It can be specified using notation: "1 min", "20 s"
		
		 单位：`秒`

### com.qlangtech.plugins.incr.flink.launch.restart.OFF

* **显示名:** off 

* **全路径名:** [com.qlangtech.plugins.incr.flink.launch.restart.OFF](https://github.com/qlangtech/plugins/tree/master/tis-incr/tis-realtime-flink/src/main/java/com/qlangtech/plugins/incr/flink/launch/restart/OFF.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-realtime-flink.tpi](./tpis#tis-realtime-flinktpi)

## com.qlangtech.tis.plugin.datax.doplinscheduler.export.DSTaskGroup

### com.qlangtech.tis.plugin.datax.doplinscheduler.export.DSTaskGroup

* **显示名:** Default 

* **全路径名:** [com.qlangtech.tis.plugin.datax.doplinscheduler.export.DSTaskGroup](https://github.com/qlangtech/plugins/tree/master/tis-datax/tis-datax-dolphinscheduler-plugin/src/main/java/com/qlangtech/tis/plugin/datax/doplinscheduler/export/DSTaskGroup.java) 

* **费用:** :smile: `社区版(免费)`

* **插件包:** [tis-datax-dolphinscheduler-plugin.tpi](./tpis#tis-datax-dolphinscheduler-plugintpi)

* **配置项说明:** 

1. groupName

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.doplinscheduler.export.DSTaskGroup.dftGroupName()
	* **说明:** 		对应dolphinscheduler中资源组名称

2. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5
	* **说明:** 		资源组中最大可调用资源数量，可用来控制最大并发执行数

